1Intro
-Motivation and goals
-(IA-ML)
Bayes classifier, aprender a partir de muestras, aprendizaje probabilistico
Como se lleva lo de aprender de los datos a traduccion automatica

Es importante hacer referencias a la seccion previa. Instancia de clasificador de bayes para que el documento quede coherente
statistical learning?

--Supervised
--DL
-MT(breve 1 pagina)
Continuacion de lo anterior instanciado a machine translation
IBM, words & phrase based ?
modelos log lineales con phrase based ya no daban mas de si
plateu, durante años muy dificil mejorar los resultados
no hacia breakthrough
--Historia de antes del DL 1,2 páginas, problemas, limitaciones igual que de ML -> DL, MT -> NMT aquello que ha funcionado bien en ML en clasificacion se ha llevado a cabo en traduccion dando buenos resultados
--NMT
---(RNN, LSTM, Transformer) modelos por los que se ha pasado y como se ha llegado al transformer
---SOA (hitos, articulos de referencia, 1er articulo nmt, transformer, redes recurrentes)
---Modelo usado en tfg --descripcion, ventajas, transformer, resultados, citar competiciones, trabajos, articulo que aglutina resultados de la competicion IWSLT 2022, gran mayoria transformer --Dejar clara que la decision se basa en resultados recientes --mencionar que es el utilizado
-Framework of this work
--Marco de beca de la colaboracion CERN
(-Why the choice of this path to solve the problem)
-Document structure

2Data
-Preprocessing
--Tokenize
--Truecase
--BPE
-Filters
--Sentence length Ratio 
--Language Id filter

-Datasets
(training)
-Europarl-ST corpus
-Cern-corpus
-WMT dev test

(evaluacion)
-WMT dev test
-Polimedia dev test 
-Cern dev test

(estadisticas numero de frases, vocabulario, mencionarlo en cada uno o tabla)
-explain bias towards production system

3 CERN-News
-New dev test (posible capitulo)
--Crawling
--Split
--Align
(---articulo de importancia de dev test)

4 Fairseq (as an example to explain all steps & introduce to (learning) the task)
(Implementeacion modelo transformer)
Podemos poner ejemplo
(Punto de vista de toolkit)
-data
-preprocess
-model 
-fairseq
-training 
-evaluation
(-improvements)

5CERN
-production system (x5gon)

-mini
--(steps)
-baseline
--(steps)
-baseline2
--(steps)
-evaluation
-results

-improvements
--backtranslations
--fine tunning with cern news
(X --extra metric: technical words glossary X)
--compare different dev/test sets
--explain bias towards production system

6(Simultaneous NMT)
-(...)

7(Integracion no hecha)
-(...)

6Conclusion
-objectives achieved
-still a lot of possibilites for improving
-learning progress (revisited eurpoarl in the end)
-(...)

