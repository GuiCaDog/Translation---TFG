\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\catcode `<\active 
\catcode `>\active 
\@nameuse{es@quoting}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\babel@aux{catalan}{}
\babel@aux{english}{}
\babel@aux{spanish}{}
\babel@aux{english}{}
\babel@aux{english}{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{Contents}{v}{section*.1}\protected@file@percent }
\citation{pml1Book}
\citation{pml1Book}
\citation{pml1Book}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{vii}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Tables}{vii}{section*.3}\protected@file@percent }
\@writefile{toc}{\noindent \hrulefill \par }
\citation{Jumper2021HighlyAP}
\citation{Willett2020.07.01.183384}
\citation{https://doi.org/10.48550/arxiv.2102.07109}
\citation{doi:10.1177/117693510600200030}
\citation{https://doi.org/10.48550/arxiv.2204.06125}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{loq}{\addvspace {10\p@ }}
\newlabel{intro}{{1}{1}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{1}{section.1.1}\protected@file@percent }
\citation{BookTM}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Goals}{2}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Machine Learning}{2}{section.1.3}\protected@file@percent }
\newlabel{ml}{{1.3}{2}{Machine Learning}{section.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Supervised learning and classification}{3}{subsection.1.3.1}\protected@file@percent }
\newlabel{sl}{{1.3.1}{3}{Supervised learning and classification}{subsection.1.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Bayes classifier}{3}{subsubsection*.4}\protected@file@percent }
\newlabel{cagmx}{{1.3}{3}{Bayes classifier}{equation.1.3.3}{}}
\citation{pml1Book}
\citation{pml1Book}
\citation{rosenblatt1958perceptron}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Illustration of 4 data-samples representing the XOR problem. Adapted from Figure 13.1 of \cite  {pml1Book}.\relax }}{4}{figure.caption.6}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{chap1:xor}{{1.1}{4}{Illustration of 4 data-samples representing the XOR problem. Adapted from Figure 13.1 of \cite {pml1Book}.\relax }{figure.caption.6}{}}
\newlabel{bayesxc}{{1.4}{4}{Bayes classifier}{equation.1.3.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{Perceptron algorithm}{4}{subsubsection*.5}\protected@file@percent }
\newlabel{perc}{{1.5}{4}{Perceptron algorithm}{equation.1.3.5}{}}
\citation{minsky69perceptrons}
\citation{pml1Book}
\citation{pml1Book}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Deep learning}{5}{subsection.1.3.2}\protected@file@percent }
\newlabel{dl}{{1.3.2}{5}{Deep learning}{subsection.1.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Multilayer perceptron}{5}{subsubsection*.7}\protected@file@percent }
\citation{rumelhart1986learning}
\citation{dahl2011large}
\citation{10.5555/2999134.2999257}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces (a) Multilayer perceptron solving the XOR problem. (b) Representation of possible output values after the first layer ($\phi $). Adapted from Figure 13.1 of \cite  {pml1Book}. \relax }}{6}{figure.caption.8}\protected@file@percent }
\newlabel{chap1:xorsolved}{{1.2}{6}{(a) Multilayer perceptron solving the XOR problem. (b) Representation of possible output values after the first layer ($\phi $). Adapted from Figure 13.1 of \cite {pml1Book}. \relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering }}}{6}{subfigure.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering }}}{6}{subfigure.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Neural network}{6}{subsubsection*.9}\protected@file@percent }
\newlabel{ffnn}{{1.11}{6}{Neural network}{equation.1.3.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Machine Translation}{7}{section.1.4}\protected@file@percent }
\newlabel{mt}{{1.4}{7}{Machine Translation}{section.1.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{Formal setting}{7}{subsubsection*.10}\protected@file@percent }
\citation{brown1990statistical}
\citation{koehn2003statistical}
\citation{DEMP1977}
\citation{BRODER19971157}
\newlabel{nobayesxy}{{1.14}{8}{Formal setting}{equation.1.4.14}{}}
\newlabel{bayesxy}{{1.15}{8}{Formal setting}{equation.1.4.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Word and Phrase Based Models}{8}{subsection.1.4.1}\protected@file@percent }
\newlabel{wordbased}{{1.4.1}{8}{Word and Phrase Based Models}{subsection.1.4.1}{}}
\citation{https://doi.org/10.48550/arxiv.1409.0473}
\citation{pml1Book}
\citation{pml1Book}
\citation{650093}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Neural Machine Translation}{9}{section.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}RNN and Translation}{9}{subsection.1.5.1}\protected@file@percent }
\newlabel{nmtrnn}{{1.5.1}{9}{RNN and Translation}{subsection.1.5.1}{}}
\citation{hochreiter1997long}
\citation{cho-etal-2014-learning}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Sequence to sequence recurrent neural network with $n$ hidden states and $L$ hidden layers. Adapted from Figure 15.5 of \cite  {pml1Book}.\relax }}{10}{figure.caption.11}\protected@file@percent }
\newlabel{chap1:seq2seq}{{1.3}{10}{Sequence to sequence recurrent neural network with $n$ hidden states and $L$ hidden layers. Adapted from Figure 15.5 of \cite {pml1Book}.\relax }{figure.caption.11}{}}
\newlabel{hfor}{{1.18}{10}{RNN and Translation}{equation.1.5.18}{}}
\newlabel{hback}{{1.19}{10}{RNN and Translation}{equation.1.5.19}{}}
\citation{https://doi.org/10.48550/arxiv.1409.0473}
\citation{pml1Book}
\newlabel{sdec}{{1.21}{11}{RNN and Translation}{equation.1.5.21}{}}
\newlabel{decoc}{{1.22}{11}{RNN and Translation}{equation.1.5.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{Attention mechanism}{11}{subsubsection*.12}\protected@file@percent }
\newlabel{attn1}{{1.23}{11}{Attention mechanism}{equation.1.5.23}{}}
\newlabel{attn2}{{1.24}{11}{Attention mechanism}{equation.1.5.24}{}}
\newlabel{sdpa}{{1.25}{11}{Attention mechanism}{equation.1.5.25}{}}
\newlabel{attnRnn}{{1.26}{11}{Attention mechanism}{equation.1.5.26}{}}
\citation{https://doi.org/10.48550/arxiv.1409.0473}
\citation{https://doi.org/10.48550/arxiv.1706.03762}
\citation{pml1Book}
\citation{zhang2021dive}
\citation{koehn2020neural}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.2}The Transformer Model}{12}{subsection.1.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Self Attention Architecture}{12}{subsubsection*.13}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces A structural representation of the Transformer model with a certain number of encoding and decoding units.\relax }}{13}{figure.caption.14}\protected@file@percent }
\newlabel{chap1:transformer}{{1.4}{13}{A structural representation of the Transformer model with a certain number of encoding and decoding units.\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces (a) Representation of a encoding unit from Transformer. (b) Representation of a decoding unit from Transformer where $K$ and $V$ values are obtained from the top-most encoding unit. \relax }}{13}{figure.caption.15}\protected@file@percent }
\newlabel{chap1:encode}{{1.5}{13}{(a) Representation of a encoding unit from Transformer. (b) Representation of a decoding unit from Transformer where $K$ and $V$ values are obtained from the top-most encoding unit. \relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering }}}{13}{subfigure.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering }}}{13}{subfigure.5.2}\protected@file@percent }
\citation{https://doi.org/10.48550/arxiv.1803.08375}
\citation{ARTS:LayNor}
\citation{7780459}
\citation{pml1Book}
\@writefile{toc}{\contentsline {subsubsection}{Multi Head Self Attention}{14}{subsubsection*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Layer Normalization and Residual Connections}{14}{subsubsection*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Input representation and positional encoding}{15}{subsubsection*.18}\protected@file@percent }
\newlabel{inputrep}{{1.5.2}{15}{Input representation and positional encoding}{subsubsection*.18}{}}
\citation{press-wolf-2017-using}
\citation{https://doi.org/10.48550/arxiv.2005.14165}
\citation{https://doi.org/10.48550/arxiv.1810.04805}
\citation{https://doi.org/10.48550/arxiv.1910.10683}
\citation{anastasopoulos-etal-2022-findings}
\citation{papineni-etal-2002-bleu}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Evaluation}{16}{section.1.6}\protected@file@percent }
\citation{specia-etal-2009-improving}
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Framework of this work}{17}{section.1.7}\protected@file@percent }
\newlabel{framework}{{1.7}{17}{Framework of this work}{section.1.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.8}Document structure}{17}{section.1.8}\protected@file@percent }
\citation{https://doi.org/10.48550/arxiv.2005.14165}
\citation{aulamo-tiedemann-2019-opus}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Data}{19}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{loq}{\addvspace {10\p@ }}
\newlabel{dos}{{2}{19}{Data}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Datasets}{19}{section.2.1}\protected@file@percent }
\citation{el-kishky-etal-2020-ccaligned}
\citation{banon-etal-2020-paracrawl}
\citation{DBLP:journals/corr/abs-1907-05791}
\citation{tiedemann-2012-parallel}
\citation{TIEDEMANN12.463}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Statistics on parallel datasets. M = $1\cdot 10^6.$\relax }}{20}{table.caption.19}\protected@file@percent }
\newlabel{chap2:trainset}{{2.1}{20}{Statistics on parallel datasets. M = $1\cdot 10^6.$\relax }{table.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}General domain training dataset}{20}{subsection.2.1.1}\protected@file@percent }
\newlabel{dataset}{{2.1.1}{20}{General domain training dataset}{subsection.2.1.1}{}}
\citation{ziemski-etal-2016-united}
\citation{skadins-etal-2014-billions}
\citation{koehn-2005-europarl}
\citation{DBLP:journals/corr/abs-1911-03167}
\citation{DBLP:journals/corr/SteinbergerEKPS13}
\citation{TIEDEMANN12.463}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Development and Test Datasets from WMT}{21}{subsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Preprocessing}{21}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Tokenize and Truecasing}{21}{subsection.2.2.1}\protected@file@percent }
\citation{koehn-etal-2007-moses}
\citation{DBLP:journals/corr/SennrichHB15}
\citation{10.5555/177910.177914}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Training sentence before and after applying Moses' truecasing and tokenizer.\relax }}{22}{table.caption.20}\protected@file@percent }
\newlabel{table:truec}{{2.2}{22}{Training sentence before and after applying Moses' truecasing and tokenizer.\relax }{table.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Subword Segmentation}{22}{subsection.2.2.2}\protected@file@percent }
\newlabel{subw}{{2.2.2}{22}{Subword Segmentation}{subsection.2.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Byte Pair Encoding}{22}{subsubsection*.21}\protected@file@percent }
\citation{https://doi.org/10.48550/arxiv.1808.06226}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces Training sentence before and after applying Moses' truecasing, tokenizer and byte pair encoding.\relax }}{23}{table.caption.22}\protected@file@percent }
\newlabel{table:bpe}{{2.3}{23}{Training sentence before and after applying Moses' truecasing, tokenizer and byte pair encoding.\relax }{table.caption.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{Sentence Piece}{23}{subsubsection*.23}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.4}{\ignorespaces Training sentence before and after applying Moses' truecasing and sentence piece encoding.\relax }}{24}{table.caption.24}\protected@file@percent }
\newlabel{table:spm}{{2.4}{24}{Training sentence before and after applying Moses' truecasing and sentence piece encoding.\relax }{table.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Filtering}{24}{subsection.2.2.3}\protected@file@percent }
\newlabel{filtering}{{2.2.3}{24}{Filtering}{subsection.2.2.3}{}}
\citation{koehn-etal-2007-moses}
\citation{braune-fraser-2010-improved}
\citation{hunalignBook}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}CERN News}{25}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{loq}{\addvspace {10\p@ }}
\newlabel{tres}{{3}{25}{CERN News}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Data collection}{25}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Crawling and basic preprocessing}{25}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Alignment}{25}{subsection.3.1.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Statistics on the CERN News training, development, test sets. K = $1\cdot 10^3.$\relax }}{26}{table.caption.25}\protected@file@percent }
\newlabel{table:cnstats}{{3.1}{26}{Statistics on the CERN News training, development, test sets. K = $1\cdot 10^3.$\relax }{table.caption.25}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}CERN News Sets}{26}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Development and Test Sets}{26}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Training Set}{26}{subsection.3.2.2}\protected@file@percent }
\newlabel{CNTrain}{{3.2.2}{26}{Training Set}{subsection.3.2.2}{}}
\citation{ott-etal-2019-fairseq}
\citation{DBLP:journals/corr/abs-1806-00187}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Offline NMT Systems}{27}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{loq}{\addvspace {10\p@ }}
\newlabel{systems}{{4}{27}{Offline NMT Systems}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Fairseq}{27}{section.4.1}\protected@file@percent }
\newlabel{fairseq}{{4.1}{27}{Fairseq}{section.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Systems}{27}{section.4.2}\protected@file@percent }
\citation{https://doi.org/10.48550/arxiv.1706.03762}
\citation{https://doi.org/10.48550/arxiv.1412.6980}
\citation{https://doi.org/10.48550/arxiv.1706.03762}
\citation{JMLR:v15:srivastava14a}
\citation{DBLP:journals/corr/SzegedyVISW15}
\citation{https://doi.org/10.48550/arxiv.1710.03282}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}V0 System in Production}{28}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}V1 Baseline}{28}{subsection.4.2.2}\protected@file@percent }
\newlabel{V1}{{4.2.2}{28}{V1 Baseline}{subsection.4.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Preprocessing}{28}{subsubsection*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Training}{28}{subsubsection*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Inference and evaluation}{29}{subsubsection*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}V2 Language ID}{29}{subsection.4.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}V3 Sentence Piece}{29}{subsection.4.2.4}\protected@file@percent }
\newlabel{V3}{{4.2.4}{29}{V3 Sentence Piece}{subsection.4.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Offline systems pipelines and versions.\relax }}{30}{figure.caption.29}\protected@file@percent }
\newlabel{chap4:pipeline}{{4.1}{30}{Offline systems pipelines and versions.\relax }{figure.caption.29}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces En->Fr Bleu scores for WMT and CERN News evaluation sets.\relax }}{30}{table.caption.30}\protected@file@percent }
\newlabel{transformer:wmt:r}{{4.1}{30}{En->Fr Bleu scores for WMT and CERN News evaluation sets.\relax }{table.caption.30}{}}
\newlabel{table:bleuoff}{{4.1}{30}{En->Fr Bleu scores for WMT and CERN News evaluation sets.\relax }{table.caption.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Results}{30}{section.4.3}\protected@file@percent }
\citation{DBLP:journals/corr/SennrichHB15a}
\citation{DBLP:journals/corr/abs-1808-09381}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Domain Adaptation}{31}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{loq}{\addvspace {10\p@ }}
\newlabel{domad}{{5}{31}{Domain Adaptation}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Training with backtranslations}{31}{section.5.1}\protected@file@percent }
\citation{DBLP:journals/corr/abs-1803-10082}
\citation{DBLP:journals/corr/abs-1801-06146}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces En->Fr Bleu scores for WMT, CERN and CERNnews evaluation sets (V4 backtranslations).\relax }}{32}{table.caption.31}\protected@file@percent }
\newlabel{transformer:wmt:r}{{5.1}{32}{En->Fr Bleu scores for WMT, CERN and CERNnews evaluation sets (V4 backtranslations).\relax }{table.caption.31}{}}
\newlabel{table:bleuoffv4}{{5.1}{32}{En->Fr Bleu scores for WMT, CERN and CERNnews evaluation sets (V4 backtranslations).\relax }{table.caption.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Experimental setup}{32}{subsection.5.1.1}\protected@file@percent }
\newlabel{V4}{{5.1.1}{32}{Experimental setup}{subsection.5.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Results}{32}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Finetuning}{32}{section.5.2}\protected@file@percent }
\newlabel{fine}{{5.2}{32}{Finetuning}{section.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Results on CERN News development set for V4 finetuned on CDS backtranslations parallel set and on CERN News training set.\relax }}{33}{figure.caption.32}\protected@file@percent }
\newlabel{pmid:cnft}{{5.1}{33}{Results on CERN News development set for V4 finetuned on CDS backtranslations parallel set and on CERN News training set.\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Experimental setup}{33}{subsection.5.2.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Best results of En->Fr finetuned systems in BLEU scores for CERN News evaluation sets.\relax }}{34}{table.caption.33}\protected@file@percent }
\newlabel{table:bleuft}{{5.2}{34}{Best results of En->Fr finetuned systems in BLEU scores for CERN News evaluation sets.\relax }{table.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Results}{34}{subsection.5.2.2}\protected@file@percent }
\citation{https://doi.org/10.48550/arxiv.2203.02459}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Streaming NMT}{35}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{loq}{\addvspace {10\p@ }}
\newlabel{strnmt}{{6}{35}{Streaming NMT}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Formal setting}{35}{section.6.1}\protected@file@percent }
\citation{DBLP:journals/corr/abs-2005-08595}
\newlabel{pg}{{6.1}{36}{Formal setting}{equation.6.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Simultaneous Transformer model}{36}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Wait-k policy}{36}{subsection.6.2.1}\protected@file@percent }
\newlabel{waitkgamma}{{6.5}{36}{Wait-k policy}{equation.6.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Multi-path-wait-k model}{36}{subsection.6.2.2}\protected@file@percent }
\newlabel{multik}{{6.2.2}{36}{Multi-path-wait-k model}{subsection.6.2.2}{}}
\citation{ma-etal-2019-stacl}
\citation{DBLP:journals/corr/ChoE16}
\citation{DBLP:journals/corr/abs-1906-00048}
\citation{DBLP:journals/corr/ChoE16}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Evaluation}{37}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Average Proportion}{37}{subsection.6.3.1}\protected@file@percent }
\citation{DBLP:journals/corr/abs-1906-00048}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Average Lagging}{38}{subsection.6.3.2}\protected@file@percent }
\newlabel{al}{{6.9}{38}{Average Lagging}{equation.6.3.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.3}Differentiable Average Lagging}{38}{subsection.6.3.3}\protected@file@percent }
\citation{DBLP:journals/corr/abs-2005-08595}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces (a) WMT13 Development set evaluation for different wait-k policies during inference time. (b) Same evaluation on CERN News 21 Development set. \relax }}{39}{figure.caption.34}\protected@file@percent }
\newlabel{chap6:onlineres}{{6.1}{39}{(a) WMT13 Development set evaluation for different wait-k policies during inference time. (b) Same evaluation on CERN News 21 Development set. \relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering }}}{39}{subfigure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering }}}{39}{subfigure.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Experimental setup}{39}{section.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Results}{39}{section.6.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces BLEU and latency results of our multi-path-wait-k system for development and test sets with a wait-6 policy at inference time.\relax }}{40}{table.caption.35}\protected@file@percent }
\newlabel{table:testres}{{6.1}{40}{BLEU and latency results of our multi-path-wait-k system for development and test sets with a wait-6 policy at inference time.\relax }{table.caption.35}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusions}{41}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{loq}{\addvspace {10\p@ }}
\newlabel{conclusion}{{7}{41}{Conclusions}{chapter.7}{}}
\bibstyle{plain}
\bibdata{bibliography}
\bibcite{https://doi.org/10.48550/arxiv.1803.08375}{1}
\bibcite{anastasopoulos-etal-2022-findings}{2}
\bibcite{aulamo-tiedemann-2019-opus}{3}
\bibcite{ARTS:LayNor}{4}
\bibcite{https://doi.org/10.48550/arxiv.1409.0473}{5}
\bibcite{banon-etal-2020-paracrawl}{6}
\bibcite{braune-fraser-2010-improved}{7}
\bibcite{BRODER19971157}{8}
\bibcite{brown1990statistical}{9}
\bibcite{https://doi.org/10.48550/arxiv.2005.14165}{10}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{43}{chapter*.36}\protected@file@percent }
\bibcite{https://doi.org/10.48550/arxiv.1710.03282}{11}
\bibcite{DBLP:journals/corr/abs-1906-00048}{12}
\bibcite{DBLP:journals/corr/ChoE16}{13}
\bibcite{cho-etal-2014-learning}{14}
\bibcite{doi:10.1177/117693510600200030}{15}
\bibcite{dahl2011large}{16}
\bibcite{DEMP1977}{17}
\bibcite{https://doi.org/10.48550/arxiv.1810.04805}{18}
\bibcite{DBLP:journals/corr/abs-1808-09381}{19}
\bibcite{el-kishky-etal-2020-ccaligned}{20}
\bibcite{DBLP:journals/corr/abs-2005-08595}{21}
\bibcite{10.5555/177910.177914}{22}
\bibcite{hunalignBook}{23}
\bibcite{7780459}{24}
\bibcite{hochreiter1997long}{25}
\bibcite{DBLP:journals/corr/abs-1801-06146}{26}
\bibcite{DBLP:journals/corr/abs-1911-03167}{27}
\bibcite{https://doi.org/10.48550/arxiv.2203.02459}{28}
\bibcite{Jumper2021HighlyAP}{29}
\bibcite{https://doi.org/10.48550/arxiv.1412.6980}{30}
\bibcite{koehn-2005-europarl}{31}
\bibcite{koehn2020neural}{32}
\bibcite{koehn-etal-2007-moses}{33}
\bibcite{koehn2003statistical}{34}
\bibcite{10.5555/2999134.2999257}{35}
\bibcite{https://doi.org/10.48550/arxiv.1808.06226}{36}
\bibcite{ma-etal-2019-stacl}{37}
\bibcite{minsky69perceptrons}{38}
\bibcite{BookTM}{39}
\bibcite{pml1Book}{40}
\bibcite{ott-etal-2019-fairseq}{41}
\bibcite{DBLP:journals/corr/abs-1806-00187}{42}
\bibcite{papineni-etal-2002-bleu}{43}
\bibcite{press-wolf-2017-using}{44}
\bibcite{https://doi.org/10.48550/arxiv.1910.10683}{45}
\bibcite{https://doi.org/10.48550/arxiv.2204.06125}{46}
\bibcite{DBLP:journals/corr/abs-1803-10082}{47}
\bibcite{rosenblatt1958perceptron}{48}
\bibcite{rumelhart1986learning}{49}
\bibcite{650093}{50}
\bibcite{DBLP:journals/corr/abs-1907-05791}{51}
\bibcite{DBLP:journals/corr/SennrichHB15a}{52}
\bibcite{DBLP:journals/corr/SennrichHB15}{53}
\bibcite{skadins-etal-2014-billions}{54}
\bibcite{specia-etal-2009-improving}{55}
\bibcite{JMLR:v15:srivastava14a}{56}
\bibcite{DBLP:journals/corr/SteinbergerEKPS13}{57}
\bibcite{DBLP:journals/corr/SzegedyVISW15}{58}
\bibcite{tiedemann-2012-parallel}{59}
\bibcite{TIEDEMANN12.463}{60}
\bibcite{https://doi.org/10.48550/arxiv.1706.03762}{61}
\bibcite{https://doi.org/10.48550/arxiv.2102.07109}{62}
\bibcite{Willett2020.07.01.183384}{63}
\bibcite{zhang2021dive}{64}
\bibcite{ziemski-etal-2016-united}{65}
\setcounter {appendix}{2}
\gdef \@abspage@last{58}
