[II][GPU AM][2022-07-19 07:13:23] Hostname: panxo.dsic.upv.es
[II][GPU AM][2022-07-19 07:13:23] New request (JOB_ID 4920616): GPU_mem 11274289152, GPU_cards 1
[II][GPU AM][2022-07-19 07:13:23] Calling nvidia-smi:
Tue Jul 19 07:13:23 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:19:00.0 Off |                  N/A |
| 72%   70C    P2   130W / 250W |   2858MiB / 11264MiB |     10%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:1A:00.0 Off |                  N/A |
| 96%   85C    P2   239W / 250W |   8876MiB / 11264MiB |     60%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:67:00.0 Off |                  N/A |
|100%   82C    P2   135W / 250W |   4842MiB / 11264MiB |     10%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:68:00.0 Off |                  N/A |
| 72%   68C    P2    99W / 250W |   2866MiB / 11264MiB |     18%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A   3014829      C   python3                          2853MiB |
|    1   N/A  N/A   3717877      C   python3                          8871MiB |
|    2   N/A  N/A   2998050      C   python3                          4837MiB |
|    3   N/A  N/A   3031711      C   python3                          2861MiB |
+-----------------------------------------------------------------------------+

[II][GPU AM][2022-07-19 07:13:23] Current database status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": [
    {
      "jid": 4920571,
      "taskid": 4,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA49_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    },
    {
      "jid": 4920574,
      "taskid": 5,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": [
    {
      "jid": 4920574,
      "taskid": 6,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": [
    {
      "jid": 4920073,
      "taskid": null,
      "name": "exp6c_topotrans_pos_noeps_gnorm",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "6144 MB"
    }
  ],
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": [
    {
      "jid": 4920574,
      "taskid": 7,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ]
}

[WW][GPU AM][2022-07-19 07:13:23] I found an unexisting split (JID 4920571 -- TASKID 4) using GPU GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f. Fixing DB...
[II][GPU AM][2022-07-19 07:13:23] Updated database status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": [
    {
      "jid": 4920574,
      "taskid": 5,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": [
    {
      "jid": 4920574,
      "taskid": 6,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": [
    {
      "jid": 4920073,
      "taskid": null,
      "name": "exp6c_topotrans_pos_noeps_gnorm",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "6144 MB"
    }
  ],
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": [
    {
      "jid": 4920574,
      "taskid": 7,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ]
}

[II][GPU AM][2022-07-19 07:13:23] Current GPU status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": {
    "mem_total": "11264 MB",
    "mem_free_current": "6177 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "6177 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": {
    "mem_total": "11264 MB",
    "mem_free_current": "8161 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": {
    "mem_total": "11264 MB",
    "mem_free_current": "2143 MB",
    "mem_free_allocated": "5120 MB",
    "mem_free_real": "2143 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": {
    "mem_total": "11264 MB",
    "mem_free_current": "8152 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  }
}

[EE][GPU AM][2022-07-19 07:13:23] No GPU cards available to meet job requirements
+------- PROLOGUE SCRIPT -----------------------------------------------
|
| Job ID ...........: 4920616
| Started at .......: Tue Jul 19 07:13:23 CEST 2022
| Execution host ...: panxo
| Cluster queue ....: all.q
| ..................: NOT_ENOUGH_GPU_RESOURCES, WILL RESCHEDULE JOB.
| Script ...........: /opt/sge6-2/default/spool/panxo/job_scripts/4920616
| > trap "exit 100" ERR; ./finetune_CN.sh 90
|
+------- PROLOGUE SCRIPT -----------------------------------------------
[LL] Waiting 60 seconds before reescheduling...
[LL] Reescheduling now!
+------- EPILOGUE SCRIPT -----------------------------------------------
|
| Job ID ..............: 4920616
| Stopped at ..........: Tue Jul 19 07:14:23 CEST 2022
| Resources used ......: cpu=00:00:00, mem=0.00000 GBs, io=0.00000, vmem=N/A, maxvmem=N/A
| Peak memory value ...: N/A
| Total time used .....: 0:01:00
|
+------- EPILOGUE SCRIPT -----------------------------------------------
[II][GPU AM][2022-07-19 07:15:01] Hostname: panxo.dsic.upv.es
[II][GPU AM][2022-07-19 07:15:01] New request (JOB_ID 4920616): GPU_mem 11274289152, GPU_cards 1
[II][GPU AM][2022-07-19 07:15:01] Calling nvidia-smi:
Tue Jul 19 07:15:01 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:19:00.0 Off |                  N/A |
| 73%   65C    P2    91W / 250W |   2858MiB / 11264MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:1A:00.0 Off |                  N/A |
| 96%   85C    P2   275W / 250W |   8876MiB / 11264MiB |     61%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:67:00.0 Off |                  N/A |
| 94%   83C    P2   130W / 250W |   4842MiB / 11264MiB |      9%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:68:00.0 Off |                  N/A |
| 72%   68C    P2   100W / 250W |   2866MiB / 11264MiB |     18%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A   3014829      C   python3                          2853MiB |
|    1   N/A  N/A   3717877      C   python3                          8871MiB |
|    2   N/A  N/A   2998050      C   python3                          4837MiB |
|    3   N/A  N/A   3031711      C   python3                          2861MiB |
+-----------------------------------------------------------------------------+

[II][GPU AM][2022-07-19 07:15:01] Current database status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": [
    {
      "jid": 4920574,
      "taskid": 5,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": [
    {
      "jid": 4920574,
      "taskid": 6,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": [
    {
      "jid": 4920073,
      "taskid": null,
      "name": "exp6c_topotrans_pos_noeps_gnorm",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "6144 MB"
    }
  ],
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": [
    {
      "jid": 4920574,
      "taskid": 7,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ]
}

[II][GPU AM][2022-07-19 07:15:01] Current GPU status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": {
    "mem_total": "11264 MB",
    "mem_free_current": "6177 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "6177 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": {
    "mem_total": "11264 MB",
    "mem_free_current": "8161 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": {
    "mem_total": "11264 MB",
    "mem_free_current": "2143 MB",
    "mem_free_allocated": "5120 MB",
    "mem_free_real": "2143 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": {
    "mem_total": "11264 MB",
    "mem_free_current": "8152 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  }
}

[EE][GPU AM][2022-07-19 07:15:01] No GPU cards available to meet job requirements
+------- PROLOGUE SCRIPT -----------------------------------------------
|
| Job ID ...........: 4920616
| Started at .......: Tue Jul 19 07:15:01 CEST 2022
| Execution host ...: panxo
| Cluster queue ....: all.q
| ..................: NOT_ENOUGH_GPU_RESOURCES, WILL RESCHEDULE JOB.
| Script ...........: /opt/sge6-2/default/spool/panxo/job_scripts/4920616
| > trap "exit 100" ERR; ./finetune_CN.sh 90
|
+------- PROLOGUE SCRIPT -----------------------------------------------
[LL] Waiting 60 seconds before reescheduling...
[LL] Reescheduling now!
+------- EPILOGUE SCRIPT -----------------------------------------------
|
| Job ID ..............: 4920616
| Stopped at ..........: Tue Jul 19 07:16:01 CEST 2022
| Resources used ......: cpu=00:00:00, mem=0.00000 GBs, io=0.00000, vmem=N/A, maxvmem=N/A
| Peak memory value ...: N/A
| Total time used .....: 0:01:00
|
+------- EPILOGUE SCRIPT -----------------------------------------------
[II][GPU AM][2022-07-19 07:16:25] Hostname: panxo.dsic.upv.es
[II][GPU AM][2022-07-19 07:16:25] New request (JOB_ID 4920616): GPU_mem 11274289152, GPU_cards 1
[II][GPU AM][2022-07-19 07:16:25] Calling nvidia-smi:
Tue Jul 19 07:16:25 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:19:00.0 Off |                  N/A |
| 73%   71C    P2   131W / 250W |   2858MiB / 11264MiB |     17%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:1A:00.0 Off |                  N/A |
| 96%   86C    P2   267W / 250W |   8876MiB / 11264MiB |     60%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:67:00.0 Off |                  N/A |
| 93%   82C    P2   133W / 250W |   4842MiB / 11264MiB |      9%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:68:00.0 Off |                  N/A |
| 72%   69C    P2   102W / 250W |   2866MiB / 11264MiB |     18%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A   3014829      C   python3                          2853MiB |
|    1   N/A  N/A   3717877      C   python3                          8871MiB |
|    2   N/A  N/A   2998050      C   python3                          4837MiB |
|    3   N/A  N/A   3031711      C   python3                          2861MiB |
+-----------------------------------------------------------------------------+

[II][GPU AM][2022-07-19 07:16:25] Current database status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": [
    {
      "jid": 4920574,
      "taskid": 5,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": [
    {
      "jid": 4920574,
      "taskid": 6,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": [
    {
      "jid": 4920073,
      "taskid": null,
      "name": "exp6c_topotrans_pos_noeps_gnorm",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "6144 MB"
    }
  ],
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": [
    {
      "jid": 4920574,
      "taskid": 7,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ]
}

[II][GPU AM][2022-07-19 07:16:25] Current GPU status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": {
    "mem_total": "11264 MB",
    "mem_free_current": "6177 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "6177 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": {
    "mem_total": "11264 MB",
    "mem_free_current": "8161 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": {
    "mem_total": "11264 MB",
    "mem_free_current": "2143 MB",
    "mem_free_allocated": "5120 MB",
    "mem_free_real": "2143 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": {
    "mem_total": "11264 MB",
    "mem_free_current": "8152 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  }
}

[EE][GPU AM][2022-07-19 07:16:25] No GPU cards available to meet job requirements
+------- PROLOGUE SCRIPT -----------------------------------------------
|
| Job ID ...........: 4920616
| Started at .......: Tue Jul 19 07:16:25 CEST 2022
| Execution host ...: panxo
| Cluster queue ....: all.q
| ..................: NOT_ENOUGH_GPU_RESOURCES, WILL RESCHEDULE JOB.
| Script ...........: /opt/sge6-2/default/spool/panxo/job_scripts/4920616
| > trap "exit 100" ERR; ./finetune_CN.sh 90
|
+------- PROLOGUE SCRIPT -----------------------------------------------
[LL] Waiting 60 seconds before reescheduling...
[LL] Reescheduling now!
+------- EPILOGUE SCRIPT -----------------------------------------------
|
| Job ID ..............: 4920616
| Stopped at ..........: Tue Jul 19 07:17:25 CEST 2022
| Resources used ......: cpu=00:00:00, mem=0.00000 GBs, io=0.00000, vmem=N/A, maxvmem=N/A
| Peak memory value ...: N/A
| Total time used .....: 0:01:00
|
+------- EPILOGUE SCRIPT -----------------------------------------------
[II][GPU AM][2022-07-19 07:17:49] Hostname: panxo.dsic.upv.es
[II][GPU AM][2022-07-19 07:17:49] New request (JOB_ID 4920616): GPU_mem 11274289152, GPU_cards 1
[II][GPU AM][2022-07-19 07:17:49] Calling nvidia-smi:
Tue Jul 19 07:17:49 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:19:00.0 Off |                  N/A |
| 72%   68C    P2   129W / 250W |   2858MiB / 11264MiB |     10%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:1A:00.0 Off |                  N/A |
|124%   83C    P2   225W / 250W |   8876MiB / 11264MiB |     61%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:67:00.0 Off |                  N/A |
| 93%   82C    P2   116W / 250W |   4842MiB / 11264MiB |     10%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:68:00.0 Off |                  N/A |
| 73%   69C    P2   101W / 250W |   2866MiB / 11264MiB |     18%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A   3014829      C   python3                          2853MiB |
|    1   N/A  N/A   3717877      C   python3                          8871MiB |
|    2   N/A  N/A   2998050      C   python3                          4837MiB |
|    3   N/A  N/A   3031711      C   python3                          2861MiB |
+-----------------------------------------------------------------------------+

[II][GPU AM][2022-07-19 07:17:49] Current database status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": [
    {
      "jid": 4920574,
      "taskid": 5,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": [
    {
      "jid": 4920574,
      "taskid": 6,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": [
    {
      "jid": 4920073,
      "taskid": null,
      "name": "exp6c_topotrans_pos_noeps_gnorm",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "6144 MB"
    }
  ],
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": [
    {
      "jid": 4920574,
      "taskid": 7,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ]
}

[II][GPU AM][2022-07-19 07:17:49] Current GPU status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": {
    "mem_total": "11264 MB",
    "mem_free_current": "6177 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "6177 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": {
    "mem_total": "11264 MB",
    "mem_free_current": "8161 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": {
    "mem_total": "11264 MB",
    "mem_free_current": "2143 MB",
    "mem_free_allocated": "5120 MB",
    "mem_free_real": "2143 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": {
    "mem_total": "11264 MB",
    "mem_free_current": "8152 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  }
}

[EE][GPU AM][2022-07-19 07:17:49] No GPU cards available to meet job requirements
+------- PROLOGUE SCRIPT -----------------------------------------------
|
| Job ID ...........: 4920616
| Started at .......: Tue Jul 19 07:17:49 CEST 2022
| Execution host ...: panxo
| Cluster queue ....: all.q
| ..................: NOT_ENOUGH_GPU_RESOURCES, WILL RESCHEDULE JOB.
| Script ...........: /opt/sge6-2/default/spool/panxo/job_scripts/4920616
| > trap "exit 100" ERR; ./finetune_CN.sh 90
|
+------- PROLOGUE SCRIPT -----------------------------------------------
[LL] Waiting 60 seconds before reescheduling...
[LL] Reescheduling now!
+------- EPILOGUE SCRIPT -----------------------------------------------
|
| Job ID ..............: 4920616
| Stopped at ..........: Tue Jul 19 07:18:49 CEST 2022
| Resources used ......: cpu=00:00:00, mem=0.00000 GBs, io=0.00000, vmem=N/A, maxvmem=N/A
| Peak memory value ...: N/A
| Total time used .....: 0:01:00
|
+------- EPILOGUE SCRIPT -----------------------------------------------
[II][GPU AM][2022-07-19 07:19:41] Hostname: panxo.dsic.upv.es
[II][GPU AM][2022-07-19 07:19:41] New request (JOB_ID 4920616): GPU_mem 11274289152, GPU_cards 1
[II][GPU AM][2022-07-19 07:19:41] Calling nvidia-smi:
Tue Jul 19 07:19:41 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:19:00.0 Off |                  N/A |
| 72%   69C    P2   136W / 250W |   2858MiB / 11264MiB |      9%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:1A:00.0 Off |                  N/A |
| 96%   83C    P2   156W / 250W |   8876MiB / 11264MiB |     58%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:67:00.0 Off |                  N/A |
| 93%   83C    P2   135W / 250W |   4842MiB / 11264MiB |     14%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:68:00.0 Off |                  N/A |
| 73%   70C    P2   101W / 250W |   2866MiB / 11264MiB |      9%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A   3014829      C   python3                          2853MiB |
|    1   N/A  N/A   3717877      C   python3                          8871MiB |
|    2   N/A  N/A   2998050      C   python3                          4837MiB |
|    3   N/A  N/A   3031711      C   python3                          2861MiB |
+-----------------------------------------------------------------------------+

[II][GPU AM][2022-07-19 07:19:41] Current database status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": [
    {
      "jid": 4920574,
      "taskid": 5,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": [
    {
      "jid": 4920574,
      "taskid": 6,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": [
    {
      "jid": 4920073,
      "taskid": null,
      "name": "exp6c_topotrans_pos_noeps_gnorm",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "6144 MB"
    }
  ],
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": [
    {
      "jid": 4920574,
      "taskid": 7,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ]
}

[II][GPU AM][2022-07-19 07:19:41] Current GPU status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": {
    "mem_total": "11264 MB",
    "mem_free_current": "6177 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "6177 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": {
    "mem_total": "11264 MB",
    "mem_free_current": "8161 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": {
    "mem_total": "11264 MB",
    "mem_free_current": "2143 MB",
    "mem_free_allocated": "5120 MB",
    "mem_free_real": "2143 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": {
    "mem_total": "11264 MB",
    "mem_free_current": "8152 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  }
}

[EE][GPU AM][2022-07-19 07:19:41] No GPU cards available to meet job requirements
+------- PROLOGUE SCRIPT -----------------------------------------------
|
| Job ID ...........: 4920616
| Started at .......: Tue Jul 19 07:19:41 CEST 2022
| Execution host ...: panxo
| Cluster queue ....: all.q
| ..................: NOT_ENOUGH_GPU_RESOURCES, WILL RESCHEDULE JOB.
| Script ...........: /opt/sge6-2/default/spool/panxo/job_scripts/4920616
| > trap "exit 100" ERR; ./finetune_CN.sh 90
|
+------- PROLOGUE SCRIPT -----------------------------------------------
[LL] Waiting 60 seconds before reescheduling...
[LL] Reescheduling now!
+------- EPILOGUE SCRIPT -----------------------------------------------
|
| Job ID ..............: 4920616
| Stopped at ..........: Tue Jul 19 07:20:41 CEST 2022
| Resources used ......: cpu=00:00:00, mem=0.00000 GBs, io=0.00000, vmem=N/A, maxvmem=N/A
| Peak memory value ...: N/A
| Total time used .....: 0:01:00
|
+------- EPILOGUE SCRIPT -----------------------------------------------
[II][GPU AM][2022-07-19 07:20:44] Hostname: gozer2
[II][GPU AM][2022-07-19 07:20:44] New request (JOB_ID 4920616): GPU_mem 11274289152, GPU_cards 1
[II][GPU AM][2022-07-19 07:20:44] Calling nvidia-smi:
Tue Jul 19 07:20:44 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:02:00.0 Off |                  N/A |
| 36%   58C    P2   108W / 250W |   1842MiB / 11264MiB |      3%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:03:00.0 Off |                  N/A |
| 38%   62C    P2    88W / 250W |   2858MiB / 11264MiB |     13%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A   3307755      C   python3                          1837MiB |
|    1   N/A  N/A   3293617      C   python3                          2853MiB |
+-----------------------------------------------------------------------------+

[II][GPU AM][2022-07-19 07:20:44] Current database status:

{
  "GPU-15d857f5-5516-fcd3-4eb8-6ef2dd9c6ce4": [
    {
      "jid": 4920571,
      "taskid": 1,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA49_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-fed2c5ab-0b51-a98a-a38b-f5c281533683": [
    {
      "jid": 4920574,
      "taskid": 8,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ]
}

[II][GPU AM][2022-07-19 07:20:44] Current GPU status:

{
  "GPU-15d857f5-5516-fcd3-4eb8-6ef2dd9c6ce4": {
    "mem_total": "11264 MB",
    "mem_free_current": "9175 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-fed2c5ab-0b51-a98a-a38b-f5c281533683": {
    "mem_total": "11264 MB",
    "mem_free_current": "8161 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  }
}

[EE][GPU AM][2022-07-19 07:20:44] No GPU cards available to meet job requirements
+------- PROLOGUE SCRIPT -----------------------------------------------
|
| Job ID ...........: 4920616
| Started at .......: Tue Jul 19 07:20:44 CEST 2022
| Execution host ...: gozer2
| Cluster queue ....: all.q
| ..................: NOT_ENOUGH_GPU_RESOURCES, WILL RESCHEDULE JOB.
| Script ...........: /opt/sge6-2/default/spool/gozer2/job_scripts/4920616
| > trap "exit 100" ERR; ./finetune_CN.sh 90
|
+------- PROLOGUE SCRIPT -----------------------------------------------
[LL] Waiting 60 seconds before reescheduling...
[LL] Reescheduling now!
+------- EPILOGUE SCRIPT -----------------------------------------------
|
| Job ID ..............: 4920616
| Stopped at ..........: Tue Jul 19 07:21:44 CEST 2022
| Resources used ......: cpu=00:00:00, mem=0.00000 GBs, io=0.00000, vmem=N/A, maxvmem=N/A
| Peak memory value ...: N/A
| Total time used .....: 0:01:00
|
+------- EPILOGUE SCRIPT -----------------------------------------------
[II][GPU AM][2022-07-19 07:21:50] Hostname: panxo.dsic.upv.es
[II][GPU AM][2022-07-19 07:21:50] New request (JOB_ID 4920616): GPU_mem 11274289152, GPU_cards 1
[II][GPU AM][2022-07-19 07:21:50] Calling nvidia-smi:
Tue Jul 19 07:21:50 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:19:00.0 Off |                  N/A |
| 73%   70C    P2   134W / 250W |   2858MiB / 11264MiB |     19%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:1A:00.0 Off |                  N/A |
| 96%   84C    P2   178W / 250W |   8876MiB / 11264MiB |     59%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:67:00.0 Off |                  N/A |
| 93%   86C    P2   247W / 250W |   4842MiB / 11264MiB |     10%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:68:00.0 Off |                  N/A |
| 73%   70C    P2   101W / 250W |   2866MiB / 11264MiB |     16%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A   3014829      C   python3                          2853MiB |
|    1   N/A  N/A   3717877      C   python3                          8871MiB |
|    2   N/A  N/A   2998050      C   python3                          4837MiB |
|    3   N/A  N/A   3031711      C   python3                          2861MiB |
+-----------------------------------------------------------------------------+

[II][GPU AM][2022-07-19 07:21:50] Current database status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": [
    {
      "jid": 4920574,
      "taskid": 5,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": [
    {
      "jid": 4920574,
      "taskid": 6,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": [
    {
      "jid": 4920073,
      "taskid": null,
      "name": "exp6c_topotrans_pos_noeps_gnorm",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "6144 MB"
    }
  ],
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": [
    {
      "jid": 4920574,
      "taskid": 7,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ]
}

[II][GPU AM][2022-07-19 07:21:50] Current GPU status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": {
    "mem_total": "11264 MB",
    "mem_free_current": "6177 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "6177 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": {
    "mem_total": "11264 MB",
    "mem_free_current": "8161 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": {
    "mem_total": "11264 MB",
    "mem_free_current": "2143 MB",
    "mem_free_allocated": "5120 MB",
    "mem_free_real": "2143 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": {
    "mem_total": "11264 MB",
    "mem_free_current": "8152 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  }
}

[EE][GPU AM][2022-07-19 07:21:50] No GPU cards available to meet job requirements
+------- PROLOGUE SCRIPT -----------------------------------------------
|
| Job ID ...........: 4920616
| Started at .......: Tue Jul 19 07:21:50 CEST 2022
| Execution host ...: panxo
| Cluster queue ....: all.q
| ..................: NOT_ENOUGH_GPU_RESOURCES, WILL RESCHEDULE JOB.
| Script ...........: /opt/sge6-2/default/spool/panxo/job_scripts/4920616
| > trap "exit 100" ERR; ./finetune_CN.sh 90
|
+------- PROLOGUE SCRIPT -----------------------------------------------
[LL] Waiting 60 seconds before reescheduling...
[LL] Reescheduling now!
+------- EPILOGUE SCRIPT -----------------------------------------------
|
| Job ID ..............: 4920616
| Stopped at ..........: Tue Jul 19 07:22:50 CEST 2022
| Resources used ......: cpu=00:00:00, mem=0.00000 GBs, io=0.00000, vmem=N/A, maxvmem=N/A
| Peak memory value ...: N/A
| Total time used .....: 0:01:03
|
+------- EPILOGUE SCRIPT -----------------------------------------------
[II][GPU AM][2022-07-19 07:23:46] Hostname: panxo.dsic.upv.es
[II][GPU AM][2022-07-19 07:23:46] New request (JOB_ID 4920616): GPU_mem 11274289152, GPU_cards 1
[II][GPU AM][2022-07-19 07:23:46] Calling nvidia-smi:
Tue Jul 19 07:23:46 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:19:00.0 Off |                  N/A |
| 73%   71C    P2   186W / 250W |   2858MiB / 11264MiB |     10%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:1A:00.0 Off |                  N/A |
|116%   83C    P2   175W / 250W |   8876MiB / 11264MiB |     63%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:67:00.0 Off |                  N/A |
| 92%   81C    P2   134W / 250W |   4842MiB / 11264MiB |      9%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:68:00.0 Off |                  N/A |
| 74%   70C    P2   101W / 250W |   2866MiB / 11264MiB |     11%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A   3014829      C   python3                          2853MiB |
|    1   N/A  N/A   3717877      C   python3                          8871MiB |
|    2   N/A  N/A   2998050      C   python3                          4837MiB |
|    3   N/A  N/A   3031711      C   python3                          2861MiB |
+-----------------------------------------------------------------------------+

[II][GPU AM][2022-07-19 07:23:46] Current database status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": [
    {
      "jid": 4920574,
      "taskid": 5,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": [
    {
      "jid": 4920574,
      "taskid": 6,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": [
    {
      "jid": 4920073,
      "taskid": null,
      "name": "exp6c_topotrans_pos_noeps_gnorm",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "6144 MB"
    }
  ],
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": [
    {
      "jid": 4920574,
      "taskid": 7,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ]
}

[II][GPU AM][2022-07-19 07:23:46] Current GPU status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": {
    "mem_total": "11264 MB",
    "mem_free_current": "6177 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "6177 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": {
    "mem_total": "11264 MB",
    "mem_free_current": "8161 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": {
    "mem_total": "11264 MB",
    "mem_free_current": "2143 MB",
    "mem_free_allocated": "5120 MB",
    "mem_free_real": "2143 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": {
    "mem_total": "11264 MB",
    "mem_free_current": "8152 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  }
}

[EE][GPU AM][2022-07-19 07:23:46] No GPU cards available to meet job requirements
+------- PROLOGUE SCRIPT -----------------------------------------------
|
| Job ID ...........: 4920616
| Started at .......: Tue Jul 19 07:23:46 CEST 2022
| Execution host ...: panxo
| Cluster queue ....: all.q
| ..................: NOT_ENOUGH_GPU_RESOURCES, WILL RESCHEDULE JOB.
| Script ...........: /opt/sge6-2/default/spool/panxo/job_scripts/4920616
| > trap "exit 100" ERR; ./finetune_CN.sh 90
|
+------- PROLOGUE SCRIPT -----------------------------------------------
[LL] Waiting 60 seconds before reescheduling...
[LL] Reescheduling now!
+------- EPILOGUE SCRIPT -----------------------------------------------
|
| Job ID ..............: 4920616
| Stopped at ..........: Tue Jul 19 07:24:46 CEST 2022
| Resources used ......: cpu=00:00:00, mem=0.00000 GBs, io=0.00000, vmem=N/A, maxvmem=N/A
| Peak memory value ...: N/A
| Total time used .....: 0:01:00
|
+------- EPILOGUE SCRIPT -----------------------------------------------
[II][GPU AM][2022-07-19 07:24:49] Hostname: gozer2
[II][GPU AM][2022-07-19 07:24:49] New request (JOB_ID 4920616): GPU_mem 11274289152, GPU_cards 1
[II][GPU AM][2022-07-19 07:24:49] Calling nvidia-smi:
Tue Jul 19 07:24:49 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:02:00.0 Off |                  N/A |
| 35%   56C    P2    76W / 250W |   1842MiB / 11264MiB |      4%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:03:00.0 Off |                  N/A |
| 37%   62C    P2    93W / 250W |   2858MiB / 11264MiB |     24%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A   3307755      C   python3                          1837MiB |
|    1   N/A  N/A   3293617      C   python3                          2853MiB |
+-----------------------------------------------------------------------------+

[II][GPU AM][2022-07-19 07:24:49] Current database status:

{
  "GPU-15d857f5-5516-fcd3-4eb8-6ef2dd9c6ce4": [
    {
      "jid": 4920571,
      "taskid": 1,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA49_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-fed2c5ab-0b51-a98a-a38b-f5c281533683": [
    {
      "jid": 4920574,
      "taskid": 8,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ]
}

[II][GPU AM][2022-07-19 07:24:49] Current GPU status:

{
  "GPU-15d857f5-5516-fcd3-4eb8-6ef2dd9c6ce4": {
    "mem_total": "11264 MB",
    "mem_free_current": "9175 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-fed2c5ab-0b51-a98a-a38b-f5c281533683": {
    "mem_total": "11264 MB",
    "mem_free_current": "8161 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  }
}

[EE][GPU AM][2022-07-19 07:24:49] No GPU cards available to meet job requirements
+------- PROLOGUE SCRIPT -----------------------------------------------
|
| Job ID ...........: 4920616
| Started at .......: Tue Jul 19 07:24:49 CEST 2022
| Execution host ...: gozer2
| Cluster queue ....: all.q
| ..................: NOT_ENOUGH_GPU_RESOURCES, WILL RESCHEDULE JOB.
| Script ...........: /opt/sge6-2/default/spool/gozer2/job_scripts/4920616
| > trap "exit 100" ERR; ./finetune_CN.sh 90
|
+------- PROLOGUE SCRIPT -----------------------------------------------
[LL] Waiting 60 seconds before reescheduling...
[LL] Reescheduling now!
+------- EPILOGUE SCRIPT -----------------------------------------------
|
| Job ID ..............: 4920616
| Stopped at ..........: Tue Jul 19 07:25:49 CEST 2022
| Resources used ......: cpu=00:00:00, mem=0.00000 GBs, io=0.00000, vmem=N/A, maxvmem=N/A
| Peak memory value ...: N/A
| Total time used .....: 0:01:00
|
+------- EPILOGUE SCRIPT -----------------------------------------------
[II][GPU AM][2022-07-19 07:25:52] Hostname: panxo.dsic.upv.es
[II][GPU AM][2022-07-19 07:25:52] New request (JOB_ID 4920616): GPU_mem 11274289152, GPU_cards 1
[II][GPU AM][2022-07-19 07:25:52] Calling nvidia-smi:
Tue Jul 19 07:25:52 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:19:00.0 Off |                  N/A |
| 74%   73C    P2   186W / 250W |   2858MiB / 11264MiB |     14%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:1A:00.0 Off |                  N/A |
|124%   83C    P2   162W / 250W |   8876MiB / 11264MiB |     64%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:67:00.0 Off |                  N/A |
| 93%   83C    P2   128W / 250W |   4842MiB / 11264MiB |     17%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:68:00.0 Off |                  N/A |
| 74%   70C    P2    99W / 250W |   2866MiB / 11264MiB |      9%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A   3014829      C   python3                          2853MiB |
|    1   N/A  N/A   3717877      C   python3                          8871MiB |
|    2   N/A  N/A   2998050      C   python3                          4837MiB |
|    3   N/A  N/A   3031711      C   python3                          2861MiB |
+-----------------------------------------------------------------------------+

[II][GPU AM][2022-07-19 07:25:52] Current database status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": [
    {
      "jid": 4920574,
      "taskid": 5,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": [
    {
      "jid": 4920574,
      "taskid": 6,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": [
    {
      "jid": 4920073,
      "taskid": null,
      "name": "exp6c_topotrans_pos_noeps_gnorm",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "6144 MB"
    }
  ],
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": [
    {
      "jid": 4920574,
      "taskid": 7,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ]
}

[II][GPU AM][2022-07-19 07:25:52] Current GPU status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": {
    "mem_total": "11264 MB",
    "mem_free_current": "6177 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "6177 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": {
    "mem_total": "11264 MB",
    "mem_free_current": "8161 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": {
    "mem_total": "11264 MB",
    "mem_free_current": "2143 MB",
    "mem_free_allocated": "5120 MB",
    "mem_free_real": "2143 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": {
    "mem_total": "11264 MB",
    "mem_free_current": "8152 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  }
}

[EE][GPU AM][2022-07-19 07:25:52] No GPU cards available to meet job requirements
+------- PROLOGUE SCRIPT -----------------------------------------------
|
| Job ID ...........: 4920616
| Started at .......: Tue Jul 19 07:25:52 CEST 2022
| Execution host ...: panxo
| Cluster queue ....: all.q
| ..................: NOT_ENOUGH_GPU_RESOURCES, WILL RESCHEDULE JOB.
| Script ...........: /opt/sge6-2/default/spool/panxo/job_scripts/4920616
| > trap "exit 100" ERR; ./finetune_CN.sh 90
|
+------- PROLOGUE SCRIPT -----------------------------------------------
[LL] Waiting 60 seconds before reescheduling...
[LL] Reescheduling now!
+------- EPILOGUE SCRIPT -----------------------------------------------
|
| Job ID ..............: 4920616
| Stopped at ..........: Tue Jul 19 07:26:52 CEST 2022
| Resources used ......: cpu=00:00:00, mem=0.00000 GBs, io=0.00000, vmem=N/A, maxvmem=N/A
| Peak memory value ...: N/A
| Total time used .....: 0:01:00
|
+------- EPILOGUE SCRIPT -----------------------------------------------
[II][GPU AM][2022-07-19 07:27:44] Hostname: panxo.dsic.upv.es
[II][GPU AM][2022-07-19 07:27:44] New request (JOB_ID 4920616): GPU_mem 11274289152, GPU_cards 1
[II][GPU AM][2022-07-19 07:27:44] Calling nvidia-smi:
Tue Jul 19 07:27:44 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:19:00.0 Off |                  N/A |
| 74%   70C    P2   138W / 250W |   2858MiB / 11264MiB |     19%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:1A:00.0 Off |                  N/A |
|124%   85C    P2   239W / 250W |   8876MiB / 11264MiB |     63%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:67:00.0 Off |                  N/A |
| 94%   86C    P2   156W / 250W |   4842MiB / 11264MiB |      9%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:68:00.0 Off |                  N/A |
| 74%   69C    P2    93W / 250W |   2866MiB / 11264MiB |     19%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A   3014829      C   python3                          2853MiB |
|    1   N/A  N/A   3717877      C   python3                          8871MiB |
|    2   N/A  N/A   2998050      C   python3                          4837MiB |
|    3   N/A  N/A   3031711      C   python3                          2861MiB |
+-----------------------------------------------------------------------------+

[II][GPU AM][2022-07-19 07:27:44] Current database status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": [
    {
      "jid": 4920574,
      "taskid": 5,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": [
    {
      "jid": 4920574,
      "taskid": 6,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": [
    {
      "jid": 4920073,
      "taskid": null,
      "name": "exp6c_topotrans_pos_noeps_gnorm",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "6144 MB"
    }
  ],
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": [
    {
      "jid": 4920574,
      "taskid": 7,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ]
}

[II][GPU AM][2022-07-19 07:27:44] Current GPU status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": {
    "mem_total": "11264 MB",
    "mem_free_current": "6177 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "6177 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": {
    "mem_total": "11264 MB",
    "mem_free_current": "8161 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": {
    "mem_total": "11264 MB",
    "mem_free_current": "2143 MB",
    "mem_free_allocated": "5120 MB",
    "mem_free_real": "2143 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": {
    "mem_total": "11264 MB",
    "mem_free_current": "8152 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  }
}

[EE][GPU AM][2022-07-19 07:27:44] No GPU cards available to meet job requirements
+------- PROLOGUE SCRIPT -----------------------------------------------
|
| Job ID ...........: 4920616
| Started at .......: Tue Jul 19 07:27:44 CEST 2022
| Execution host ...: panxo
| Cluster queue ....: all.q
| ..................: NOT_ENOUGH_GPU_RESOURCES, WILL RESCHEDULE JOB.
| Script ...........: /opt/sge6-2/default/spool/panxo/job_scripts/4920616
| > trap "exit 100" ERR; ./finetune_CN.sh 90
|
+------- PROLOGUE SCRIPT -----------------------------------------------
[LL] Waiting 60 seconds before reescheduling...
[LL] Reescheduling now!
+------- EPILOGUE SCRIPT -----------------------------------------------
|
| Job ID ..............: 4920616
| Stopped at ..........: Tue Jul 19 07:28:44 CEST 2022
| Resources used ......: cpu=00:00:00, mem=0.00000 GBs, io=0.00000, vmem=N/A, maxvmem=N/A
| Peak memory value ...: N/A
| Total time used .....: 0:01:00
|
+------- EPILOGUE SCRIPT -----------------------------------------------
[II][GPU AM][2022-07-19 07:29:43] Hostname: panxo.dsic.upv.es
[II][GPU AM][2022-07-19 07:29:43] New request (JOB_ID 4920616): GPU_mem 11274289152, GPU_cards 1
[II][GPU AM][2022-07-19 07:29:43] Calling nvidia-smi:
Tue Jul 19 07:29:43 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:19:00.0 Off |                  N/A |
| 73%   68C    P2   132W / 250W |   2858MiB / 11264MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:1A:00.0 Off |                  N/A |
| 96%   84C    P2   274W / 250W |   8876MiB / 11264MiB |     62%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:67:00.0 Off |                  N/A |
| 94%   85C    P2   158W / 250W |   4842MiB / 11264MiB |     10%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:68:00.0 Off |                  N/A |
| 74%   67C    P2    78W / 250W |   2866MiB / 11264MiB |     17%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A   3014829      C   python3                          2853MiB |
|    1   N/A  N/A   3717877      C   python3                          8871MiB |
|    2   N/A  N/A   2998050      C   python3                          4837MiB |
|    3   N/A  N/A   3031711      C   python3                          2861MiB |
+-----------------------------------------------------------------------------+

[II][GPU AM][2022-07-19 07:29:43] Current database status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": [
    {
      "jid": 4920574,
      "taskid": 5,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": [
    {
      "jid": 4920574,
      "taskid": 6,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": [
    {
      "jid": 4920073,
      "taskid": null,
      "name": "exp6c_topotrans_pos_noeps_gnorm",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "6144 MB"
    }
  ],
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": [
    {
      "jid": 4920574,
      "taskid": 7,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ]
}

[II][GPU AM][2022-07-19 07:29:43] Current GPU status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": {
    "mem_total": "11264 MB",
    "mem_free_current": "6177 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "6177 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": {
    "mem_total": "11264 MB",
    "mem_free_current": "8161 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": {
    "mem_total": "11264 MB",
    "mem_free_current": "2143 MB",
    "mem_free_allocated": "5120 MB",
    "mem_free_real": "2143 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": {
    "mem_total": "11264 MB",
    "mem_free_current": "8152 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "7168 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  }
}

[EE][GPU AM][2022-07-19 07:29:43] No GPU cards available to meet job requirements
+------- PROLOGUE SCRIPT -----------------------------------------------
|
| Job ID ...........: 4920616
| Started at .......: Tue Jul 19 07:29:43 CEST 2022
| Execution host ...: panxo
| Cluster queue ....: all.q
| ..................: NOT_ENOUGH_GPU_RESOURCES, WILL RESCHEDULE JOB.
| Script ...........: /opt/sge6-2/default/spool/panxo/job_scripts/4920616
| > trap "exit 100" ERR; ./finetune_CN.sh 90
|
+------- PROLOGUE SCRIPT -----------------------------------------------
[LL] Waiting 60 seconds before reescheduling...
[LL] Reescheduling now!
+------- EPILOGUE SCRIPT -----------------------------------------------
|
| Job ID ..............: 4920616
| Stopped at ..........: Tue Jul 19 07:30:43 CEST 2022
| Resources used ......: cpu=00:00:00, mem=0.00000 GBs, io=0.00000, vmem=N/A, maxvmem=N/A
| Peak memory value ...: N/A
| Total time used .....: 0:01:00
|
+------- EPILOGUE SCRIPT -----------------------------------------------
[II][GPU AM][2022-07-19 07:31:42] Hostname: panxo.dsic.upv.es
[II][GPU AM][2022-07-19 07:31:42] New request (JOB_ID 4920616): GPU_mem 11274289152, GPU_cards 1
[II][GPU AM][2022-07-19 07:31:43] Calling nvidia-smi:
Tue Jul 19 07:31:43 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:19:00.0 Off |                  N/A |
| 50%   58C    P0    84W / 250W |      0MiB / 11264MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce ...  Off  | 00000000:1A:00.0 Off |                  N/A |
| 96%   83C    P2   267W / 250W |   8876MiB / 11264MiB |     61%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  Off  | 00000000:67:00.0 Off |                  N/A |
| 94%   84C    P2   210W / 250W |   4842MiB / 11264MiB |     18%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  Off  | 00000000:68:00.0 Off |                  N/A |
| 40%   58C    P0    40W / 250W |      0MiB / 11264MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    1   N/A  N/A   3717877      C   python3                          8871MiB |
|    2   N/A  N/A   2998050      C   python3                          4837MiB |
+-----------------------------------------------------------------------------+

[II][GPU AM][2022-07-19 07:31:43] Current database status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": [
    {
      "jid": 4920574,
      "taskid": 5,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": [
    {
      "jid": 4920574,
      "taskid": 6,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": [
    {
      "jid": 4920073,
      "taskid": null,
      "name": "exp6c_topotrans_pos_noeps_gnorm",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "6144 MB"
    }
  ],
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": [
    {
      "jid": 4920574,
      "taskid": 7,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ]
}

[WW][GPU AM][2022-07-19 07:31:45] I found an unexisting split (JID 4920574 -- TASKID 6) using GPU GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e. Fixing DB...
[WW][GPU AM][2022-07-19 07:31:45] I found an unexisting split (JID 4920574 -- TASKID 7) using GPU GPU-d85a1210-8f4e-8096-9c24-233d3fe252da. Fixing DB...
[II][GPU AM][2022-07-19 07:31:45] Updated database status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": [
    {
      "jid": 4920574,
      "taskid": 5,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": [],
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": [
    {
      "jid": 4920073,
      "taskid": null,
      "name": "exp6c_topotrans_pos_noeps_gnorm",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "6144 MB"
    }
  ],
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": []
}

[II][GPU AM][2022-07-19 07:31:45] Current GPU status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": {
    "mem_total": "11264 MB",
    "mem_free_current": "6177 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "6177 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": {
    "mem_total": "11264 MB",
    "mem_free_current": "11019 MB",
    "mem_free_allocated": "11264 MB",
    "mem_free_real": "11019 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 0
  },
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": {
    "mem_total": "11264 MB",
    "mem_free_current": "2143 MB",
    "mem_free_allocated": "5120 MB",
    "mem_free_real": "2143 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": {
    "mem_total": "11264 MB",
    "mem_free_current": "11018 MB",
    "mem_free_allocated": "11264 MB",
    "mem_free_real": "11018 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 0
  }
}

[II][GPU AM][2022-07-19 07:31:45] Updated database status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": [
    {
      "jid": 4920574,
      "taskid": 5,
      "name": "reco_words_dev_exp7b_topotrans_pos_noeps_fgnorm_avgno_EP42_GSF4.0_HP7500_BEAM160_HPMIN20_LA149_STEP20.recognition.standard-step1.recognise-body",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "4096 MB"
    }
  ],
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": [
    {
      "jid": 4920616,
      "taskid": null,
      "name": "tv4FTK90",
      "user": "gicado",
      "gpu_card": 1,
      "gpu_mem": "10752 MB"
    }
  ],
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": [
    {
      "jid": 4920073,
      "taskid": null,
      "name": "exp6c_topotrans_pos_noeps_gnorm",
      "user": "agimenez",
      "gpu_card": 0,
      "gpu_mem": "6144 MB"
    }
  ],
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": []
}

[II][GPU AM][2022-07-19 07:31:45] Updated GPU status:

{
  "GPU-2428c4c2-bdf5-664d-d8bc-767538aba25f": {
    "mem_total": "11264 MB",
    "mem_free_current": "6177 MB",
    "mem_free_allocated": "7168 MB",
    "mem_free_real": "6177 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e": {
    "mem_total": "11264 MB",
    "mem_free_current": "11019 MB",
    "mem_free_allocated": "512 MB",
    "mem_free_real": "267 MB",
    "sge_card_allocated": true,
    "sge_slots_allocated": 0
  },
  "GPU-660b0474-1b6f-ed2a-3b8d-d41ca3017639": {
    "mem_total": "11264 MB",
    "mem_free_current": "2143 MB",
    "mem_free_allocated": "5120 MB",
    "mem_free_real": "2143 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 1
  },
  "GPU-d85a1210-8f4e-8096-9c24-233d3fe252da": {
    "mem_total": "11264 MB",
    "mem_free_current": "11018 MB",
    "mem_free_allocated": "11264 MB",
    "mem_free_real": "11018 MB",
    "sge_card_allocated": false,
    "sge_slots_allocated": 0
  }
}

[II][GPU AM][2022-07-19 07:31:45] Selected GPUs: GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e

+------- PROLOGUE SCRIPT -----------------------------------------------
|
| Job ID ...........: 4920616
| Started at .......: Tue Jul 19 07:31:45 CEST 2022
| Execution host ...: panxo
| Cluster queue ....: all.q
| GPUs .............: GPU-3074c9a6-dcac-b8b6-c514-45e0f520975e
| Script ...........: /opt/sge6-2/default/spool/panxo/job_scripts/4920616
| > trap "exit 100" ERR; ./finetune_CN.sh 90
|
+------- PROLOGUE SCRIPT -----------------------------------------------
2022-07-19 07:31:56 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_vaswani_wmt_en_fr_big', attention_dropout=0.0, best_checkpoint_metric='loss', bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/home/gicado/tfg/mt_systems/enfr/CERN-June28_v4_1M_backtranslations/finetuning/CN_training_keep90/fairseq_prepared_data_finetuning_CNdev_CERNnews/', data_buffer_size=0, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=50, keep_last_epochs=-1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=10, lr=[1e-05], lr_scheduler='fixed', lr_shrink=0.1, max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=1900, max_tokens_valid=1900, max_update=5000, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=True, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=True, restore_file='/scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations/checkpoint_best.pt', save_dir='/scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews', save_interval=100, save_interval_updates=100, seed=1, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', target_lang='fr', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[8], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_updates=0, weight_decay=0.0)
2022-07-19 07:31:56 | INFO | fairseq.tasks.translation | [en] dictionary: 49960 types
2022-07-19 07:31:56 | INFO | fairseq.tasks.translation | [fr] dictionary: 49960 types
2022-07-19 07:31:56 | INFO | fairseq.data.data_utils | loaded 2200 examples from: /home/gicado/tfg/mt_systems/enfr/CERN-June28_v4_1M_backtranslations/finetuning/CN_training_keep90/fairseq_prepared_data_finetuning_CNdev_CERNnews/valid.en-fr.en
2022-07-19 07:31:56 | INFO | fairseq.data.data_utils | loaded 2200 examples from: /home/gicado/tfg/mt_systems/enfr/CERN-June28_v4_1M_backtranslations/finetuning/CN_training_keep90/fairseq_prepared_data_finetuning_CNdev_CERNnews/valid.en-fr.fr
2022-07-19 07:31:56 | INFO | fairseq.tasks.translation | /home/gicado/tfg/mt_systems/enfr/CERN-June28_v4_1M_backtranslations/finetuning/CN_training_keep90/fairseq_prepared_data_finetuning_CNdev_CERNnews/ valid en-fr 2200 examples
2022-07-19 07:31:59 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (embed_tokens): Embedding(49960, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(49960, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=1024, out_features=49960, bias=False)
  )
)
2022-07-19 07:31:59 | INFO | fairseq_cli.train | model transformer_vaswani_wmt_en_fr_big, criterion LabelSmoothedCrossEntropyCriterion
2022-07-19 07:31:59 | INFO | fairseq_cli.train | num. model params: 227516416 (num. trained: 227516416)
2022-07-19 07:32:09 | INFO | fairseq_cli.train | training on 1 GPUs
2022-07-19 07:32:09 | INFO | fairseq_cli.train | max tokens per GPU = 1900 and max sentences per GPU = None
2022-07-19 07:32:37 | INFO | fairseq.trainer | loaded checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations/checkpoint_best.pt (epoch 2 @ 0 updates)
2022-07-19 07:32:37 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16
2022-07-19 07:32:37 | INFO | fairseq.trainer | loading train data for epoch 2
2022-07-19 07:32:37 | INFO | fairseq.data.data_utils | loaded 50340 examples from: /home/gicado/tfg/mt_systems/enfr/CERN-June28_v4_1M_backtranslations/finetuning/CN_training_keep90/fairseq_prepared_data_finetuning_CNdev_CERNnews/train.en-fr.en
2022-07-19 07:32:37 | INFO | fairseq.data.data_utils | loaded 50340 examples from: /home/gicado/tfg/mt_systems/enfr/CERN-June28_v4_1M_backtranslations/finetuning/CN_training_keep90/fairseq_prepared_data_finetuning_CNdev_CERNnews/train.en-fr.fr
2022-07-19 07:32:37 | INFO | fairseq.tasks.translation | /home/gicado/tfg/mt_systems/enfr/CERN-June28_v4_1M_backtranslations/finetuning/CN_training_keep90/fairseq_prepared_data_finetuning_CNdev_CERNnews/ train en-fr 50340 examples
2022-07-19 07:32:58 | INFO | train_inner | epoch 003:     10 / 138 loss=3.461, nll_loss=1.715, ppl=3.28, wps=5084.9, ups=0.4, wpb=12781.3, bsz=365.2, num_updates=10, lr=1e-05, gnorm=1.143, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:33:19 | INFO | train_inner | epoch 003:     20 / 138 loss=3.42, nll_loss=1.67, ppl=3.18, wps=6091.5, ups=0.49, wpb=12424.6, bsz=352.8, num_updates=20, lr=1e-05, gnorm=0.795, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:33:39 | INFO | train_inner | epoch 003:     30 / 138 loss=3.393, nll_loss=1.64, ppl=3.12, wps=6119.1, ups=0.49, wpb=12511.4, bsz=364.8, num_updates=30, lr=1e-05, gnorm=0.767, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:33:59 | INFO | train_inner | epoch 003:     40 / 138 loss=3.372, nll_loss=1.611, ppl=3.05, wps=6000.4, ups=0.49, wpb=12138.2, bsz=340, num_updates=40, lr=1e-05, gnorm=0.799, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:34:20 | INFO | train_inner | epoch 003:     50 / 138 loss=3.345, nll_loss=1.582, ppl=2.99, wps=6092.4, ups=0.48, wpb=12630.5, bsz=361.6, num_updates=50, lr=1e-05, gnorm=0.749, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:34:40 | INFO | train_inner | epoch 003:     60 / 138 loss=3.404, nll_loss=1.651, ppl=3.14, wps=6015.1, ups=0.49, wpb=12182.2, bsz=318.4, num_updates=60, lr=1e-05, gnorm=0.78, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:35:01 | INFO | train_inner | epoch 003:     70 / 138 loss=3.346, nll_loss=1.584, ppl=3, wps=6021, ups=0.48, wpb=12446.4, bsz=391.9, num_updates=70, lr=1e-05, gnorm=0.73, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:35:22 | INFO | train_inner | epoch 003:     80 / 138 loss=3.381, nll_loss=1.623, ppl=3.08, wps=5961.4, ups=0.48, wpb=12496.8, bsz=400.8, num_updates=80, lr=1e-05, gnorm=0.78, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:35:43 | INFO | train_inner | epoch 003:     90 / 138 loss=3.357, nll_loss=1.598, ppl=3.03, wps=6011.6, ups=0.46, wpb=12945.8, bsz=428.8, num_updates=90, lr=1e-05, gnorm=0.722, loss_scale=None, train_wall=21, wall=0
2022-07-19 07:36:04 | INFO | train_inner | epoch 003:    100 / 138 loss=3.361, nll_loss=1.598, ppl=3.03, wps=6008.8, ups=0.49, wpb=12378.9, bsz=355.2, num_updates=100, lr=1e-05, gnorm=0.792, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:36:10 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 3.244 | nll_loss 1.44 | ppl 2.71 | wps 14761.6 | wpb 1129.8 | bsz 29.7 | num_updates 100
2022-07-19 07:38:37 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_3_100.pt (epoch 3 @ 100 updates, score 3.244) (writing took 147.3915844084695 seconds)
2022-07-19 07:38:57 | INFO | train_inner | epoch 003:    110 / 138 loss=3.377, nll_loss=1.617, ppl=3.07, wps=731.6, ups=0.06, wpb=12668.3, bsz=315.2, num_updates=110, lr=1e-05, gnorm=0.71, loss_scale=None, train_wall=19, wall=0
2022-07-19 07:39:17 | INFO | train_inner | epoch 003:    120 / 138 loss=3.332, nll_loss=1.57, ppl=2.97, wps=6199.3, ups=0.5, wpb=12284.3, bsz=374.4, num_updates=120, lr=1e-05, gnorm=0.764, loss_scale=None, train_wall=19, wall=0
2022-07-19 07:39:37 | INFO | train_inner | epoch 003:    130 / 138 loss=3.321, nll_loss=1.556, ppl=2.94, wps=6038.7, ups=0.5, wpb=12059.6, bsz=404.6, num_updates=130, lr=1e-05, gnorm=0.809, loss_scale=None, train_wall=19, wall=0
2022-07-19 07:39:57 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 3.235 | nll_loss 1.43 | ppl 2.7 | wps 15041.2 | wpb 1129.8 | bsz 29.7 | num_updates 138 | best_loss 3.235
2022-07-19 07:39:57 | INFO | train | epoch 003 | loss 3.372 | nll_loss 1.611 | ppl 3.06 | wps 24963.3 | ups 1.85 | wpb 13494 | bsz 470.4 | num_updates 138 | lr 1e-05 | gnorm 0.65 | loss_scale 13 | train_wall 232736 | wall 0
2022-07-19 07:40:02 | INFO | train_inner | epoch 004:      2 / 138 loss=3.405, nll_loss=1.651, ppl=3.14, wps=4689.3, ups=0.41, wpb=11466.5, bsz=328.3, num_updates=140, lr=1e-05, gnorm=0.895, loss_scale=None, train_wall=18, wall=0
2022-07-19 07:40:22 | INFO | train_inner | epoch 004:     12 / 138 loss=3.289, nll_loss=1.518, ppl=2.86, wps=6051.6, ups=0.49, wpb=12390.4, bsz=411.2, num_updates=150, lr=1e-05, gnorm=0.724, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:40:43 | INFO | train_inner | epoch 004:     22 / 138 loss=3.281, nll_loss=1.51, ppl=2.85, wps=6047.1, ups=0.48, wpb=12669.5, bsz=355.9, num_updates=160, lr=1e-05, gnorm=0.732, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:41:03 | INFO | train_inner | epoch 004:     32 / 138 loss=3.322, nll_loss=1.554, ppl=2.94, wps=5931, ups=0.49, wpb=11993.8, bsz=312.4, num_updates=170, lr=1e-05, gnorm=0.756, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:41:24 | INFO | train_inner | epoch 004:     42 / 138 loss=3.302, nll_loss=1.533, ppl=2.89, wps=6047, ups=0.48, wpb=12639.5, bsz=363.2, num_updates=180, lr=1e-05, gnorm=0.684, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:41:45 | INFO | train_inner | epoch 004:     52 / 138 loss=3.249, nll_loss=1.475, ppl=2.78, wps=6036.4, ups=0.49, wpb=12346.5, bsz=355.8, num_updates=190, lr=1e-05, gnorm=0.692, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:42:05 | INFO | train_inner | epoch 004:     62 / 138 loss=3.276, nll_loss=1.503, ppl=2.83, wps=6137.9, ups=0.48, wpb=12723.6, bsz=362.4, num_updates=200, lr=1e-05, gnorm=0.716, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:42:11 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 3.225 | nll_loss 1.419 | ppl 2.67 | wps 14781.1 | wpb 1129.8 | bsz 29.7 | num_updates 200 | best_loss 3.225
2022-07-19 07:44:35 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_4_200.pt (epoch 4 @ 200 updates, score 3.225) (writing took 143.6435914253816 seconds)
2022-07-19 07:44:54 | INFO | train_inner | epoch 004:     72 / 138 loss=3.283, nll_loss=1.512, ppl=2.85, wps=741.9, ups=0.06, wpb=12550.3, bsz=350.4, num_updates=210, lr=1e-05, gnorm=0.674, loss_scale=None, train_wall=19, wall=0
2022-07-19 07:45:14 | INFO | train_inner | epoch 004:     82 / 138 loss=3.277, nll_loss=1.504, ppl=2.84, wps=6170.9, ups=0.5, wpb=12311.4, bsz=382.4, num_updates=220, lr=1e-05, gnorm=0.714, loss_scale=None, train_wall=19, wall=0
2022-07-19 07:45:34 | INFO | train_inner | epoch 004:     92 / 138 loss=3.289, nll_loss=1.517, ppl=2.86, wps=6080.3, ups=0.5, wpb=12246.6, bsz=350.4, num_updates=230, lr=1e-05, gnorm=0.703, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:45:55 | INFO | train_inner | epoch 004:    102 / 138 loss=3.342, nll_loss=1.58, ppl=2.99, wps=6091, ups=0.5, wpb=12257, bsz=356.9, num_updates=240, lr=1e-05, gnorm=0.814, loss_scale=None, train_wall=19, wall=0
2022-07-19 07:46:15 | INFO | train_inner | epoch 004:    112 / 138 loss=3.278, nll_loss=1.506, ppl=2.84, wps=6017.8, ups=0.48, wpb=12464.3, bsz=397.6, num_updates=250, lr=1e-05, gnorm=0.716, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:46:36 | INFO | train_inner | epoch 004:    122 / 138 loss=3.309, nll_loss=1.541, ppl=2.91, wps=6123.7, ups=0.48, wpb=12810, bsz=382.6, num_updates=260, lr=1e-05, gnorm=0.715, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:46:57 | INFO | train_inner | epoch 004:    132 / 138 loss=3.313, nll_loss=1.545, ppl=2.92, wps=6124, ups=0.49, wpb=12573.4, bsz=364, num_updates=270, lr=1e-05, gnorm=0.688, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:47:13 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 3.214 | nll_loss 1.408 | ppl 2.65 | wps 14868.7 | wpb 1129.8 | bsz 29.7 | num_updates 276 | best_loss 3.214
2022-07-19 07:47:13 | INFO | train | epoch 004 | loss 3.296 | nll_loss 1.526 | ppl 2.88 | wps 3919.3 | ups 0.32 | wpb 12385.4 | bsz 364.8 | num_updates 276 | lr 1e-05 | gnorm 0.722 | loss_scale None | train_wall 272 | wall 0
2022-07-19 07:47:21 | INFO | train_inner | epoch 005:      4 / 138 loss=3.322, nll_loss=1.556, ppl=2.94, wps=4536.2, ups=0.4, wpb=11205, bsz=368, num_updates=280, lr=1e-05, gnorm=0.782, loss_scale=None, train_wall=18, wall=0
2022-07-19 07:47:43 | INFO | train_inner | epoch 005:     14 / 138 loss=3.241, nll_loss=1.466, ppl=2.76, wps=6110.7, ups=0.47, wpb=12872.9, bsz=417.6, num_updates=290, lr=1e-05, gnorm=0.684, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:48:03 | INFO | train_inner | epoch 005:     24 / 138 loss=3.265, nll_loss=1.489, ppl=2.81, wps=6050.9, ups=0.49, wpb=12462.3, bsz=369.6, num_updates=300, lr=1e-05, gnorm=0.679, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:48:09 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 3.212 | nll_loss 1.404 | ppl 2.65 | wps 14800 | wpb 1129.8 | bsz 29.7 | num_updates 300 | best_loss 3.212
2022-07-19 07:50:33 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_5_300.pt (epoch 5 @ 300 updates, score 3.212) (writing took 143.69984802603722 seconds)
2022-07-19 07:50:52 | INFO | train_inner | epoch 005:     34 / 138 loss=3.246, nll_loss=1.468, ppl=2.77, wps=720.6, ups=0.06, wpb=12198.7, bsz=353.6, num_updates=310, lr=1e-05, gnorm=0.7, loss_scale=None, train_wall=19, wall=0
2022-07-19 07:51:12 | INFO | train_inner | epoch 005:     44 / 138 loss=3.288, nll_loss=1.517, ppl=2.86, wps=6168.4, ups=0.5, wpb=12307.9, bsz=341.6, num_updates=320, lr=1e-05, gnorm=0.722, loss_scale=None, train_wall=19, wall=0
2022-07-19 07:51:33 | INFO | train_inner | epoch 005:     54 / 138 loss=3.21, nll_loss=1.429, ppl=2.69, wps=6084, ups=0.48, wpb=12723.6, bsz=384.6, num_updates=330, lr=1e-05, gnorm=0.699, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:51:54 | INFO | train_inner | epoch 005:     64 / 138 loss=3.23, nll_loss=1.451, ppl=2.73, wps=6160.5, ups=0.49, wpb=12502.8, bsz=332.8, num_updates=340, lr=1e-05, gnorm=0.689, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:52:14 | INFO | train_inner | epoch 005:     74 / 138 loss=3.183, nll_loss=1.398, ppl=2.64, wps=6226.6, ups=0.49, wpb=12794.5, bsz=348.8, num_updates=350, lr=1e-05, gnorm=0.663, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:52:35 | INFO | train_inner | epoch 005:     84 / 138 loss=3.255, nll_loss=1.48, ppl=2.79, wps=5988.8, ups=0.48, wpb=12517.5, bsz=406.4, num_updates=360, lr=1e-05, gnorm=0.687, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:52:56 | INFO | train_inner | epoch 005:     94 / 138 loss=3.224, nll_loss=1.444, ppl=2.72, wps=6073.2, ups=0.48, wpb=12669.8, bsz=381.6, num_updates=370, lr=1e-05, gnorm=0.669, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:53:17 | INFO | train_inner | epoch 005:    104 / 138 loss=3.271, nll_loss=1.498, ppl=2.82, wps=5907, ups=0.48, wpb=12205.6, bsz=389.3, num_updates=380, lr=1e-05, gnorm=0.735, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:53:37 | INFO | train_inner | epoch 005:    114 / 138 loss=3.232, nll_loss=1.454, ppl=2.74, wps=5986.9, ups=0.48, wpb=12464.6, bsz=388, num_updates=390, lr=1e-05, gnorm=0.665, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:53:58 | INFO | train_inner | epoch 005:    124 / 138 loss=3.294, nll_loss=1.522, ppl=2.87, wps=5959.9, ups=0.5, wpb=12017.8, bsz=305.7, num_updates=400, lr=1e-05, gnorm=0.756, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:54:03 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 3.204 | nll_loss 1.395 | ppl 2.63 | wps 14858.4 | wpb 1129.8 | bsz 29.7 | num_updates 400 | best_loss 3.204
2022-07-19 07:56:32 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_5_400.pt (epoch 5 @ 400 updates, score 3.204) (writing took 148.95212675724179 seconds)
2022-07-19 07:56:52 | INFO | train_inner | epoch 005:    134 / 138 loss=3.237, nll_loss=1.459, ppl=2.75, wps=713.9, ups=0.06, wpb=12456.5, bsz=345.6, num_updates=410, lr=1e-05, gnorm=0.683, loss_scale=None, train_wall=19, wall=0
2022-07-19 07:57:06 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 3.203 | nll_loss 1.396 | ppl 2.63 | wps 15154.8 | wpb 1129.8 | bsz 29.7 | num_updates 414 | best_loss 3.203
2022-07-19 07:57:06 | INFO | train | epoch 005 | loss 3.246 | nll_loss 1.469 | ppl 2.77 | wps 2885.5 | ups 0.23 | wpb 12385.4 | bsz 364.8 | num_updates 414 | lr 1e-05 | gnorm 0.7 | loss_scale None | train_wall 272 | wall 0
2022-07-19 07:57:18 | INFO | train_inner | epoch 006:      6 / 138 loss=3.251, nll_loss=1.476, ppl=2.78, wps=4434.2, ups=0.38, wpb=11599.2, bsz=356, num_updates=420, lr=1e-05, gnorm=0.743, loss_scale=None, train_wall=18, wall=0
2022-07-19 07:57:38 | INFO | train_inner | epoch 006:     16 / 138 loss=3.231, nll_loss=1.451, ppl=2.73, wps=6112, ups=0.49, wpb=12393, bsz=320.1, num_updates=430, lr=1e-05, gnorm=0.713, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:57:59 | INFO | train_inner | epoch 006:     26 / 138 loss=3.214, nll_loss=1.433, ppl=2.7, wps=5935.8, ups=0.49, wpb=12022.1, bsz=406.6, num_updates=440, lr=1e-05, gnorm=0.718, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:58:19 | INFO | train_inner | epoch 006:     36 / 138 loss=3.178, nll_loss=1.391, ppl=2.62, wps=6129.3, ups=0.49, wpb=12561.7, bsz=351.2, num_updates=450, lr=1e-05, gnorm=0.645, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:58:40 | INFO | train_inner | epoch 006:     46 / 138 loss=3.234, nll_loss=1.455, ppl=2.74, wps=6129.8, ups=0.49, wpb=12543.4, bsz=356, num_updates=460, lr=1e-05, gnorm=0.694, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:59:00 | INFO | train_inner | epoch 006:     56 / 138 loss=3.215, nll_loss=1.434, ppl=2.7, wps=6024.8, ups=0.48, wpb=12440.8, bsz=373.2, num_updates=470, lr=1e-05, gnorm=0.723, loss_scale=None, train_wall=20, wall=0
2022-07-19 07:59:22 | INFO | train_inner | epoch 006:     66 / 138 loss=3.206, nll_loss=1.423, ppl=2.68, wps=5893.9, ups=0.47, wpb=12496.3, bsz=342.3, num_updates=480, lr=1e-05, gnorm=0.692, loss_scale=None, train_wall=21, wall=0
2022-07-19 07:59:42 | INFO | train_inner | epoch 006:     76 / 138 loss=3.181, nll_loss=1.396, ppl=2.63, wps=6012.7, ups=0.48, wpb=12518, bsz=354.4, num_updates=490, lr=1e-05, gnorm=0.71, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:00:03 | INFO | train_inner | epoch 006:     86 / 138 loss=3.178, nll_loss=1.394, ppl=2.63, wps=6046.8, ups=0.47, wpb=12753.9, bsz=435.2, num_updates=500, lr=1e-05, gnorm=0.644, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:00:09 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 3.201 | nll_loss 1.39 | ppl 2.62 | wps 14865 | wpb 1129.8 | bsz 29.7 | num_updates 500 | best_loss 3.201
2022-07-19 08:02:27 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_6_500.pt (epoch 6 @ 500 updates, score 3.201) (writing took 137.6724246116355 seconds)
2022-07-19 08:02:47 | INFO | train_inner | epoch 006:     96 / 138 loss=3.235, nll_loss=1.457, ppl=2.75, wps=778, ups=0.06, wpb=12724.2, bsz=405.6, num_updates=510, lr=1e-05, gnorm=0.671, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:03:07 | INFO | train_inner | epoch 006:    106 / 138 loss=3.226, nll_loss=1.447, ppl=2.73, wps=6197.4, ups=0.5, wpb=12305.6, bsz=344.8, num_updates=520, lr=1e-05, gnorm=0.673, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:03:27 | INFO | train_inner | epoch 006:    116 / 138 loss=3.192, nll_loss=1.409, ppl=2.65, wps=6080.2, ups=0.49, wpb=12303.3, bsz=363.8, num_updates=530, lr=1e-05, gnorm=0.717, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:03:47 | INFO | train_inner | epoch 006:    126 / 138 loss=3.189, nll_loss=1.406, ppl=2.65, wps=6025.2, ups=0.5, wpb=12152.3, bsz=341.6, num_updates=540, lr=1e-05, gnorm=0.672, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:04:08 | INFO | train_inner | epoch 006:    136 / 138 loss=3.213, nll_loss=1.43, ppl=2.69, wps=6061.7, ups=0.49, wpb=12422.7, bsz=362.4, num_updates=550, lr=1e-05, gnorm=0.671, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:04:16 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 3.197 | nll_loss 1.385 | ppl 2.61 | wps 14892.6 | wpb 1129.8 | bsz 29.7 | num_updates 552 | best_loss 3.197
2022-07-19 08:04:16 | INFO | train | epoch 006 | loss 3.208 | nll_loss 1.426 | ppl 2.69 | wps 3973.1 | ups 0.32 | wpb 12385.4 | bsz 364.8 | num_updates 552 | lr 1e-05 | gnorm 0.691 | loss_scale None | train_wall 272 | wall 0
2022-07-19 08:04:32 | INFO | train_inner | epoch 007:      8 / 138 loss=3.152, nll_loss=1.363, ppl=2.57, wps=4710.1, ups=0.41, wpb=11475, bsz=302.4, num_updates=560, lr=1e-05, gnorm=0.772, loss_scale=None, train_wall=18, wall=0
2022-07-19 08:04:53 | INFO | train_inner | epoch 007:     18 / 138 loss=3.197, nll_loss=1.415, ppl=2.67, wps=5994.7, ups=0.48, wpb=12511, bsz=344.8, num_updates=570, lr=1e-05, gnorm=0.667, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:05:14 | INFO | train_inner | epoch 007:     28 / 138 loss=3.177, nll_loss=1.392, ppl=2.62, wps=5908.5, ups=0.48, wpb=12404.2, bsz=444.8, num_updates=580, lr=1e-05, gnorm=0.657, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:05:35 | INFO | train_inner | epoch 007:     38 / 138 loss=3.195, nll_loss=1.408, ppl=2.65, wps=5934.7, ups=0.47, wpb=12501.4, bsz=381.6, num_updates=590, lr=1e-05, gnorm=0.653, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:05:55 | INFO | train_inner | epoch 007:     48 / 138 loss=3.172, nll_loss=1.385, ppl=2.61, wps=6074.6, ups=0.49, wpb=12386.9, bsz=343.2, num_updates=600, lr=1e-05, gnorm=0.668, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:06:01 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 3.197 | nll_loss 1.386 | ppl 2.61 | wps 14807.5 | wpb 1129.8 | bsz 29.7 | num_updates 600 | best_loss 3.197
2022-07-19 08:08:21 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_7_600.pt (epoch 7 @ 600 updates, score 3.197) (writing took 139.98662072326988 seconds)
2022-07-19 08:08:41 | INFO | train_inner | epoch 007:     58 / 138 loss=3.17, nll_loss=1.383, ppl=2.61, wps=763.1, ups=0.06, wpb=12631, bsz=340.8, num_updates=610, lr=1e-05, gnorm=0.65, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:09:02 | INFO | train_inner | epoch 007:     68 / 138 loss=3.119, nll_loss=1.326, ppl=2.51, wps=6051.2, ups=0.49, wpb=12454, bsz=424.7, num_updates=620, lr=1e-05, gnorm=0.668, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:09:21 | INFO | train_inner | epoch 007:     78 / 138 loss=3.19, nll_loss=1.405, ppl=2.65, wps=6092.7, ups=0.5, wpb=12091, bsz=289.7, num_updates=630, lr=1e-05, gnorm=0.717, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:09:42 | INFO | train_inner | epoch 007:     88 / 138 loss=3.216, nll_loss=1.435, ppl=2.7, wps=6080.4, ups=0.49, wpb=12391.4, bsz=401.4, num_updates=640, lr=1e-05, gnorm=0.73, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:10:02 | INFO | train_inner | epoch 007:     98 / 138 loss=3.172, nll_loss=1.385, ppl=2.61, wps=6176.3, ups=0.49, wpb=12690.3, bsz=348.8, num_updates=650, lr=1e-05, gnorm=0.644, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:10:23 | INFO | train_inner | epoch 007:    108 / 138 loss=3.161, nll_loss=1.372, ppl=2.59, wps=6078.6, ups=0.47, wpb=12837.1, bsz=405.6, num_updates=660, lr=1e-05, gnorm=0.647, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:10:45 | INFO | train_inner | epoch 007:    118 / 138 loss=3.183, nll_loss=1.397, ppl=2.63, wps=6068.5, ups=0.47, wpb=12884, bsz=367, num_updates=670, lr=1e-05, gnorm=0.663, loss_scale=None, train_wall=21, wall=0
2022-07-19 08:11:05 | INFO | train_inner | epoch 007:    128 / 138 loss=3.199, nll_loss=1.415, ppl=2.67, wps=5894.8, ups=0.49, wpb=12054.8, bsz=332.8, num_updates=680, lr=1e-05, gnorm=0.702, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:11:24 | INFO | train_inner | epoch 007:    138 / 138 loss=3.126, nll_loss=1.334, ppl=2.52, wps=5929.3, ups=0.53, wpb=11250.3, bsz=348.8, num_updates=690, lr=1e-05, gnorm=0.704, loss_scale=None, train_wall=18, wall=0
2022-07-19 08:11:30 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 3.194 | nll_loss 1.382 | ppl 2.61 | wps 14742.9 | wpb 1129.8 | bsz 29.7 | num_updates 690 | best_loss 3.194
2022-07-19 08:11:30 | INFO | train | epoch 007 | loss 3.174 | nll_loss 1.387 | ppl 2.62 | wps 3940.2 | ups 0.32 | wpb 12385.4 | bsz 364.8 | num_updates 690 | lr 1e-05 | gnorm 0.677 | loss_scale None | train_wall 273 | wall 0
2022-07-19 08:11:50 | INFO | train_inner | epoch 008:     10 / 138 loss=3.157, nll_loss=1.367, ppl=2.58, wps=4682.5, ups=0.38, wpb=12329.2, bsz=336, num_updates=700, lr=1e-05, gnorm=0.727, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:11:57 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 3.195 | nll_loss 1.382 | ppl 2.61 | wps 12204.1 | wpb 1129.8 | bsz 29.7 | num_updates 700 | best_loss 3.195
2022-07-19 08:14:04 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_8_700.pt (epoch 8 @ 700 updates, score 3.195) (writing took 126.23242836724967 seconds)
2022-07-19 08:14:23 | INFO | train_inner | epoch 008:     20 / 138 loss=3.135, nll_loss=1.342, ppl=2.54, wps=825.1, ups=0.07, wpb=12630.4, bsz=375.2, num_updates=710, lr=1e-05, gnorm=0.639, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:14:43 | INFO | train_inner | epoch 008:     30 / 138 loss=3.161, nll_loss=1.373, ppl=2.59, wps=6150.3, ups=0.5, wpb=12276, bsz=344, num_updates=720, lr=1e-05, gnorm=0.653, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:15:03 | INFO | train_inner | epoch 008:     40 / 138 loss=3.159, nll_loss=1.371, ppl=2.59, wps=6007.2, ups=0.5, wpb=12024.4, bsz=340.6, num_updates=730, lr=1e-05, gnorm=0.695, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:15:24 | INFO | train_inner | epoch 008:     50 / 138 loss=3.155, nll_loss=1.364, ppl=2.57, wps=5987.4, ups=0.48, wpb=12513.9, bsz=436, num_updates=740, lr=1e-05, gnorm=0.663, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:15:45 | INFO | train_inner | epoch 008:     60 / 138 loss=3.113, nll_loss=1.318, ppl=2.49, wps=6056, ups=0.48, wpb=12730.7, bsz=427.2, num_updates=750, lr=1e-05, gnorm=0.64, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:16:06 | INFO | train_inner | epoch 008:     70 / 138 loss=3.142, nll_loss=1.35, ppl=2.55, wps=6127.2, ups=0.49, wpb=12599.8, bsz=359.2, num_updates=760, lr=1e-05, gnorm=0.649, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:16:27 | INFO | train_inner | epoch 008:     80 / 138 loss=3.121, nll_loss=1.328, ppl=2.51, wps=6079, ups=0.47, wpb=12845.3, bsz=394.4, num_updates=770, lr=1e-05, gnorm=0.65, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:16:48 | INFO | train_inner | epoch 008:     90 / 138 loss=3.136, nll_loss=1.343, ppl=2.54, wps=6051.3, ups=0.49, wpb=12404.3, bsz=342, num_updates=780, lr=1e-05, gnorm=0.671, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:17:08 | INFO | train_inner | epoch 008:    100 / 138 loss=3.108, nll_loss=1.311, ppl=2.48, wps=6108.7, ups=0.48, wpb=12602.2, bsz=350.4, num_updates=790, lr=1e-05, gnorm=0.69, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:17:29 | INFO | train_inner | epoch 008:    110 / 138 loss=3.152, nll_loss=1.362, ppl=2.57, wps=6079.1, ups=0.48, wpb=12733.7, bsz=354.4, num_updates=800, lr=1e-05, gnorm=0.655, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:17:35 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 3.193 | nll_loss 1.381 | ppl 2.6 | wps 14815.5 | wpb 1129.8 | bsz 29.7 | num_updates 800 | best_loss 3.193
2022-07-19 08:20:20 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_8_800.pt (epoch 8 @ 800 updates, score 3.193) (writing took 164.88916368596256 seconds)
2022-07-19 08:20:40 | INFO | train_inner | epoch 008:    120 / 138 loss=3.202, nll_loss=1.42, ppl=2.68, wps=651.2, ups=0.05, wpb=12401.5, bsz=350.6, num_updates=810, lr=1e-05, gnorm=0.667, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:20:59 | INFO | train_inner | epoch 008:    130 / 138 loss=3.106, nll_loss=1.309, ppl=2.48, wps=6108.6, ups=0.51, wpb=12093.6, bsz=354.4, num_updates=820, lr=1e-05, gnorm=0.663, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:21:20 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 3.193 | nll_loss 1.381 | ppl 2.6 | wps 15032.2 | wpb 1129.8 | bsz 29.7 | num_updates 828 | best_loss 3.193
2022-07-19 08:21:20 | INFO | train | epoch 008 | loss 3.144 | nll_loss 1.353 | ppl 2.55 | wps 2897.3 | ups 0.23 | wpb 12385.4 | bsz 364.8 | num_updates 828 | lr 1e-05 | gnorm 0.672 | loss_scale None | train_wall 272 | wall 0
2022-07-19 08:21:24 | INFO | train_inner | epoch 009:      2 / 138 loss=3.148, nll_loss=1.358, ppl=2.56, wps=4634.1, ups=0.41, wpb=11397.6, bsz=374.4, num_updates=830, lr=1e-05, gnorm=0.74, loss_scale=None, train_wall=18, wall=0
2022-07-19 08:21:45 | INFO | train_inner | epoch 009:     12 / 138 loss=3.105, nll_loss=1.309, ppl=2.48, wps=6059.1, ups=0.49, wpb=12437.4, bsz=348.2, num_updates=840, lr=1e-05, gnorm=0.659, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:22:05 | INFO | train_inner | epoch 009:     22 / 138 loss=3.106, nll_loss=1.31, ppl=2.48, wps=6068.2, ups=0.49, wpb=12377.4, bsz=339.2, num_updates=850, lr=1e-05, gnorm=0.642, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:22:26 | INFO | train_inner | epoch 009:     32 / 138 loss=3.117, nll_loss=1.322, ppl=2.5, wps=6078.6, ups=0.48, wpb=12550, bsz=354.4, num_updates=860, lr=1e-05, gnorm=0.647, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:22:46 | INFO | train_inner | epoch 009:     42 / 138 loss=3.127, nll_loss=1.334, ppl=2.52, wps=6058.2, ups=0.49, wpb=12390.3, bsz=352, num_updates=870, lr=1e-05, gnorm=0.653, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:23:07 | INFO | train_inner | epoch 009:     52 / 138 loss=3.101, nll_loss=1.304, ppl=2.47, wps=6092.6, ups=0.48, wpb=12782.6, bsz=368.4, num_updates=880, lr=1e-05, gnorm=1.275, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:23:27 | INFO | train_inner | epoch 009:     62 / 138 loss=3.136, nll_loss=1.342, ppl=2.54, wps=6019.1, ups=0.49, wpb=12315.7, bsz=383.2, num_updates=890, lr=1e-05, gnorm=0.66, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:23:48 | INFO | train_inner | epoch 009:     72 / 138 loss=3.109, nll_loss=1.313, ppl=2.48, wps=6145.9, ups=0.48, wpb=12860.1, bsz=381.7, num_updates=900, lr=1e-05, gnorm=0.663, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:23:54 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 3.193 | nll_loss 1.381 | ppl 2.6 | wps 14761.4 | wpb 1129.8 | bsz 29.7 | num_updates 900 | best_loss 3.193
2022-07-19 08:25:58 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_9_900.pt (epoch 9 @ 900 updates, score 3.193) (writing took 123.61494686361402 seconds)
2022-07-19 08:26:17 | INFO | train_inner | epoch 009:     82 / 138 loss=3.133, nll_loss=1.34, ppl=2.53, wps=790.4, ups=0.07, wpb=11749.9, bsz=339.2, num_updates=910, lr=1e-05, gnorm=0.69, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:26:37 | INFO | train_inner | epoch 009:     92 / 138 loss=3.129, nll_loss=1.337, ppl=2.53, wps=6059.5, ups=0.51, wpb=11892.5, bsz=362.4, num_updates=920, lr=1e-05, gnorm=0.666, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:26:57 | INFO | train_inner | epoch 009:    102 / 138 loss=3.128, nll_loss=1.334, ppl=2.52, wps=6071.9, ups=0.49, wpb=12310.4, bsz=377.4, num_updates=930, lr=1e-05, gnorm=0.681, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:27:17 | INFO | train_inner | epoch 009:    112 / 138 loss=3.128, nll_loss=1.335, ppl=2.52, wps=5959.5, ups=0.5, wpb=11920.9, bsz=358.4, num_updates=940, lr=1e-05, gnorm=0.675, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:27:38 | INFO | train_inner | epoch 009:    122 / 138 loss=3.102, nll_loss=1.305, ppl=2.47, wps=6155.3, ups=0.47, wpb=12997.5, bsz=367.1, num_updates=950, lr=1e-05, gnorm=0.646, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:27:59 | INFO | train_inner | epoch 009:    132 / 138 loss=3.117, nll_loss=1.323, ppl=2.5, wps=6141.9, ups=0.47, wpb=12986.8, bsz=386.4, num_updates=960, lr=1e-05, gnorm=0.648, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:28:16 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 3.193 | nll_loss 1.377 | ppl 2.6 | wps 14910.5 | wpb 1129.8 | bsz 29.7 | num_updates 966 | best_loss 3.193
2022-07-19 08:28:16 | INFO | train | epoch 009 | loss 3.116 | nll_loss 1.321 | ppl 2.5 | wps 4107.5 | ups 0.33 | wpb 12385.4 | bsz 364.8 | num_updates 966 | lr 1e-05 | gnorm 0.707 | loss_scale None | train_wall 272 | wall 0
2022-07-19 08:28:24 | INFO | train_inner | epoch 010:      4 / 138 loss=3.092, nll_loss=1.293, ppl=2.45, wps=4751.6, ups=0.4, wpb=11862.7, bsz=359.2, num_updates=970, lr=1e-05, gnorm=0.683, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:28:44 | INFO | train_inner | epoch 010:     14 / 138 loss=3.084, nll_loss=1.285, ppl=2.44, wps=6071, ups=0.5, wpb=12122.1, bsz=328, num_updates=980, lr=1e-05, gnorm=0.655, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:29:05 | INFO | train_inner | epoch 010:     24 / 138 loss=3.08, nll_loss=1.28, ppl=2.43, wps=6018.4, ups=0.48, wpb=12531.7, bsz=382.4, num_updates=990, lr=1e-05, gnorm=0.637, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:29:25 | INFO | train_inner | epoch 010:     34 / 138 loss=3.136, nll_loss=1.344, ppl=2.54, wps=5916.5, ups=0.5, wpb=11896.5, bsz=318.2, num_updates=1000, lr=1e-05, gnorm=0.693, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:29:31 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 3.193 | nll_loss 1.378 | ppl 2.6 | wps 14851 | wpb 1129.8 | bsz 29.7 | num_updates 1000 | best_loss 3.193
2022-07-19 08:31:28 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_10_1000.pt (epoch 10 @ 1000 updates, score 3.193) (writing took 117.6422096695751 seconds)
2022-07-19 08:31:48 | INFO | train_inner | epoch 010:     44 / 138 loss=3.084, nll_loss=1.284, ppl=2.44, wps=865.2, ups=0.07, wpb=12394.6, bsz=346.4, num_updates=1010, lr=1e-05, gnorm=0.663, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:32:08 | INFO | train_inner | epoch 010:     54 / 138 loss=3.095, nll_loss=1.298, ppl=2.46, wps=6194.4, ups=0.5, wpb=12382, bsz=352.1, num_updates=1020, lr=1e-05, gnorm=0.687, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:32:29 | INFO | train_inner | epoch 010:     64 / 138 loss=3.095, nll_loss=1.296, ppl=2.46, wps=6123.2, ups=0.49, wpb=12545.2, bsz=388.8, num_updates=1030, lr=1e-05, gnorm=0.644, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:32:50 | INFO | train_inner | epoch 010:     74 / 138 loss=3.081, nll_loss=1.282, ppl=2.43, wps=6218.3, ups=0.47, wpb=13218.8, bsz=403.2, num_updates=1040, lr=1e-05, gnorm=0.61, loss_scale=None, train_wall=21, wall=0
2022-07-19 08:33:11 | INFO | train_inner | epoch 010:     84 / 138 loss=3.092, nll_loss=1.295, ppl=2.45, wps=6071.6, ups=0.48, wpb=12535.3, bsz=392.6, num_updates=1050, lr=1e-05, gnorm=0.701, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:33:31 | INFO | train_inner | epoch 010:     94 / 138 loss=3.053, nll_loss=1.249, ppl=2.38, wps=6133.9, ups=0.48, wpb=12712.5, bsz=378.4, num_updates=1060, lr=1e-05, gnorm=0.635, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:33:52 | INFO | train_inner | epoch 010:    104 / 138 loss=3.086, nll_loss=1.286, ppl=2.44, wps=6059.1, ups=0.49, wpb=12459.7, bsz=361.6, num_updates=1070, lr=1e-05, gnorm=0.64, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:34:12 | INFO | train_inner | epoch 010:    114 / 138 loss=3.104, nll_loss=1.307, ppl=2.47, wps=6078.9, ups=0.49, wpb=12440.3, bsz=344.8, num_updates=1080, lr=1e-05, gnorm=0.654, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:34:33 | INFO | train_inner | epoch 010:    124 / 138 loss=3.098, nll_loss=1.302, ppl=2.46, wps=5896.3, ups=0.49, wpb=12071.7, bsz=408, num_updates=1090, lr=1e-05, gnorm=0.67, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:34:54 | INFO | train_inner | epoch 010:    134 / 138 loss=3.106, nll_loss=1.31, ppl=2.48, wps=5855.2, ups=0.48, wpb=12284.7, bsz=378.3, num_updates=1100, lr=1e-05, gnorm=0.728, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:35:00 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 3.192 | nll_loss 1.379 | ppl 2.6 | wps 14819.4 | wpb 1129.8 | bsz 29.7 | num_updates 1100 | best_loss 3.192
2022-07-19 08:36:33 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_10_1100.pt (epoch 10 @ 1100 updates, score 3.192) (writing took 93.4507079385221 seconds)
2022-07-19 08:36:45 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 3.192 | nll_loss 1.378 | ppl 2.6 | wps 15334 | wpb 1129.8 | bsz 29.7 | num_updates 1104 | best_loss 3.192
2022-07-19 08:36:45 | INFO | train | epoch 010 | loss 3.091 | nll_loss 1.292 | ppl 2.45 | wps 3356.4 | ups 0.27 | wpb 12385.4 | bsz 364.8 | num_updates 1104 | lr 1e-05 | gnorm 0.665 | loss_scale None | train_wall 272 | wall 0
2022-07-19 08:36:57 | INFO | train_inner | epoch 011:      6 / 138 loss=3.054, nll_loss=1.25, ppl=2.38, wps=937.1, ups=0.08, wpb=11556.5, bsz=315.2, num_updates=1110, lr=1e-05, gnorm=0.684, loss_scale=None, train_wall=18, wall=0
2022-07-19 08:37:17 | INFO | train_inner | epoch 011:     16 / 138 loss=3.075, nll_loss=1.274, ppl=2.42, wps=6047.2, ups=0.5, wpb=12118.2, bsz=344, num_updates=1120, lr=1e-05, gnorm=0.655, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:37:38 | INFO | train_inner | epoch 011:     26 / 138 loss=3.069, nll_loss=1.267, ppl=2.41, wps=6137.2, ups=0.49, wpb=12495.9, bsz=336.6, num_updates=1130, lr=1e-05, gnorm=0.646, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:37:58 | INFO | train_inner | epoch 011:     36 / 138 loss=3.034, nll_loss=1.228, ppl=2.34, wps=6141.8, ups=0.48, wpb=12687.3, bsz=371.2, num_updates=1140, lr=1e-05, gnorm=0.613, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:38:19 | INFO | train_inner | epoch 011:     46 / 138 loss=3.055, nll_loss=1.253, ppl=2.38, wps=6045.3, ups=0.47, wpb=12759.9, bsz=444.8, num_updates=1150, lr=1e-05, gnorm=0.634, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:38:40 | INFO | train_inner | epoch 011:     56 / 138 loss=3.087, nll_loss=1.288, ppl=2.44, wps=5931.5, ups=0.48, wpb=12252, bsz=372.7, num_updates=1160, lr=1e-05, gnorm=0.682, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:39:01 | INFO | train_inner | epoch 011:     66 / 138 loss=3.05, nll_loss=1.247, ppl=2.37, wps=5992.7, ups=0.48, wpb=12465, bsz=404, num_updates=1170, lr=1e-05, gnorm=0.642, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:39:21 | INFO | train_inner | epoch 011:     76 / 138 loss=3.054, nll_loss=1.249, ppl=2.38, wps=5933.8, ups=0.49, wpb=12186.2, bsz=365.6, num_updates=1180, lr=1e-05, gnorm=0.643, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:39:42 | INFO | train_inner | epoch 011:     86 / 138 loss=3.048, nll_loss=1.245, ppl=2.37, wps=6081.9, ups=0.48, wpb=12644.4, bsz=388.8, num_updates=1190, lr=1e-05, gnorm=0.628, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:40:03 | INFO | train_inner | epoch 011:     96 / 138 loss=3.08, nll_loss=1.28, ppl=2.43, wps=5938.1, ups=0.48, wpb=12265.6, bsz=373.6, num_updates=1200, lr=1e-05, gnorm=0.652, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:40:09 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 3.194 | nll_loss 1.38 | ppl 2.6 | wps 14701.4 | wpb 1129.8 | bsz 29.7 | num_updates 1200 | best_loss 3.192
2022-07-19 08:41:09 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_11_1200.pt (epoch 11 @ 1200 updates, score 3.194) (writing took 60.28477890137583 seconds)
2022-07-19 08:41:29 | INFO | train_inner | epoch 011:    106 / 138 loss=3.048, nll_loss=1.244, ppl=2.37, wps=1490.2, ups=0.12, wpb=12878.8, bsz=354, num_updates=1210, lr=1e-05, gnorm=0.642, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:41:49 | INFO | train_inner | epoch 011:    116 / 138 loss=3.095, nll_loss=1.296, ppl=2.46, wps=6108.2, ups=0.5, wpb=12138.5, bsz=306.4, num_updates=1220, lr=1e-05, gnorm=0.667, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:42:10 | INFO | train_inner | epoch 011:    126 / 138 loss=3.049, nll_loss=1.245, ppl=2.37, wps=6149, ups=0.49, wpb=12617, bsz=353, num_updates=1230, lr=1e-05, gnorm=0.653, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:42:30 | INFO | train_inner | epoch 011:    136 / 138 loss=3.113, nll_loss=1.317, ppl=2.49, wps=6067.6, ups=0.49, wpb=12483.4, bsz=356.1, num_updates=1240, lr=1e-05, gnorm=0.684, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:42:39 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 3.195 | nll_loss 1.381 | ppl 2.6 | wps 14846.6 | wpb 1129.8 | bsz 29.7 | num_updates 1242 | best_loss 3.192
2022-07-19 08:42:39 | INFO | train | epoch 011 | loss 3.066 | nll_loss 1.265 | ppl 2.4 | wps 4835.1 | ups 0.39 | wpb 12385.4 | bsz 364.8 | num_updates 1242 | lr 1e-05 | gnorm 0.653 | loss_scale None | train_wall 273 | wall 0
2022-07-19 08:42:55 | INFO | train_inner | epoch 012:      8 / 138 loss=3.052, nll_loss=1.248, ppl=2.38, wps=4622.8, ups=0.4, wpb=11532.4, bsz=320.8, num_updates=1250, lr=1e-05, gnorm=0.699, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:43:16 | INFO | train_inner | epoch 012:     18 / 138 loss=3.058, nll_loss=1.254, ppl=2.38, wps=5824.5, ups=0.49, wpb=11868.2, bsz=351.2, num_updates=1260, lr=1e-05, gnorm=0.66, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:43:37 | INFO | train_inner | epoch 012:     28 / 138 loss=3.056, nll_loss=1.255, ppl=2.39, wps=5989.7, ups=0.47, wpb=12635.2, bsz=387.2, num_updates=1270, lr=1e-05, gnorm=0.663, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:43:58 | INFO | train_inner | epoch 012:     38 / 138 loss=3.053, nll_loss=1.249, ppl=2.38, wps=6088.3, ups=0.47, wpb=12852.8, bsz=366.4, num_updates=1280, lr=1e-05, gnorm=0.628, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:44:19 | INFO | train_inner | epoch 012:     48 / 138 loss=3.059, nll_loss=1.256, ppl=2.39, wps=5988, ups=0.48, wpb=12481.6, bsz=384, num_updates=1290, lr=1e-05, gnorm=0.643, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:44:39 | INFO | train_inner | epoch 012:     58 / 138 loss=3.014, nll_loss=1.207, ppl=2.31, wps=6151.6, ups=0.48, wpb=12779.5, bsz=354.4, num_updates=1300, lr=1e-05, gnorm=0.611, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:44:45 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 3.196 | nll_loss 1.38 | ppl 2.6 | wps 14764.3 | wpb 1129.8 | bsz 29.7 | num_updates 1300 | best_loss 3.192
2022-07-19 08:45:46 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_12_1300.pt (epoch 12 @ 1300 updates, score 3.196) (writing took 60.48599012941122 seconds)
2022-07-19 08:46:05 | INFO | train_inner | epoch 012:     68 / 138 loss=3.052, nll_loss=1.247, ppl=2.37, wps=1433, ups=0.12, wpb=12335, bsz=350, num_updates=1310, lr=1e-05, gnorm=0.648, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:46:26 | INFO | train_inner | epoch 012:     78 / 138 loss=3.024, nll_loss=1.217, ppl=2.33, wps=6084.9, ups=0.5, wpb=12246.7, bsz=387.2, num_updates=1320, lr=1e-05, gnorm=0.629, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:46:46 | INFO | train_inner | epoch 012:     88 / 138 loss=3.032, nll_loss=1.225, ppl=2.34, wps=6091.2, ups=0.49, wpb=12389, bsz=336.8, num_updates=1330, lr=1e-05, gnorm=0.639, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:47:07 | INFO | train_inner | epoch 012:     98 / 138 loss=3.045, nll_loss=1.24, ppl=2.36, wps=6111.3, ups=0.48, wpb=12821.1, bsz=376, num_updates=1340, lr=1e-05, gnorm=0.627, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:47:27 | INFO | train_inner | epoch 012:    108 / 138 loss=3.056, nll_loss=1.254, ppl=2.38, wps=5995.2, ups=0.49, wpb=12172.7, bsz=396, num_updates=1350, lr=1e-05, gnorm=0.674, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:47:48 | INFO | train_inner | epoch 012:    118 / 138 loss=3.048, nll_loss=1.244, ppl=2.37, wps=6098.9, ups=0.48, wpb=12769.8, bsz=383.2, num_updates=1360, lr=1e-05, gnorm=0.659, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:48:09 | INFO | train_inner | epoch 012:    128 / 138 loss=3.047, nll_loss=1.242, ppl=2.37, wps=5886, ups=0.49, wpb=12122.1, bsz=328.8, num_updates=1370, lr=1e-05, gnorm=0.694, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:48:28 | INFO | train_inner | epoch 012:    138 / 138 loss=3.041, nll_loss=1.235, ppl=2.35, wps=5945.6, ups=0.52, wpb=11422.8, bsz=363.2, num_updates=1380, lr=1e-05, gnorm=0.677, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:48:34 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 3.197 | nll_loss 1.382 | ppl 2.61 | wps 14766.5 | wpb 1129.8 | bsz 29.7 | num_updates 1380 | best_loss 3.192
2022-07-19 08:48:34 | INFO | train | epoch 012 | loss 3.044 | nll_loss 1.239 | ppl 2.36 | wps 4813.2 | ups 0.39 | wpb 12385.4 | bsz 364.8 | num_updates 1380 | lr 1e-05 | gnorm 0.648 | loss_scale None | train_wall 274 | wall 0
2022-07-19 08:48:54 | INFO | train_inner | epoch 013:     10 / 138 loss=2.991, nll_loss=1.178, ppl=2.26, wps=4746, ups=0.38, wpb=12561.7, bsz=369.6, num_updates=1390, lr=1e-05, gnorm=0.626, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:49:15 | INFO | train_inner | epoch 013:     20 / 138 loss=3.081, nll_loss=1.28, ppl=2.43, wps=5741.4, ups=0.48, wpb=12059.4, bsz=399.3, num_updates=1400, lr=1e-05, gnorm=0.681, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:49:21 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 3.199 | nll_loss 1.385 | ppl 2.61 | wps 14750.4 | wpb 1129.8 | bsz 29.7 | num_updates 1400 | best_loss 3.192
2022-07-19 08:50:22 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_13_1400.pt (epoch 13 @ 1400 updates, score 3.199) (writing took 60.573033321648836 seconds)
2022-07-19 08:50:42 | INFO | train_inner | epoch 013:     30 / 138 loss=3.021, nll_loss=1.213, ppl=2.32, wps=1437.9, ups=0.12, wpb=12397.6, bsz=340, num_updates=1410, lr=1e-05, gnorm=0.633, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:51:02 | INFO | train_inner | epoch 013:     40 / 138 loss=3.005, nll_loss=1.195, ppl=2.29, wps=6107.2, ups=0.49, wpb=12357.8, bsz=392.8, num_updates=1420, lr=1e-05, gnorm=0.633, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:51:22 | INFO | train_inner | epoch 013:     50 / 138 loss=2.986, nll_loss=1.173, ppl=2.26, wps=6059.1, ups=0.49, wpb=12452.8, bsz=353.6, num_updates=1430, lr=1e-05, gnorm=0.625, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:51:43 | INFO | train_inner | epoch 013:     60 / 138 loss=3.004, nll_loss=1.193, ppl=2.29, wps=6072.5, ups=0.48, wpb=12636.6, bsz=346.3, num_updates=1440, lr=1e-05, gnorm=0.636, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:52:04 | INFO | train_inner | epoch 013:     70 / 138 loss=3.046, nll_loss=1.24, ppl=2.36, wps=6061.4, ups=0.48, wpb=12696.3, bsz=381.6, num_updates=1450, lr=1e-05, gnorm=0.628, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:52:25 | INFO | train_inner | epoch 013:     80 / 138 loss=3.028, nll_loss=1.222, ppl=2.33, wps=5965.7, ups=0.49, wpb=12200.5, bsz=398.4, num_updates=1460, lr=1e-05, gnorm=0.646, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:52:45 | INFO | train_inner | epoch 013:     90 / 138 loss=3.041, nll_loss=1.236, ppl=2.35, wps=6014, ups=0.48, wpb=12494.3, bsz=324, num_updates=1470, lr=1e-05, gnorm=0.685, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:53:06 | INFO | train_inner | epoch 013:    100 / 138 loss=3.017, nll_loss=1.209, ppl=2.31, wps=6093.2, ups=0.48, wpb=12806.9, bsz=346.4, num_updates=1480, lr=1e-05, gnorm=0.61, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:53:27 | INFO | train_inner | epoch 013:    110 / 138 loss=3.044, nll_loss=1.239, ppl=2.36, wps=5920.1, ups=0.49, wpb=12193.5, bsz=355.2, num_updates=1490, lr=1e-05, gnorm=0.654, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:53:48 | INFO | train_inner | epoch 013:    120 / 138 loss=3.014, nll_loss=1.205, ppl=2.31, wps=6049.3, ups=0.47, wpb=12926.7, bsz=358.4, num_updates=1500, lr=1e-05, gnorm=0.627, loss_scale=None, train_wall=21, wall=0
2022-07-19 08:53:54 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 3.199 | nll_loss 1.385 | ppl 2.61 | wps 14706.3 | wpb 1129.8 | bsz 29.7 | num_updates 1500 | best_loss 3.192
2022-07-19 08:54:54 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_13_1500.pt (epoch 13 @ 1500 updates, score 3.199) (writing took 59.705477422103286 seconds)
2022-07-19 08:55:13 | INFO | train_inner | epoch 013:    130 / 138 loss=3.018, nll_loss=1.209, ppl=2.31, wps=1400.1, ups=0.12, wpb=11876.9, bsz=358.4, num_updates=1510, lr=1e-05, gnorm=0.641, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:55:34 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 3.2 | nll_loss 1.386 | ppl 2.61 | wps 14966.3 | wpb 1129.8 | bsz 29.7 | num_updates 1518 | best_loss 3.192
2022-07-19 08:55:34 | INFO | train | epoch 013 | loss 3.023 | nll_loss 1.215 | ppl 2.32 | wps 4066.3 | ups 0.33 | wpb 12385.4 | bsz 364.8 | num_updates 1518 | lr 1e-05 | gnorm 0.647 | loss_scale None | train_wall 274 | wall 0
2022-07-19 08:55:38 | INFO | train_inner | epoch 014:      2 / 138 loss=3.017, nll_loss=1.208, ppl=2.31, wps=4733.5, ups=0.4, wpb=11846, bsz=397.2, num_updates=1520, lr=1e-05, gnorm=0.739, loss_scale=None, train_wall=19, wall=0
2022-07-19 08:55:59 | INFO | train_inner | epoch 014:     12 / 138 loss=3.019, nll_loss=1.211, ppl=2.32, wps=5977.4, ups=0.48, wpb=12433.9, bsz=357.6, num_updates=1530, lr=1e-05, gnorm=0.622, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:56:20 | INFO | train_inner | epoch 014:     22 / 138 loss=2.982, nll_loss=1.169, ppl=2.25, wps=6076.4, ups=0.49, wpb=12500.8, bsz=372.8, num_updates=1540, lr=1e-05, gnorm=0.613, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:56:40 | INFO | train_inner | epoch 014:     32 / 138 loss=3.052, nll_loss=1.246, ppl=2.37, wps=5954.6, ups=0.49, wpb=12229.3, bsz=369.3, num_updates=1550, lr=1e-05, gnorm=0.681, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:57:01 | INFO | train_inner | epoch 014:     42 / 138 loss=2.988, nll_loss=1.176, ppl=2.26, wps=5950.8, ups=0.49, wpb=12226.7, bsz=324, num_updates=1560, lr=1e-05, gnorm=0.649, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:57:22 | INFO | train_inner | epoch 014:     52 / 138 loss=3, nll_loss=1.189, ppl=2.28, wps=5965.2, ups=0.48, wpb=12490.6, bsz=359.2, num_updates=1570, lr=1e-05, gnorm=0.656, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:57:42 | INFO | train_inner | epoch 014:     62 / 138 loss=3.015, nll_loss=1.205, ppl=2.31, wps=5910.9, ups=0.48, wpb=12227.3, bsz=340.8, num_updates=1580, lr=1e-05, gnorm=0.65, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:58:03 | INFO | train_inner | epoch 014:     72 / 138 loss=2.981, nll_loss=1.168, ppl=2.25, wps=6078.4, ups=0.49, wpb=12477.7, bsz=338.4, num_updates=1590, lr=1e-05, gnorm=0.612, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:58:24 | INFO | train_inner | epoch 014:     82 / 138 loss=2.984, nll_loss=1.171, ppl=2.25, wps=6004.3, ups=0.48, wpb=12622.5, bsz=448.8, num_updates=1600, lr=1e-05, gnorm=0.623, loss_scale=None, train_wall=20, wall=0
2022-07-19 08:58:30 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 3.202 | nll_loss 1.388 | ppl 2.62 | wps 14644.9 | wpb 1129.8 | bsz 29.7 | num_updates 1600 | best_loss 3.192
2022-07-19 08:59:30 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_14_1600.pt (epoch 14 @ 1600 updates, score 3.202) (writing took 60.74765073880553 seconds)
2022-07-19 08:59:51 | INFO | train_inner | epoch 014:     92 / 138 loss=3.024, nll_loss=1.217, ppl=2.32, wps=1457, ups=0.12, wpb=12656.2, bsz=348.7, num_updates=1610, lr=1e-05, gnorm=0.632, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:00:11 | INFO | train_inner | epoch 014:    102 / 138 loss=3.011, nll_loss=1.202, ppl=2.3, wps=6020.6, ups=0.49, wpb=12313.6, bsz=402.2, num_updates=1620, lr=1e-05, gnorm=0.662, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:00:32 | INFO | train_inner | epoch 014:    112 / 138 loss=3.016, nll_loss=1.207, ppl=2.31, wps=6037.3, ups=0.49, wpb=12303.5, bsz=358.6, num_updates=1630, lr=1e-05, gnorm=0.661, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:00:52 | INFO | train_inner | epoch 014:    122 / 138 loss=3.007, nll_loss=1.196, ppl=2.29, wps=6099, ups=0.5, wpb=12307.2, bsz=333.6, num_updates=1640, lr=1e-05, gnorm=0.626, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:01:13 | INFO | train_inner | epoch 014:    132 / 138 loss=2.976, nll_loss=1.162, ppl=2.24, wps=6127.8, ups=0.47, wpb=12939.7, bsz=372, num_updates=1650, lr=1e-05, gnorm=0.61, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:01:30 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 3.204 | nll_loss 1.389 | ppl 2.62 | wps 14777.4 | wpb 1129.8 | bsz 29.7 | num_updates 1656 | best_loss 3.192
2022-07-19 09:01:30 | INFO | train | epoch 014 | loss 3.002 | nll_loss 1.192 | ppl 2.28 | wps 4803.7 | ups 0.39 | wpb 12385.4 | bsz 364.8 | num_updates 1656 | lr 1e-05 | gnorm 0.642 | loss_scale None | train_wall 275 | wall 0
2022-07-19 09:01:38 | INFO | train_inner | epoch 015:      4 / 138 loss=2.955, nll_loss=1.139, ppl=2.2, wps=4578, ups=0.39, wpb=11608, bsz=392, num_updates=1660, lr=1e-05, gnorm=0.669, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:01:59 | INFO | train_inner | epoch 015:     14 / 138 loss=2.99, nll_loss=1.177, ppl=2.26, wps=6084.3, ups=0.48, wpb=12640.9, bsz=324, num_updates=1670, lr=1e-05, gnorm=0.622, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:02:20 | INFO | train_inner | epoch 015:     24 / 138 loss=2.992, nll_loss=1.179, ppl=2.26, wps=6023.2, ups=0.48, wpb=12448.2, bsz=394.4, num_updates=1680, lr=1e-05, gnorm=0.619, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:02:41 | INFO | train_inner | epoch 015:     34 / 138 loss=2.938, nll_loss=1.119, ppl=2.17, wps=5986.4, ups=0.48, wpb=12462.7, bsz=336.8, num_updates=1690, lr=1e-05, gnorm=0.617, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:03:01 | INFO | train_inner | epoch 015:     44 / 138 loss=2.985, nll_loss=1.172, ppl=2.25, wps=5899.5, ups=0.49, wpb=12154.3, bsz=351.6, num_updates=1700, lr=1e-05, gnorm=0.652, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:03:07 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 3.206 | nll_loss 1.39 | ppl 2.62 | wps 14751 | wpb 1129.8 | bsz 29.7 | num_updates 1700 | best_loss 3.192
2022-07-19 09:04:07 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_15_1700.pt (epoch 15 @ 1700 updates, score 3.206) (writing took 60.113319925032556 seconds)
2022-07-19 09:04:27 | INFO | train_inner | epoch 015:     54 / 138 loss=2.987, nll_loss=1.173, ppl=2.26, wps=1426, ups=0.12, wpb=12253.2, bsz=435.2, num_updates=1710, lr=1e-05, gnorm=0.636, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:04:47 | INFO | train_inner | epoch 015:     64 / 138 loss=3.007, nll_loss=1.196, ppl=2.29, wps=6185.8, ups=0.49, wpb=12581.3, bsz=314.2, num_updates=1720, lr=1e-05, gnorm=0.645, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:05:08 | INFO | train_inner | epoch 015:     74 / 138 loss=2.978, nll_loss=1.165, ppl=2.24, wps=6157.6, ups=0.48, wpb=12814.9, bsz=438.4, num_updates=1730, lr=1e-05, gnorm=0.615, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:05:28 | INFO | train_inner | epoch 015:     84 / 138 loss=2.947, nll_loss=1.129, ppl=2.19, wps=6067.9, ups=0.5, wpb=12168.2, bsz=320.8, num_updates=1740, lr=1e-05, gnorm=0.612, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:05:49 | INFO | train_inner | epoch 015:     94 / 138 loss=2.977, nll_loss=1.163, ppl=2.24, wps=6039.4, ups=0.47, wpb=12723.7, bsz=353.6, num_updates=1750, lr=1e-05, gnorm=0.621, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:06:10 | INFO | train_inner | epoch 015:    104 / 138 loss=2.956, nll_loss=1.139, ppl=2.2, wps=5973.4, ups=0.49, wpb=12137.9, bsz=362.4, num_updates=1760, lr=1e-05, gnorm=0.634, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:06:30 | INFO | train_inner | epoch 015:    114 / 138 loss=3.023, nll_loss=1.214, ppl=2.32, wps=5949.2, ups=0.48, wpb=12356.9, bsz=368.7, num_updates=1770, lr=1e-05, gnorm=0.661, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:06:52 | INFO | train_inner | epoch 015:    124 / 138 loss=2.999, nll_loss=1.189, ppl=2.28, wps=5995.2, ups=0.47, wpb=12680, bsz=389.7, num_updates=1780, lr=1e-05, gnorm=0.648, loss_scale=None, train_wall=21, wall=0
2022-07-19 09:07:13 | INFO | train_inner | epoch 015:    134 / 138 loss=2.985, nll_loss=1.172, ppl=2.25, wps=5975.6, ups=0.48, wpb=12519.2, bsz=341, num_updates=1790, lr=1e-05, gnorm=0.65, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:07:25 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 3.207 | nll_loss 1.391 | ppl 2.62 | wps 14757.7 | wpb 1129.8 | bsz 29.7 | num_updates 1794 | best_loss 3.192
2022-07-19 09:07:25 | INFO | train | epoch 015 | loss 2.983 | nll_loss 1.169 | ppl 2.25 | wps 4810.9 | ups 0.39 | wpb 12385.4 | bsz 364.8 | num_updates 1794 | lr 1e-05 | gnorm 0.637 | loss_scale None | train_wall 275 | wall 0
2022-07-19 09:07:37 | INFO | train_inner | epoch 016:      6 / 138 loss=2.993, nll_loss=1.18, ppl=2.27, wps=4514.1, ups=0.4, wpb=11248.9, bsz=316, num_updates=1800, lr=1e-05, gnorm=0.684, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:07:43 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 3.207 | nll_loss 1.392 | ppl 2.62 | wps 14747.8 | wpb 1129.8 | bsz 29.7 | num_updates 1800 | best_loss 3.192
2022-07-19 09:08:44 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_16_1800.pt (epoch 16 @ 1800 updates, score 3.207) (writing took 60.42521048989147 seconds)
2022-07-19 09:09:04 | INFO | train_inner | epoch 016:     16 / 138 loss=2.964, nll_loss=1.148, ppl=2.22, wps=1458.2, ups=0.12, wpb=12612.4, bsz=404, num_updates=1810, lr=1e-05, gnorm=0.622, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:09:24 | INFO | train_inner | epoch 016:     26 / 138 loss=2.952, nll_loss=1.134, ppl=2.19, wps=6164.9, ups=0.49, wpb=12483, bsz=355.2, num_updates=1820, lr=1e-05, gnorm=0.614, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:09:45 | INFO | train_inner | epoch 016:     36 / 138 loss=2.951, nll_loss=1.133, ppl=2.19, wps=6084.7, ups=0.49, wpb=12394.1, bsz=322.4, num_updates=1830, lr=1e-05, gnorm=0.618, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:10:05 | INFO | train_inner | epoch 016:     46 / 138 loss=2.997, nll_loss=1.185, ppl=2.27, wps=6044.4, ups=0.48, wpb=12607.3, bsz=375.3, num_updates=1840, lr=1e-05, gnorm=0.674, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:10:26 | INFO | train_inner | epoch 016:     56 / 138 loss=2.977, nll_loss=1.162, ppl=2.24, wps=6049.1, ups=0.49, wpb=12327.8, bsz=321, num_updates=1850, lr=1e-05, gnorm=0.635, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:10:47 | INFO | train_inner | epoch 016:     66 / 138 loss=2.943, nll_loss=1.125, ppl=2.18, wps=5937.4, ups=0.48, wpb=12493.8, bsz=418.4, num_updates=1860, lr=1e-05, gnorm=0.616, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:11:08 | INFO | train_inner | epoch 016:     76 / 138 loss=2.953, nll_loss=1.135, ppl=2.2, wps=5994.7, ups=0.48, wpb=12529.5, bsz=349.6, num_updates=1870, lr=1e-05, gnorm=0.615, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:11:28 | INFO | train_inner | epoch 016:     86 / 138 loss=2.988, nll_loss=1.175, ppl=2.26, wps=5851.6, ups=0.5, wpb=11815.3, bsz=390.8, num_updates=1880, lr=1e-05, gnorm=0.675, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:11:49 | INFO | train_inner | epoch 016:     96 / 138 loss=2.958, nll_loss=1.141, ppl=2.21, wps=6108.8, ups=0.47, wpb=13057, bsz=364.7, num_updates=1890, lr=1e-05, gnorm=0.614, loss_scale=None, train_wall=21, wall=0
2022-07-19 09:12:10 | INFO | train_inner | epoch 016:    106 / 138 loss=2.981, nll_loss=1.168, ppl=2.25, wps=6094.1, ups=0.47, wpb=12909.1, bsz=358.2, num_updates=1900, lr=1e-05, gnorm=0.641, loss_scale=None, train_wall=21, wall=0
2022-07-19 09:12:16 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 3.211 | nll_loss 1.395 | ppl 2.63 | wps 14735.7 | wpb 1129.8 | bsz 29.7 | num_updates 1900 | best_loss 3.192
2022-07-19 09:13:17 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_16_1900.pt (epoch 16 @ 1900 updates, score 3.211) (writing took 60.93405816145241 seconds)
2022-07-19 09:13:37 | INFO | train_inner | epoch 016:    116 / 138 loss=2.961, nll_loss=1.143, ppl=2.21, wps=1394, ups=0.12, wpb=12059.3, bsz=396.8, num_updates=1910, lr=1e-05, gnorm=0.643, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:13:58 | INFO | train_inner | epoch 016:    126 / 138 loss=2.941, nll_loss=1.123, ppl=2.18, wps=6075.6, ups=0.49, wpb=12501.4, bsz=405.6, num_updates=1920, lr=1e-05, gnorm=0.617, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:14:18 | INFO | train_inner | epoch 016:    136 / 138 loss=2.973, nll_loss=1.158, ppl=2.23, wps=6055.2, ups=0.49, wpb=12404.7, bsz=354.4, num_updates=1930, lr=1e-05, gnorm=0.636, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:14:26 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 3.212 | nll_loss 1.398 | ppl 2.64 | wps 14890.4 | wpb 1129.8 | bsz 29.7 | num_updates 1932 | best_loss 3.192
2022-07-19 09:14:26 | INFO | train | epoch 016 | loss 2.965 | nll_loss 1.148 | ppl 2.22 | wps 4058.8 | ups 0.33 | wpb 12385.4 | bsz 364.8 | num_updates 1932 | lr 1e-05 | gnorm 0.638 | loss_scale None | train_wall 274 | wall 0
2022-07-19 09:14:43 | INFO | train_inner | epoch 017:      8 / 138 loss=2.951, nll_loss=1.133, ppl=2.19, wps=4641.5, ups=0.4, wpb=11489.1, bsz=330.4, num_updates=1940, lr=1e-05, gnorm=0.701, loss_scale=None, train_wall=18, wall=0
2022-07-19 09:15:03 | INFO | train_inner | epoch 017:     18 / 138 loss=2.97, nll_loss=1.153, ppl=2.22, wps=6138.7, ups=0.49, wpb=12411.6, bsz=334.4, num_updates=1950, lr=1e-05, gnorm=0.633, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:15:24 | INFO | train_inner | epoch 017:     28 / 138 loss=2.92, nll_loss=1.098, ppl=2.14, wps=5976.1, ups=0.48, wpb=12380.8, bsz=388, num_updates=1960, lr=1e-05, gnorm=0.61, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:15:45 | INFO | train_inner | epoch 017:     38 / 138 loss=2.94, nll_loss=1.12, ppl=2.17, wps=5892.9, ups=0.48, wpb=12346.6, bsz=400, num_updates=1970, lr=1e-05, gnorm=0.616, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:16:05 | INFO | train_inner | epoch 017:     48 / 138 loss=2.881, nll_loss=1.055, ppl=2.08, wps=6085.7, ups=0.48, wpb=12624.2, bsz=396, num_updates=1980, lr=1e-05, gnorm=0.597, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:16:26 | INFO | train_inner | epoch 017:     58 / 138 loss=2.93, nll_loss=1.11, ppl=2.16, wps=6077, ups=0.48, wpb=12721.8, bsz=398.4, num_updates=1990, lr=1e-05, gnorm=0.616, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:16:47 | INFO | train_inner | epoch 017:     68 / 138 loss=2.931, nll_loss=1.11, ppl=2.16, wps=5865.1, ups=0.49, wpb=11897.3, bsz=319.9, num_updates=2000, lr=1e-05, gnorm=0.647, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:16:52 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 3.216 | nll_loss 1.401 | ppl 2.64 | wps 14752.1 | wpb 1129.8 | bsz 29.7 | num_updates 2000 | best_loss 3.192
2022-07-19 09:17:53 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_17_2000.pt (epoch 17 @ 2000 updates, score 3.216) (writing took 60.39476192649454 seconds)
2022-07-19 09:18:13 | INFO | train_inner | epoch 017:     78 / 138 loss=2.985, nll_loss=1.171, ppl=2.25, wps=1404.6, ups=0.12, wpb=12079, bsz=360.8, num_updates=2010, lr=1e-05, gnorm=0.655, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:18:33 | INFO | train_inner | epoch 017:     88 / 138 loss=2.954, nll_loss=1.136, ppl=2.2, wps=6169.7, ups=0.49, wpb=12647.7, bsz=360.8, num_updates=2020, lr=1e-05, gnorm=0.613, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:18:54 | INFO | train_inner | epoch 017:     98 / 138 loss=2.936, nll_loss=1.117, ppl=2.17, wps=6192.4, ups=0.49, wpb=12729, bsz=384.8, num_updates=2030, lr=1e-05, gnorm=0.61, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:19:15 | INFO | train_inner | epoch 017:    108 / 138 loss=2.98, nll_loss=1.165, ppl=2.24, wps=6088.5, ups=0.48, wpb=12654.1, bsz=370, num_updates=2040, lr=1e-05, gnorm=0.658, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:19:36 | INFO | train_inner | epoch 017:    118 / 138 loss=2.93, nll_loss=1.11, ppl=2.16, wps=6051.9, ups=0.48, wpb=12709.2, bsz=333.6, num_updates=2050, lr=1e-05, gnorm=0.631, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:19:56 | INFO | train_inner | epoch 017:    128 / 138 loss=2.988, nll_loss=1.174, ppl=2.26, wps=5971.6, ups=0.49, wpb=12282.3, bsz=382.3, num_updates=2060, lr=1e-05, gnorm=0.701, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:20:15 | INFO | train_inner | epoch 017:    138 / 138 loss=2.955, nll_loss=1.138, ppl=2.2, wps=5916.4, ups=0.52, wpb=11387.8, bsz=308.2, num_updates=2070, lr=1e-05, gnorm=0.721, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:20:21 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 3.216 | nll_loss 1.401 | ppl 2.64 | wps 14772.1 | wpb 1129.8 | bsz 29.7 | num_updates 2070 | best_loss 3.192
2022-07-19 09:20:21 | INFO | train | epoch 017 | loss 2.946 | nll_loss 1.127 | ppl 2.18 | wps 4816.5 | ups 0.39 | wpb 12385.4 | bsz 364.8 | num_updates 2070 | lr 1e-05 | gnorm 0.638 | loss_scale None | train_wall 274 | wall 0
2022-07-19 09:20:42 | INFO | train_inner | epoch 018:     10 / 138 loss=2.96, nll_loss=1.143, ppl=2.21, wps=4690.8, ups=0.38, wpb=12321.1, bsz=315.9, num_updates=2080, lr=1e-05, gnorm=0.679, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:21:02 | INFO | train_inner | epoch 018:     20 / 138 loss=2.905, nll_loss=1.081, ppl=2.12, wps=5944.6, ups=0.49, wpb=12224.9, bsz=336.8, num_updates=2090, lr=1e-05, gnorm=0.613, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:21:22 | INFO | train_inner | epoch 018:     30 / 138 loss=2.93, nll_loss=1.107, ppl=2.15, wps=6056.9, ups=0.5, wpb=12110.3, bsz=330.4, num_updates=2100, lr=1e-05, gnorm=0.621, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:21:28 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.219 | nll_loss 1.404 | ppl 2.65 | wps 14824.3 | wpb 1129.8 | bsz 29.7 | num_updates 2100 | best_loss 3.192
2022-07-19 09:22:28 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_18_2100.pt (epoch 18 @ 2100 updates, score 3.219) (writing took 60.58512569963932 seconds)
2022-07-19 09:22:49 | INFO | train_inner | epoch 018:     40 / 138 loss=2.931, nll_loss=1.11, ppl=2.16, wps=1471.5, ups=0.12, wpb=12773.8, bsz=388.8, num_updates=2110, lr=1e-05, gnorm=0.613, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:23:09 | INFO | train_inner | epoch 018:     50 / 138 loss=2.92, nll_loss=1.096, ppl=2.14, wps=6159, ups=0.49, wpb=12474.7, bsz=308, num_updates=2120, lr=1e-05, gnorm=0.62, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:23:29 | INFO | train_inner | epoch 018:     60 / 138 loss=2.934, nll_loss=1.114, ppl=2.16, wps=5967.8, ups=0.5, wpb=11997.6, bsz=352, num_updates=2130, lr=1e-05, gnorm=0.63, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:23:50 | INFO | train_inner | epoch 018:     70 / 138 loss=2.949, nll_loss=1.13, ppl=2.19, wps=6089.3, ups=0.48, wpb=12698.2, bsz=414.4, num_updates=2140, lr=1e-05, gnorm=0.619, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:24:11 | INFO | train_inner | epoch 018:     80 / 138 loss=2.929, nll_loss=1.108, ppl=2.16, wps=6101.9, ups=0.48, wpb=12766.9, bsz=393.2, num_updates=2150, lr=1e-05, gnorm=0.622, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:24:32 | INFO | train_inner | epoch 018:     90 / 138 loss=2.894, nll_loss=1.069, ppl=2.1, wps=6027.7, ups=0.47, wpb=12761.5, bsz=453.6, num_updates=2160, lr=1e-05, gnorm=0.61, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:24:53 | INFO | train_inner | epoch 018:    100 / 138 loss=2.939, nll_loss=1.119, ppl=2.17, wps=6092.3, ups=0.48, wpb=12614.1, bsz=382.4, num_updates=2170, lr=1e-05, gnorm=0.626, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:25:14 | INFO | train_inner | epoch 018:    110 / 138 loss=2.897, nll_loss=1.071, ppl=2.1, wps=6113.7, ups=0.49, wpb=12603.1, bsz=329.6, num_updates=2180, lr=1e-05, gnorm=0.608, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:25:35 | INFO | train_inner | epoch 018:    120 / 138 loss=2.918, nll_loss=1.096, ppl=2.14, wps=5987.4, ups=0.47, wpb=12611.8, bsz=408.8, num_updates=2190, lr=1e-05, gnorm=0.608, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:25:55 | INFO | train_inner | epoch 018:    130 / 138 loss=2.949, nll_loss=1.13, ppl=2.19, wps=5912.6, ups=0.49, wpb=12039.1, bsz=384.1, num_updates=2200, lr=1e-05, gnorm=0.649, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:26:01 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.22 | nll_loss 1.406 | ppl 2.65 | wps 14866.4 | wpb 1129.8 | bsz 29.7 | num_updates 2200 | best_loss 3.192
2022-07-19 09:27:17 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_18_2200.pt (epoch 18 @ 2200 updates, score 3.22) (writing took 75.93925978988409 seconds)
2022-07-19 09:27:36 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.22 | nll_loss 1.407 | ppl 2.65 | wps 15308 | wpb 1129.8 | bsz 29.7 | num_updates 2208 | best_loss 3.192
2022-07-19 09:27:36 | INFO | train | epoch 018 | loss 2.928 | nll_loss 1.107 | ppl 2.15 | wps 3925.3 | ups 0.32 | wpb 12385.4 | bsz 364.8 | num_updates 2208 | lr 1e-05 | gnorm 0.629 | loss_scale None | train_wall 273 | wall 0
2022-07-19 09:27:40 | INFO | train_inner | epoch 019:      2 / 138 loss=2.932, nll_loss=1.112, ppl=2.16, wps=1088.9, ups=0.09, wpb=11479.5, bsz=297.6, num_updates=2210, lr=1e-05, gnorm=0.68, loss_scale=None, train_wall=18, wall=0
2022-07-19 09:28:01 | INFO | train_inner | epoch 019:     12 / 138 loss=2.89, nll_loss=1.063, ppl=2.09, wps=6208.8, ups=0.49, wpb=12676.5, bsz=359.2, num_updates=2220, lr=1e-05, gnorm=0.635, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:28:22 | INFO | train_inner | epoch 019:     22 / 138 loss=2.911, nll_loss=1.087, ppl=2.12, wps=6022.1, ups=0.48, wpb=12514.5, bsz=352, num_updates=2230, lr=1e-05, gnorm=0.623, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:28:42 | INFO | train_inner | epoch 019:     32 / 138 loss=2.918, nll_loss=1.094, ppl=2.13, wps=6080.8, ups=0.5, wpb=12165.7, bsz=328.8, num_updates=2240, lr=1e-05, gnorm=0.629, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:29:03 | INFO | train_inner | epoch 019:     42 / 138 loss=2.886, nll_loss=1.059, ppl=2.08, wps=6225, ups=0.48, wpb=12997.6, bsz=409.6, num_updates=2250, lr=1e-05, gnorm=0.587, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:29:23 | INFO | train_inner | epoch 019:     52 / 138 loss=2.896, nll_loss=1.071, ppl=2.1, wps=6027.2, ups=0.48, wpb=12443.7, bsz=362.3, num_updates=2260, lr=1e-05, gnorm=0.619, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:29:44 | INFO | train_inner | epoch 019:     62 / 138 loss=2.939, nll_loss=1.119, ppl=2.17, wps=6027.1, ups=0.49, wpb=12291.3, bsz=351.8, num_updates=2270, lr=1e-05, gnorm=0.643, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:30:04 | INFO | train_inner | epoch 019:     72 / 138 loss=2.905, nll_loss=1.079, ppl=2.11, wps=6000.5, ups=0.49, wpb=12353.1, bsz=352, num_updates=2280, lr=1e-05, gnorm=0.635, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:30:25 | INFO | train_inner | epoch 019:     82 / 138 loss=2.924, nll_loss=1.103, ppl=2.15, wps=5844.8, ups=0.49, wpb=12045.2, bsz=409.6, num_updates=2290, lr=1e-05, gnorm=0.631, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:30:45 | INFO | train_inner | epoch 019:     92 / 138 loss=2.882, nll_loss=1.055, ppl=2.08, wps=6062.7, ups=0.48, wpb=12564.5, bsz=371.4, num_updates=2300, lr=1e-05, gnorm=0.625, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:30:51 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.225 | nll_loss 1.41 | ppl 2.66 | wps 14820.6 | wpb 1129.8 | bsz 29.7 | num_updates 2300 | best_loss 3.192
2022-07-19 09:32:26 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_19_2300.pt (epoch 19 @ 2300 updates, score 3.225) (writing took 94.59389238897711 seconds)
2022-07-19 09:32:45 | INFO | train_inner | epoch 019:    102 / 138 loss=2.926, nll_loss=1.104, ppl=2.15, wps=998.7, ups=0.08, wpb=11949.8, bsz=320.4, num_updates=2310, lr=1e-05, gnorm=0.654, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:33:05 | INFO | train_inner | epoch 019:    112 / 138 loss=2.941, nll_loss=1.121, ppl=2.18, wps=6162, ups=0.5, wpb=12397.8, bsz=386.4, num_updates=2320, lr=1e-05, gnorm=0.643, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:33:26 | INFO | train_inner | epoch 019:    122 / 138 loss=2.918, nll_loss=1.095, ppl=2.14, wps=6045.1, ups=0.49, wpb=12387.3, bsz=403.2, num_updates=2330, lr=1e-05, gnorm=0.628, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:33:47 | INFO | train_inner | epoch 019:    132 / 138 loss=2.904, nll_loss=1.08, ppl=2.11, wps=6213.8, ups=0.48, wpb=12999, bsz=383.2, num_updates=2340, lr=1e-05, gnorm=0.614, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:34:03 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.226 | nll_loss 1.411 | ppl 2.66 | wps 14933.8 | wpb 1129.8 | bsz 29.7 | num_updates 2346 | best_loss 3.192
2022-07-19 09:34:03 | INFO | train | epoch 019 | loss 2.912 | nll_loss 1.088 | ppl 2.13 | wps 4419.8 | ups 0.36 | wpb 12385.4 | bsz 364.8 | num_updates 2346 | lr 1e-05 | gnorm 0.634 | loss_scale None | train_wall 272 | wall 0
2022-07-19 09:34:12 | INFO | train_inner | epoch 020:      4 / 138 loss=2.933, nll_loss=1.111, ppl=2.16, wps=4703.6, ups=0.4, wpb=11707.2, bsz=324.9, num_updates=2350, lr=1e-05, gnorm=0.7, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:34:32 | INFO | train_inner | epoch 020:     14 / 138 loss=2.882, nll_loss=1.055, ppl=2.08, wps=6064.5, ups=0.49, wpb=12426.6, bsz=349.6, num_updates=2360, lr=1e-05, gnorm=0.605, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:34:52 | INFO | train_inner | epoch 020:     24 / 138 loss=2.885, nll_loss=1.058, ppl=2.08, wps=6092.8, ups=0.5, wpb=12271.6, bsz=339.1, num_updates=2370, lr=1e-05, gnorm=0.632, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:35:13 | INFO | train_inner | epoch 020:     34 / 138 loss=2.887, nll_loss=1.06, ppl=2.08, wps=6171.8, ups=0.48, wpb=12944.1, bsz=350.4, num_updates=2380, lr=1e-05, gnorm=0.602, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:35:34 | INFO | train_inner | epoch 020:     44 / 138 loss=2.893, nll_loss=1.066, ppl=2.09, wps=5919.1, ups=0.48, wpb=12252.7, bsz=372, num_updates=2390, lr=1e-05, gnorm=0.614, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:35:55 | INFO | train_inner | epoch 020:     54 / 138 loss=2.889, nll_loss=1.062, ppl=2.09, wps=6081.1, ups=0.48, wpb=12592.9, bsz=368, num_updates=2400, lr=1e-05, gnorm=0.609, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:36:00 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.229 | nll_loss 1.416 | ppl 2.67 | wps 14780.1 | wpb 1129.8 | bsz 29.7 | num_updates 2400 | best_loss 3.192
2022-07-19 09:37:16 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_20_2400.pt (epoch 20 @ 2400 updates, score 3.229) (writing took 76.09229612350464 seconds)
2022-07-19 09:37:36 | INFO | train_inner | epoch 020:     64 / 138 loss=2.917, nll_loss=1.093, ppl=2.13, wps=1204, ups=0.1, wpb=12210.5, bsz=394.6, num_updates=2410, lr=1e-05, gnorm=0.65, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:37:56 | INFO | train_inner | epoch 020:     74 / 138 loss=2.886, nll_loss=1.059, ppl=2.08, wps=6142.3, ups=0.49, wpb=12537.6, bsz=381.6, num_updates=2420, lr=1e-05, gnorm=0.608, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:38:17 | INFO | train_inner | epoch 020:     84 / 138 loss=2.905, nll_loss=1.08, ppl=2.11, wps=6006.3, ups=0.49, wpb=12233.1, bsz=355.2, num_updates=2430, lr=1e-05, gnorm=0.621, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:38:37 | INFO | train_inner | epoch 020:     94 / 138 loss=2.863, nll_loss=1.033, ppl=2.05, wps=6128.5, ups=0.48, wpb=12659.9, bsz=375.6, num_updates=2440, lr=1e-05, gnorm=0.624, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:38:58 | INFO | train_inner | epoch 020:    104 / 138 loss=2.908, nll_loss=1.083, ppl=2.12, wps=6050.9, ups=0.49, wpb=12232.5, bsz=340, num_updates=2450, lr=1e-05, gnorm=0.627, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:39:19 | INFO | train_inner | epoch 020:    114 / 138 loss=2.899, nll_loss=1.074, ppl=2.11, wps=6098.2, ups=0.48, wpb=12746, bsz=391.2, num_updates=2460, lr=1e-05, gnorm=0.608, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:39:39 | INFO | train_inner | epoch 020:    124 / 138 loss=2.898, nll_loss=1.073, ppl=2.1, wps=5939.3, ups=0.48, wpb=12265.8, bsz=379.2, num_updates=2470, lr=1e-05, gnorm=0.634, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:40:00 | INFO | train_inner | epoch 020:    134 / 138 loss=2.915, nll_loss=1.09, ppl=2.13, wps=5955.2, ups=0.48, wpb=12490.6, bsz=390.3, num_updates=2480, lr=1e-05, gnorm=0.689, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:40:13 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.231 | nll_loss 1.418 | ppl 2.67 | wps 14784.9 | wpb 1129.8 | bsz 29.7 | num_updates 2484 | best_loss 3.192
2022-07-19 09:40:13 | INFO | train | epoch 020 | loss 2.895 | nll_loss 1.069 | ppl 2.1 | wps 4627.3 | ups 0.37 | wpb 12385.4 | bsz 364.8 | num_updates 2484 | lr 1e-05 | gnorm 0.634 | loss_scale None | train_wall 273 | wall 0
2022-07-19 09:40:25 | INFO | train_inner | epoch 021:      6 / 138 loss=2.89, nll_loss=1.063, ppl=2.09, wps=4587.6, ups=0.4, wpb=11502.3, bsz=315.1, num_updates=2490, lr=1e-05, gnorm=0.774, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:40:46 | INFO | train_inner | epoch 021:     16 / 138 loss=2.869, nll_loss=1.04, ppl=2.06, wps=6054.3, ups=0.49, wpb=12433.9, bsz=358.4, num_updates=2500, lr=1e-05, gnorm=0.612, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:40:51 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.232 | nll_loss 1.418 | ppl 2.67 | wps 14759.5 | wpb 1129.8 | bsz 29.7 | num_updates 2500 | best_loss 3.192
2022-07-19 09:41:52 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_21_2500.pt (epoch 21 @ 2500 updates, score 3.232) (writing took 60.442029485479 seconds)
2022-07-19 09:42:12 | INFO | train_inner | epoch 021:     26 / 138 loss=2.868, nll_loss=1.038, ppl=2.05, wps=1463.3, ups=0.12, wpb=12651.8, bsz=395.8, num_updates=2510, lr=1e-05, gnorm=0.611, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:42:33 | INFO | train_inner | epoch 021:     36 / 138 loss=2.921, nll_loss=1.097, ppl=2.14, wps=6043.4, ups=0.49, wpb=12301.7, bsz=368.9, num_updates=2520, lr=1e-05, gnorm=0.657, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:42:53 | INFO | train_inner | epoch 021:     46 / 138 loss=2.867, nll_loss=1.038, ppl=2.05, wps=6022.8, ups=0.49, wpb=12293.3, bsz=369.8, num_updates=2530, lr=1e-05, gnorm=0.639, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:43:14 | INFO | train_inner | epoch 021:     56 / 138 loss=2.874, nll_loss=1.044, ppl=2.06, wps=6155.6, ups=0.48, wpb=12857.5, bsz=389.6, num_updates=2540, lr=1e-05, gnorm=0.593, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:43:34 | INFO | train_inner | epoch 021:     66 / 138 loss=2.875, nll_loss=1.047, ppl=2.07, wps=6007.6, ups=0.5, wpb=12114.8, bsz=325.6, num_updates=2550, lr=1e-05, gnorm=0.637, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:43:55 | INFO | train_inner | epoch 021:     76 / 138 loss=2.859, nll_loss=1.028, ppl=2.04, wps=5985, ups=0.48, wpb=12419.3, bsz=372, num_updates=2560, lr=1e-05, gnorm=0.598, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:44:15 | INFO | train_inner | epoch 021:     86 / 138 loss=2.895, nll_loss=1.068, ppl=2.1, wps=6125.4, ups=0.5, wpb=12305.5, bsz=354, num_updates=2570, lr=1e-05, gnorm=0.642, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:44:36 | INFO | train_inner | epoch 021:     96 / 138 loss=2.864, nll_loss=1.034, ppl=2.05, wps=6070.9, ups=0.48, wpb=12673.9, bsz=388, num_updates=2580, lr=1e-05, gnorm=0.617, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:44:57 | INFO | train_inner | epoch 021:    106 / 138 loss=2.893, nll_loss=1.068, ppl=2.1, wps=6055.7, ups=0.48, wpb=12609.8, bsz=390.4, num_updates=2590, lr=1e-05, gnorm=0.627, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:45:18 | INFO | train_inner | epoch 021:    116 / 138 loss=2.888, nll_loss=1.058, ppl=2.08, wps=5987.4, ups=0.48, wpb=12529.8, bsz=386.4, num_updates=2600, lr=1e-05, gnorm=0.61, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:45:23 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.236 | nll_loss 1.42 | ppl 2.68 | wps 14813 | wpb 1129.8 | bsz 29.7 | num_updates 2600 | best_loss 3.192
2022-07-19 09:46:24 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_21_2600.pt (epoch 21 @ 2600 updates, score 3.236) (writing took 60.62182182073593 seconds)
2022-07-19 09:46:44 | INFO | train_inner | epoch 021:    126 / 138 loss=2.896, nll_loss=1.07, ppl=2.1, wps=1394.5, ups=0.12, wpb=11989.8, bsz=376.8, num_updates=2610, lr=1e-05, gnorm=0.623, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:47:04 | INFO | train_inner | epoch 021:    136 / 138 loss=2.874, nll_loss=1.045, ppl=2.06, wps=6163.9, ups=0.49, wpb=12584.4, bsz=308, num_updates=2620, lr=1e-05, gnorm=0.611, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:47:12 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.237 | nll_loss 1.423 | ppl 2.68 | wps 14997.1 | wpb 1129.8 | bsz 29.7 | num_updates 2622 | best_loss 3.192
2022-07-19 09:47:12 | INFO | train | epoch 021 | loss 2.879 | nll_loss 1.051 | ppl 2.07 | wps 4072.4 | ups 0.33 | wpb 12385.4 | bsz 364.8 | num_updates 2622 | lr 1e-05 | gnorm 0.627 | loss_scale None | train_wall 273 | wall 0
2022-07-19 09:47:29 | INFO | train_inner | epoch 022:      8 / 138 loss=2.84, nll_loss=1.006, ppl=2.01, wps=4703.8, ups=0.4, wpb=11681.2, bsz=318.4, num_updates=2630, lr=1e-05, gnorm=0.668, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:47:50 | INFO | train_inner | epoch 022:     18 / 138 loss=2.867, nll_loss=1.036, ppl=2.05, wps=6085.9, ups=0.48, wpb=12706.2, bsz=352.8, num_updates=2640, lr=1e-05, gnorm=0.605, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:48:10 | INFO | train_inner | epoch 022:     28 / 138 loss=2.883, nll_loss=1.055, ppl=2.08, wps=6042.6, ups=0.48, wpb=12588.9, bsz=380, num_updates=2650, lr=1e-05, gnorm=0.603, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:48:32 | INFO | train_inner | epoch 022:     38 / 138 loss=2.895, nll_loss=1.068, ppl=2.1, wps=5959.7, ups=0.47, wpb=12622.4, bsz=423.4, num_updates=2660, lr=1e-05, gnorm=0.64, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:48:52 | INFO | train_inner | epoch 022:     48 / 138 loss=2.883, nll_loss=1.055, ppl=2.08, wps=5769, ups=0.49, wpb=11734.2, bsz=364.8, num_updates=2670, lr=1e-05, gnorm=0.654, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:49:13 | INFO | train_inner | epoch 022:     58 / 138 loss=2.858, nll_loss=1.026, ppl=2.04, wps=6016.5, ups=0.48, wpb=12628.3, bsz=380.6, num_updates=2680, lr=1e-05, gnorm=0.635, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:49:34 | INFO | train_inner | epoch 022:     68 / 138 loss=2.827, nll_loss=0.991, ppl=1.99, wps=5984.4, ups=0.49, wpb=12311, bsz=348, num_updates=2690, lr=1e-05, gnorm=0.606, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:49:54 | INFO | train_inner | epoch 022:     78 / 138 loss=2.862, nll_loss=1.031, ppl=2.04, wps=6152.8, ups=0.49, wpb=12662.9, bsz=342.4, num_updates=2700, lr=1e-05, gnorm=0.607, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:50:00 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 3.241 | nll_loss 1.426 | ppl 2.69 | wps 14811 | wpb 1129.8 | bsz 29.7 | num_updates 2700 | best_loss 3.192
2022-07-19 09:51:01 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_22_2700.pt (epoch 22 @ 2700 updates, score 3.241) (writing took 60.87393036484718 seconds)
2022-07-19 09:51:21 | INFO | train_inner | epoch 022:     88 / 138 loss=2.853, nll_loss=1.021, ppl=2.03, wps=1490, ups=0.11, wpb=12982.4, bsz=406.4, num_updates=2710, lr=1e-05, gnorm=0.592, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:51:42 | INFO | train_inner | epoch 022:     98 / 138 loss=2.845, nll_loss=1.012, ppl=2.02, wps=6075.4, ups=0.49, wpb=12451.9, bsz=396, num_updates=2720, lr=1e-05, gnorm=0.595, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:52:02 | INFO | train_inner | epoch 022:    108 / 138 loss=2.929, nll_loss=1.106, ppl=2.15, wps=6105.6, ups=0.5, wpb=12273.3, bsz=328.1, num_updates=2730, lr=1e-05, gnorm=0.663, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:52:22 | INFO | train_inner | epoch 022:    118 / 138 loss=2.848, nll_loss=1.015, ppl=2.02, wps=6078, ups=0.49, wpb=12288.3, bsz=294.4, num_updates=2740, lr=1e-05, gnorm=0.633, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:52:43 | INFO | train_inner | epoch 022:    128 / 138 loss=2.83, nll_loss=0.995, ppl=1.99, wps=6056.6, ups=0.48, wpb=12643, bsz=394.3, num_updates=2750, lr=1e-05, gnorm=0.605, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:53:02 | INFO | train_inner | epoch 022:    138 / 138 loss=2.868, nll_loss=1.038, ppl=2.05, wps=5848.2, ups=0.54, wpb=10914, bsz=344.4, num_updates=2760, lr=1e-05, gnorm=0.693, loss_scale=None, train_wall=18, wall=0
2022-07-19 09:53:07 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 3.242 | nll_loss 1.429 | ppl 2.69 | wps 14855.6 | wpb 1129.8 | bsz 29.7 | num_updates 2760 | best_loss 3.192
2022-07-19 09:53:07 | INFO | train | epoch 022 | loss 2.864 | nll_loss 1.033 | ppl 2.05 | wps 4813.7 | ups 0.39 | wpb 12385.4 | bsz 364.8 | num_updates 2760 | lr 1e-05 | gnorm 0.624 | loss_scale None | train_wall 274 | wall 0
2022-07-19 09:53:28 | INFO | train_inner | epoch 023:     10 / 138 loss=2.827, nll_loss=0.991, ppl=1.99, wps=4746.6, ups=0.38, wpb=12505.6, bsz=350.4, num_updates=2770, lr=1e-05, gnorm=0.606, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:53:48 | INFO | train_inner | epoch 023:     20 / 138 loss=2.849, nll_loss=1.016, ppl=2.02, wps=6149.7, ups=0.49, wpb=12603, bsz=346.4, num_updates=2780, lr=1e-05, gnorm=0.621, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:54:09 | INFO | train_inner | epoch 023:     30 / 138 loss=2.868, nll_loss=1.038, ppl=2.05, wps=5960.1, ups=0.48, wpb=12318.7, bsz=399.2, num_updates=2790, lr=1e-05, gnorm=0.621, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:54:30 | INFO | train_inner | epoch 023:     40 / 138 loss=2.861, nll_loss=1.03, ppl=2.04, wps=6002.2, ups=0.48, wpb=12589.9, bsz=378.4, num_updates=2800, lr=1e-05, gnorm=0.605, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:54:36 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.246 | nll_loss 1.432 | ppl 2.7 | wps 14744.1 | wpb 1129.8 | bsz 29.7 | num_updates 2800 | best_loss 3.192
2022-07-19 09:56:19 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_23_2800.pt (epoch 23 @ 2800 updates, score 3.246) (writing took 103.26856504566967 seconds)
2022-07-19 09:56:39 | INFO | train_inner | epoch 023:     50 / 138 loss=2.849, nll_loss=1.016, ppl=2.02, wps=977, ups=0.08, wpb=12589.4, bsz=380, num_updates=2810, lr=1e-05, gnorm=0.602, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:56:59 | INFO | train_inner | epoch 023:     60 / 138 loss=2.854, nll_loss=1.021, ppl=2.03, wps=6076.7, ups=0.5, wpb=12206.2, bsz=327.1, num_updates=2820, lr=1e-05, gnorm=0.674, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:57:20 | INFO | train_inner | epoch 023:     70 / 138 loss=2.824, nll_loss=0.987, ppl=1.98, wps=6154.5, ups=0.49, wpb=12634.1, bsz=350.4, num_updates=2830, lr=1e-05, gnorm=0.606, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:57:40 | INFO | train_inner | epoch 023:     80 / 138 loss=2.835, nll_loss=0.999, ppl=2, wps=6166.5, ups=0.49, wpb=12689.8, bsz=349.6, num_updates=2840, lr=1e-05, gnorm=0.602, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:58:00 | INFO | train_inner | epoch 023:     90 / 138 loss=2.864, nll_loss=1.032, ppl=2.04, wps=5868.6, ups=0.5, wpb=11733.4, bsz=360.8, num_updates=2850, lr=1e-05, gnorm=0.633, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:58:21 | INFO | train_inner | epoch 023:    100 / 138 loss=2.838, nll_loss=1.005, ppl=2.01, wps=5995.4, ups=0.47, wpb=12731.2, bsz=372.7, num_updates=2860, lr=1e-05, gnorm=0.615, loss_scale=None, train_wall=21, wall=0
2022-07-19 09:58:42 | INFO | train_inner | epoch 023:    110 / 138 loss=2.821, nll_loss=0.985, ppl=1.98, wps=6052.4, ups=0.49, wpb=12304.1, bsz=362.6, num_updates=2870, lr=1e-05, gnorm=0.622, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:59:02 | INFO | train_inner | epoch 023:    120 / 138 loss=2.85, nll_loss=1.018, ppl=2.02, wps=6052.5, ups=0.48, wpb=12515.5, bsz=391.2, num_updates=2880, lr=1e-05, gnorm=0.61, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:59:23 | INFO | train_inner | epoch 023:    130 / 138 loss=2.887, nll_loss=1.06, ppl=2.08, wps=6040.1, ups=0.49, wpb=12382.2, bsz=388, num_updates=2890, lr=1e-05, gnorm=0.626, loss_scale=None, train_wall=20, wall=0
2022-07-19 09:59:44 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.246 | nll_loss 1.432 | ppl 2.7 | wps 14791.9 | wpb 1129.8 | bsz 29.7 | num_updates 2898 | best_loss 3.192
2022-07-19 09:59:44 | INFO | train | epoch 023 | loss 2.849 | nll_loss 1.016 | ppl 2.02 | wps 4309.3 | ups 0.35 | wpb 12385.4 | bsz 364.8 | num_updates 2898 | lr 1e-05 | gnorm 0.624 | loss_scale None | train_wall 273 | wall 0
2022-07-19 09:59:48 | INFO | train_inner | epoch 024:      2 / 138 loss=2.839, nll_loss=1.005, ppl=2.01, wps=4584.1, ups=0.4, wpb=11539.9, bsz=374, num_updates=2900, lr=1e-05, gnorm=0.681, loss_scale=None, train_wall=19, wall=0
2022-07-19 09:59:54 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 3.246 | nll_loss 1.433 | ppl 2.7 | wps 14825.3 | wpb 1129.8 | bsz 29.7 | num_updates 2900 | best_loss 3.192
2022-07-19 10:00:56 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_24_2900.pt (epoch 24 @ 2900 updates, score 3.246) (writing took 62.63619807269424 seconds)
2022-07-19 10:01:17 | INFO | train_inner | epoch 024:     12 / 138 loss=2.814, nll_loss=0.977, ppl=1.97, wps=1440.7, ups=0.11, wpb=12771.8, bsz=406.4, num_updates=2910, lr=1e-05, gnorm=0.596, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:01:37 | INFO | train_inner | epoch 024:     22 / 138 loss=2.833, nll_loss=0.998, ppl=2, wps=6124.3, ups=0.5, wpb=12321.6, bsz=304.6, num_updates=2920, lr=1e-05, gnorm=0.634, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:01:57 | INFO | train_inner | epoch 024:     32 / 138 loss=2.811, nll_loss=0.975, ppl=1.97, wps=6065.8, ups=0.49, wpb=12279.7, bsz=364, num_updates=2930, lr=1e-05, gnorm=0.602, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:02:17 | INFO | train_inner | epoch 024:     42 / 138 loss=2.83, nll_loss=0.994, ppl=1.99, wps=6064.5, ups=0.49, wpb=12293.3, bsz=350, num_updates=2940, lr=1e-05, gnorm=0.643, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:02:38 | INFO | train_inner | epoch 024:     52 / 138 loss=2.844, nll_loss=1.009, ppl=2.01, wps=6072.4, ups=0.48, wpb=12569.8, bsz=360.8, num_updates=2950, lr=1e-05, gnorm=0.617, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:02:59 | INFO | train_inner | epoch 024:     62 / 138 loss=2.819, nll_loss=0.982, ppl=1.98, wps=6192.5, ups=0.48, wpb=12932, bsz=362.6, num_updates=2960, lr=1e-05, gnorm=0.603, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:03:20 | INFO | train_inner | epoch 024:     72 / 138 loss=2.849, nll_loss=1.016, ppl=2.02, wps=6094.9, ups=0.48, wpb=12731.2, bsz=388, num_updates=2970, lr=1e-05, gnorm=0.619, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:03:41 | INFO | train_inner | epoch 024:     82 / 138 loss=2.838, nll_loss=1.003, ppl=2, wps=5995.6, ups=0.48, wpb=12396.1, bsz=341.6, num_updates=2980, lr=1e-05, gnorm=0.602, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:04:01 | INFO | train_inner | epoch 024:     92 / 138 loss=2.858, nll_loss=1.026, ppl=2.04, wps=5911.4, ups=0.49, wpb=12004.2, bsz=379.2, num_updates=2990, lr=1e-05, gnorm=0.625, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:04:21 | INFO | train_inner | epoch 024:    102 / 138 loss=2.836, nll_loss=1.001, ppl=2, wps=5954.6, ups=0.49, wpb=12216.5, bsz=342.3, num_updates=3000, lr=1e-05, gnorm=0.612, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:04:27 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 3.251 | nll_loss 1.437 | ppl 2.71 | wps 14883.3 | wpb 1129.8 | bsz 29.7 | num_updates 3000 | best_loss 3.192
2022-07-19 10:05:32 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_24_3000.pt (epoch 24 @ 3000 updates, score 3.251) (writing took 64.79406104423106 seconds)
2022-07-19 10:05:52 | INFO | train_inner | epoch 024:    112 / 138 loss=2.811, nll_loss=0.972, ppl=1.96, wps=1395, ups=0.11, wpb=12628.7, bsz=365.6, num_updates=3010, lr=1e-05, gnorm=0.593, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:06:12 | INFO | train_inner | epoch 024:    122 / 138 loss=2.856, nll_loss=1.023, ppl=2.03, wps=6154, ups=0.5, wpb=12186.7, bsz=380.8, num_updates=3020, lr=1e-05, gnorm=0.627, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:06:33 | INFO | train_inner | epoch 024:    132 / 138 loss=2.867, nll_loss=1.037, ppl=2.05, wps=6078.1, ups=0.47, wpb=12797.5, bsz=424.1, num_updates=3030, lr=1e-05, gnorm=0.76, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:06:49 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 3.252 | nll_loss 1.437 | ppl 2.71 | wps 14942.3 | wpb 1129.8 | bsz 29.7 | num_updates 3036 | best_loss 3.192
2022-07-19 10:06:49 | INFO | train | epoch 024 | loss 2.835 | nll_loss 1 | ppl 2 | wps 4021.4 | ups 0.32 | wpb 12385.4 | bsz 364.8 | num_updates 3036 | lr 1e-05 | gnorm 0.628 | loss_scale None | train_wall 271 | wall 0
2022-07-19 10:06:57 | INFO | train_inner | epoch 025:      4 / 138 loss=2.835, nll_loss=1, ppl=2, wps=4601.3, ups=0.41, wpb=11176.1, bsz=278.4, num_updates=3040, lr=1e-05, gnorm=0.676, loss_scale=None, train_wall=18, wall=0
2022-07-19 10:07:18 | INFO | train_inner | epoch 025:     14 / 138 loss=2.821, nll_loss=0.984, ppl=1.98, wps=6083.9, ups=0.48, wpb=12548.1, bsz=372.8, num_updates=3050, lr=1e-05, gnorm=0.618, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:07:38 | INFO | train_inner | epoch 025:     24 / 138 loss=2.819, nll_loss=0.983, ppl=1.98, wps=6051.2, ups=0.48, wpb=12479.6, bsz=383.2, num_updates=3060, lr=1e-05, gnorm=0.607, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:07:59 | INFO | train_inner | epoch 025:     34 / 138 loss=2.811, nll_loss=0.972, ppl=1.96, wps=6102.6, ups=0.48, wpb=12807.3, bsz=394.4, num_updates=3070, lr=1e-05, gnorm=0.597, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:08:19 | INFO | train_inner | epoch 025:     44 / 138 loss=2.869, nll_loss=1.037, ppl=2.05, wps=5969.1, ups=0.5, wpb=11880.5, bsz=309.8, num_updates=3080, lr=1e-05, gnorm=0.676, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:08:40 | INFO | train_inner | epoch 025:     54 / 138 loss=2.801, nll_loss=0.96, ppl=1.95, wps=5944.6, ups=0.48, wpb=12351.3, bsz=350.4, num_updates=3090, lr=1e-05, gnorm=0.602, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:09:01 | INFO | train_inner | epoch 025:     64 / 138 loss=2.82, nll_loss=0.983, ppl=1.98, wps=6094.9, ups=0.48, wpb=12738.8, bsz=377.6, num_updates=3100, lr=1e-05, gnorm=0.596, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:09:07 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 3.257 | nll_loss 1.442 | ppl 2.72 | wps 14758.4 | wpb 1129.8 | bsz 29.7 | num_updates 3100 | best_loss 3.192
2022-07-19 10:10:21 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_25_3100.pt (epoch 25 @ 3100 updates, score 3.257) (writing took 74.38992739841342 seconds)
2022-07-19 10:10:41 | INFO | train_inner | epoch 025:     74 / 138 loss=2.796, nll_loss=0.955, ppl=1.94, wps=1234, ups=0.1, wpb=12326.1, bsz=354.4, num_updates=3110, lr=1e-05, gnorm=0.612, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:11:02 | INFO | train_inner | epoch 025:     84 / 138 loss=2.806, nll_loss=0.967, ppl=1.96, wps=6156, ups=0.48, wpb=12817.1, bsz=359.5, num_updates=3120, lr=1e-05, gnorm=0.62, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:11:22 | INFO | train_inner | epoch 025:     94 / 138 loss=2.818, nll_loss=0.98, ppl=1.97, wps=6102, ups=0.49, wpb=12481.9, bsz=331.2, num_updates=3130, lr=1e-05, gnorm=0.602, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:11:43 | INFO | train_inner | epoch 025:    104 / 138 loss=2.828, nll_loss=0.991, ppl=1.99, wps=6117.8, ups=0.49, wpb=12557.7, bsz=398.5, num_updates=3140, lr=1e-05, gnorm=0.629, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:12:03 | INFO | train_inner | epoch 025:    114 / 138 loss=2.836, nll_loss=1.001, ppl=2, wps=6008.7, ups=0.48, wpb=12400.8, bsz=372.8, num_updates=3150, lr=1e-05, gnorm=0.615, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:12:24 | INFO | train_inner | epoch 025:    124 / 138 loss=2.813, nll_loss=0.975, ppl=1.97, wps=5900.9, ups=0.48, wpb=12250.2, bsz=394.2, num_updates=3160, lr=1e-05, gnorm=0.628, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:12:45 | INFO | train_inner | epoch 025:    134 / 138 loss=2.815, nll_loss=0.977, ppl=1.97, wps=5925.6, ups=0.49, wpb=12203.5, bsz=396.8, num_updates=3170, lr=1e-05, gnorm=0.62, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:12:57 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 3.255 | nll_loss 1.443 | ppl 2.72 | wps 14764.2 | wpb 1129.8 | bsz 29.7 | num_updates 3174 | best_loss 3.192
2022-07-19 10:12:57 | INFO | train | epoch 025 | loss 2.82 | nll_loss 0.982 | ppl 1.98 | wps 4641.7 | ups 0.37 | wpb 12385.4 | bsz 364.8 | num_updates 3174 | lr 1e-05 | gnorm 0.629 | loss_scale None | train_wall 273 | wall 0
2022-07-19 10:13:10 | INFO | train_inner | epoch 026:      6 / 138 loss=2.815, nll_loss=0.978, ppl=1.97, wps=4653.2, ups=0.4, wpb=11769, bsz=359.2, num_updates=3180, lr=1e-05, gnorm=0.761, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:13:31 | INFO | train_inner | epoch 026:     16 / 138 loss=2.816, nll_loss=0.979, ppl=1.97, wps=5958.8, ups=0.48, wpb=12362.8, bsz=379, num_updates=3190, lr=1e-05, gnorm=0.634, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:13:51 | INFO | train_inner | epoch 026:     26 / 138 loss=2.801, nll_loss=0.96, ppl=1.95, wps=5899.8, ups=0.48, wpb=12253.1, bsz=366.4, num_updates=3200, lr=1e-05, gnorm=0.621, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:13:57 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 3.262 | nll_loss 1.448 | ppl 2.73 | wps 14733.9 | wpb 1129.8 | bsz 29.7 | num_updates 3200 | best_loss 3.192
2022-07-19 10:15:19 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_26_3200.pt (epoch 26 @ 3200 updates, score 3.262) (writing took 82.09135550446808 seconds)
2022-07-19 10:15:39 | INFO | train_inner | epoch 026:     36 / 138 loss=2.813, nll_loss=0.976, ppl=1.97, wps=1184.9, ups=0.09, wpb=12792.9, bsz=338.4, num_updates=3210, lr=1e-05, gnorm=0.617, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:16:00 | INFO | train_inner | epoch 026:     46 / 138 loss=2.8, nll_loss=0.959, ppl=1.94, wps=6119.5, ups=0.49, wpb=12412, bsz=328.8, num_updates=3220, lr=1e-05, gnorm=0.618, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:16:19 | INFO | train_inner | epoch 026:     56 / 138 loss=2.817, nll_loss=0.98, ppl=1.97, wps=5948.4, ups=0.51, wpb=11688.3, bsz=307.4, num_updates=3230, lr=1e-05, gnorm=0.638, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:16:40 | INFO | train_inner | epoch 026:     66 / 138 loss=2.802, nll_loss=0.962, ppl=1.95, wps=5992.5, ups=0.49, wpb=12232, bsz=373.6, num_updates=3240, lr=1e-05, gnorm=0.609, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:17:00 | INFO | train_inner | epoch 026:     76 / 138 loss=2.784, nll_loss=0.942, ppl=1.92, wps=6008.3, ups=0.48, wpb=12455.7, bsz=383.2, num_updates=3250, lr=1e-05, gnorm=0.607, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:17:21 | INFO | train_inner | epoch 026:     86 / 138 loss=2.787, nll_loss=0.945, ppl=1.93, wps=6066.5, ups=0.48, wpb=12754.5, bsz=363.1, num_updates=3260, lr=1e-05, gnorm=0.612, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:17:42 | INFO | train_inner | epoch 026:     96 / 138 loss=2.806, nll_loss=0.967, ppl=1.95, wps=5928, ups=0.49, wpb=12100.3, bsz=347.6, num_updates=3270, lr=1e-05, gnorm=0.635, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:18:03 | INFO | train_inner | epoch 026:    106 / 138 loss=2.823, nll_loss=0.986, ppl=1.98, wps=5972.8, ups=0.48, wpb=12526.5, bsz=417.6, num_updates=3280, lr=1e-05, gnorm=0.625, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:18:24 | INFO | train_inner | epoch 026:    116 / 138 loss=2.829, nll_loss=0.993, ppl=1.99, wps=6037.6, ups=0.47, wpb=12776, bsz=425.6, num_updates=3290, lr=1e-05, gnorm=0.607, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:18:45 | INFO | train_inner | epoch 026:    126 / 138 loss=2.809, nll_loss=0.97, ppl=1.96, wps=6119, ups=0.48, wpb=12783, bsz=394.4, num_updates=3300, lr=1e-05, gnorm=0.604, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:18:51 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 3.263 | nll_loss 1.449 | ppl 2.73 | wps 14721.3 | wpb 1129.8 | bsz 29.7 | num_updates 3300 | best_loss 3.192
2022-07-19 10:20:12 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_26_3300.pt (epoch 26 @ 3300 updates, score 3.263) (writing took 81.48625516798347 seconds)
2022-07-19 10:20:32 | INFO | train_inner | epoch 026:    136 / 138 loss=2.79, nll_loss=0.948, ppl=1.93, wps=1186.2, ups=0.09, wpb=12745.4, bsz=344.1, num_updates=3310, lr=1e-05, gnorm=0.607, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:20:40 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 3.263 | nll_loss 1.45 | ppl 2.73 | wps 15198.9 | wpb 1129.8 | bsz 29.7 | num_updates 3312 | best_loss 3.192
2022-07-19 10:20:40 | INFO | train | epoch 026 | loss 2.806 | nll_loss 0.967 | ppl 1.95 | wps 3689.8 | ups 0.3 | wpb 12385.4 | bsz 364.8 | num_updates 3312 | lr 1e-05 | gnorm 0.622 | loss_scale None | train_wall 274 | wall 0
2022-07-19 10:20:57 | INFO | train_inner | epoch 027:      8 / 138 loss=2.775, nll_loss=0.933, ppl=1.91, wps=4710.2, ups=0.41, wpb=11433.7, bsz=326.4, num_updates=3320, lr=1e-05, gnorm=0.674, loss_scale=None, train_wall=18, wall=0
2022-07-19 10:21:17 | INFO | train_inner | epoch 027:     18 / 138 loss=2.788, nll_loss=0.946, ppl=1.93, wps=6027.2, ups=0.49, wpb=12314.6, bsz=382.4, num_updates=3330, lr=1e-05, gnorm=0.61, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:21:38 | INFO | train_inner | epoch 027:     28 / 138 loss=2.794, nll_loss=0.954, ppl=1.94, wps=5992.2, ups=0.48, wpb=12456.6, bsz=380.2, num_updates=3340, lr=1e-05, gnorm=0.661, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:21:59 | INFO | train_inner | epoch 027:     38 / 138 loss=2.824, nll_loss=0.986, ppl=1.98, wps=6144, ups=0.48, wpb=12739.4, bsz=364.1, num_updates=3350, lr=1e-05, gnorm=0.624, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:22:19 | INFO | train_inner | epoch 027:     48 / 138 loss=2.803, nll_loss=0.963, ppl=1.95, wps=6149.5, ups=0.48, wpb=12794.4, bsz=362.6, num_updates=3360, lr=1e-05, gnorm=0.602, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:22:40 | INFO | train_inner | epoch 027:     58 / 138 loss=2.777, nll_loss=0.934, ppl=1.91, wps=6004, ups=0.48, wpb=12439.1, bsz=374.4, num_updates=3370, lr=1e-05, gnorm=0.602, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:23:01 | INFO | train_inner | epoch 027:     68 / 138 loss=2.776, nll_loss=0.933, ppl=1.91, wps=5935.3, ups=0.47, wpb=12526.7, bsz=444.8, num_updates=3380, lr=1e-05, gnorm=0.6, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:23:22 | INFO | train_inner | epoch 027:     78 / 138 loss=2.802, nll_loss=0.961, ppl=1.95, wps=6115.7, ups=0.47, wpb=12890.9, bsz=352, num_updates=3390, lr=1e-05, gnorm=0.612, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:23:43 | INFO | train_inner | epoch 027:     88 / 138 loss=2.787, nll_loss=0.946, ppl=1.93, wps=5861.9, ups=0.49, wpb=11982.6, bsz=341.6, num_updates=3400, lr=1e-05, gnorm=0.66, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:23:48 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 3.267 | nll_loss 1.452 | ppl 2.74 | wps 14791.8 | wpb 1129.8 | bsz 29.7 | num_updates 3400 | best_loss 3.192
2022-07-19 10:25:16 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_27_3400.pt (epoch 27 @ 3400 updates, score 3.267) (writing took 87.46277950238436 seconds)
2022-07-19 10:25:36 | INFO | train_inner | epoch 027:     98 / 138 loss=2.79, nll_loss=0.947, ppl=1.93, wps=1114.9, ups=0.09, wpb=12638.9, bsz=368.8, num_updates=3410, lr=1e-05, gnorm=0.607, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:25:56 | INFO | train_inner | epoch 027:    108 / 138 loss=2.803, nll_loss=0.964, ppl=1.95, wps=6102, ups=0.5, wpb=12202.2, bsz=358.4, num_updates=3420, lr=1e-05, gnorm=0.617, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:26:16 | INFO | train_inner | epoch 027:    118 / 138 loss=2.812, nll_loss=0.972, ppl=1.96, wps=6078.6, ups=0.5, wpb=12271.8, bsz=336.7, num_updates=3430, lr=1e-05, gnorm=0.632, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:26:36 | INFO | train_inner | epoch 027:    128 / 138 loss=2.781, nll_loss=0.938, ppl=1.92, wps=5949.8, ups=0.49, wpb=12051.1, bsz=361.6, num_updates=3440, lr=1e-05, gnorm=0.614, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:26:56 | INFO | train_inner | epoch 027:    138 / 138 loss=2.773, nll_loss=0.93, ppl=1.91, wps=6047.6, ups=0.52, wpb=11704.9, bsz=312.8, num_updates=3450, lr=1e-05, gnorm=0.656, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:27:02 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 3.267 | nll_loss 1.454 | ppl 2.74 | wps 14826.6 | wpb 1129.8 | bsz 29.7 | num_updates 3450 | best_loss 3.192
2022-07-19 10:27:02 | INFO | train | epoch 027 | loss 2.792 | nll_loss 0.951 | ppl 1.93 | wps 4484.4 | ups 0.36 | wpb 12385.4 | bsz 364.8 | num_updates 3450 | lr 1e-05 | gnorm 0.622 | loss_scale None | train_wall 273 | wall 0
2022-07-19 10:27:22 | INFO | train_inner | epoch 028:     10 / 138 loss=2.724, nll_loss=0.874, ppl=1.83, wps=4749.9, ups=0.38, wpb=12632.2, bsz=365.6, num_updates=3460, lr=1e-05, gnorm=0.587, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:27:43 | INFO | train_inner | epoch 028:     20 / 138 loss=2.789, nll_loss=0.947, ppl=1.93, wps=6009.8, ups=0.49, wpb=12178.7, bsz=340, num_updates=3470, lr=1e-05, gnorm=0.628, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:28:03 | INFO | train_inner | epoch 028:     30 / 138 loss=2.792, nll_loss=0.951, ppl=1.93, wps=5834.9, ups=0.48, wpb=12112, bsz=384, num_updates=3480, lr=1e-05, gnorm=0.624, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:28:24 | INFO | train_inner | epoch 028:     40 / 138 loss=2.801, nll_loss=0.96, ppl=1.95, wps=5857.5, ups=0.49, wpb=11910.7, bsz=351.6, num_updates=3490, lr=1e-05, gnorm=0.674, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:28:44 | INFO | train_inner | epoch 028:     50 / 138 loss=2.781, nll_loss=0.937, ppl=1.91, wps=6018.8, ups=0.49, wpb=12354.5, bsz=322.7, num_updates=3500, lr=1e-05, gnorm=0.651, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:28:50 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 3.271 | nll_loss 1.458 | ppl 2.75 | wps 14770.7 | wpb 1129.8 | bsz 29.7 | num_updates 3500 | best_loss 3.192
2022-07-19 10:30:17 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_28_3500.pt (epoch 28 @ 3500 updates, score 3.271) (writing took 87.1859933892265 seconds)
2022-07-19 10:30:37 | INFO | train_inner | epoch 028:     60 / 138 loss=2.769, nll_loss=0.925, ppl=1.9, wps=1102.8, ups=0.09, wpb=12426.5, bsz=328.8, num_updates=3510, lr=1e-05, gnorm=0.608, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:30:57 | INFO | train_inner | epoch 028:     70 / 138 loss=2.779, nll_loss=0.936, ppl=1.91, wps=6176.1, ups=0.49, wpb=12606.8, bsz=380.8, num_updates=3520, lr=1e-05, gnorm=0.589, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:31:18 | INFO | train_inner | epoch 028:     80 / 138 loss=2.767, nll_loss=0.922, ppl=1.89, wps=6149.4, ups=0.47, wpb=12948.3, bsz=418.3, num_updates=3530, lr=1e-05, gnorm=0.608, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:31:39 | INFO | train_inner | epoch 028:     90 / 138 loss=2.778, nll_loss=0.935, ppl=1.91, wps=6102.5, ups=0.48, wpb=12828.1, bsz=371.8, num_updates=3540, lr=1e-05, gnorm=0.616, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:32:00 | INFO | train_inner | epoch 028:    100 / 138 loss=2.791, nll_loss=0.949, ppl=1.93, wps=5980.8, ups=0.49, wpb=12172.3, bsz=326.4, num_updates=3550, lr=1e-05, gnorm=0.62, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:32:21 | INFO | train_inner | epoch 028:    110 / 138 loss=2.802, nll_loss=0.96, ppl=1.95, wps=5977, ups=0.48, wpb=12457.8, bsz=372.8, num_updates=3560, lr=1e-05, gnorm=0.613, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:32:42 | INFO | train_inner | epoch 028:    120 / 138 loss=2.796, nll_loss=0.955, ppl=1.94, wps=5999.8, ups=0.48, wpb=12514.6, bsz=386.4, num_updates=3570, lr=1e-05, gnorm=0.606, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:33:02 | INFO | train_inner | epoch 028:    130 / 138 loss=2.783, nll_loss=0.94, ppl=1.92, wps=6042.2, ups=0.48, wpb=12560.2, bsz=395.2, num_updates=3580, lr=1e-05, gnorm=0.611, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:33:24 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 3.273 | nll_loss 1.461 | ppl 2.75 | wps 14756.4 | wpb 1129.8 | bsz 29.7 | num_updates 3588 | best_loss 3.192
2022-07-19 10:33:24 | INFO | train | epoch 028 | loss 2.779 | nll_loss 0.936 | ppl 1.91 | wps 4473.6 | ups 0.36 | wpb 12385.4 | bsz 364.8 | num_updates 3588 | lr 1e-05 | gnorm 0.62 | loss_scale None | train_wall 275 | wall 0
2022-07-19 10:33:28 | INFO | train_inner | epoch 029:      2 / 138 loss=2.746, nll_loss=0.9, ppl=1.87, wps=4639.2, ups=0.39, wpb=11898.3, bsz=368, num_updates=3590, lr=1e-05, gnorm=0.636, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:33:49 | INFO | train_inner | epoch 029:     12 / 138 loss=2.781, nll_loss=0.937, ppl=1.91, wps=5952.6, ups=0.49, wpb=12251, bsz=361, num_updates=3600, lr=1e-05, gnorm=0.636, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:33:54 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 3.274 | nll_loss 1.46 | ppl 2.75 | wps 14716.2 | wpb 1129.8 | bsz 29.7 | num_updates 3600 | best_loss 3.192
2022-07-19 10:35:31 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_29_3600.pt (epoch 29 @ 3600 updates, score 3.274) (writing took 96.68126754276454 seconds)
2022-07-19 10:35:51 | INFO | train_inner | epoch 029:     22 / 138 loss=2.756, nll_loss=0.909, ppl=1.88, wps=1009.9, ups=0.08, wpb=12348.9, bsz=356.8, num_updates=3610, lr=1e-05, gnorm=0.602, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:36:11 | INFO | train_inner | epoch 029:     32 / 138 loss=2.759, nll_loss=0.912, ppl=1.88, wps=6309, ups=0.51, wpb=12451.6, bsz=349.6, num_updates=3620, lr=1e-05, gnorm=0.606, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:36:31 | INFO | train_inner | epoch 029:     42 / 138 loss=2.752, nll_loss=0.904, ppl=1.87, wps=6222.2, ups=0.48, wpb=12937.9, bsz=380.8, num_updates=3630, lr=1e-05, gnorm=0.598, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:36:51 | INFO | train_inner | epoch 029:     52 / 138 loss=2.772, nll_loss=0.927, ppl=1.9, wps=6008.3, ups=0.5, wpb=12047.4, bsz=344, num_updates=3640, lr=1e-05, gnorm=0.607, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:37:12 | INFO | train_inner | epoch 029:     62 / 138 loss=2.773, nll_loss=0.929, ppl=1.9, wps=6101.6, ups=0.48, wpb=12820.3, bsz=386.8, num_updates=3650, lr=1e-05, gnorm=0.619, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:37:34 | INFO | train_inner | epoch 029:     72 / 138 loss=2.78, nll_loss=0.937, ppl=1.91, wps=6153.9, ups=0.47, wpb=13218.8, bsz=393.6, num_updates=3660, lr=1e-05, gnorm=0.582, loss_scale=None, train_wall=21, wall=0
2022-07-19 10:37:55 | INFO | train_inner | epoch 029:     82 / 138 loss=2.783, nll_loss=0.94, ppl=1.92, wps=5927.5, ups=0.48, wpb=12441.5, bsz=387.2, num_updates=3670, lr=1e-05, gnorm=0.611, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:38:15 | INFO | train_inner | epoch 029:     92 / 138 loss=2.759, nll_loss=0.913, ppl=1.88, wps=5810.2, ups=0.49, wpb=11874.4, bsz=340, num_updates=3680, lr=1e-05, gnorm=0.617, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:38:36 | INFO | train_inner | epoch 029:    102 / 138 loss=2.773, nll_loss=0.929, ppl=1.9, wps=6079.1, ups=0.48, wpb=12652.5, bsz=367.3, num_updates=3690, lr=1e-05, gnorm=0.628, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:38:57 | INFO | train_inner | epoch 029:    112 / 138 loss=2.719, nll_loss=0.87, ppl=1.83, wps=5923.4, ups=0.48, wpb=12431, bsz=395.9, num_updates=3700, lr=1e-05, gnorm=0.593, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:39:03 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 3.277 | nll_loss 1.464 | ppl 2.76 | wps 14730.6 | wpb 1129.8 | bsz 29.7 | num_updates 3700 | best_loss 3.192
2022-07-19 10:40:42 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_29_3700.pt (epoch 29 @ 3700 updates, score 3.277) (writing took 98.87516885530204 seconds)
2022-07-19 10:41:02 | INFO | train_inner | epoch 029:    122 / 138 loss=2.783, nll_loss=0.94, ppl=1.92, wps=973.4, ups=0.08, wpb=12130.2, bsz=396.8, num_updates=3710, lr=1e-05, gnorm=0.621, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:41:22 | INFO | train_inner | epoch 029:    132 / 138 loss=2.783, nll_loss=0.939, ppl=1.92, wps=5989.1, ups=0.5, wpb=11985.6, bsz=331.2, num_updates=3720, lr=1e-05, gnorm=0.624, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:41:38 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 3.276 | nll_loss 1.463 | ppl 2.76 | wps 14976.7 | wpb 1129.8 | bsz 29.7 | num_updates 3726 | best_loss 3.192
2022-07-19 10:41:38 | INFO | train | epoch 029 | loss 2.766 | nll_loss 0.921 | ppl 1.89 | wps 3456.3 | ups 0.28 | wpb 12385.4 | bsz 364.8 | num_updates 3726 | lr 1e-05 | gnorm 0.615 | loss_scale None | train_wall 273 | wall 0
2022-07-19 10:41:46 | INFO | train_inner | epoch 030:      4 / 138 loss=2.747, nll_loss=0.899, ppl=1.86, wps=4725.3, ups=0.4, wpb=11668.7, bsz=288.6, num_updates=3730, lr=1e-05, gnorm=0.666, loss_scale=None, train_wall=18, wall=0
2022-07-19 10:42:07 | INFO | train_inner | epoch 030:     14 / 138 loss=2.753, nll_loss=0.906, ppl=1.87, wps=6027.2, ups=0.48, wpb=12462, bsz=358, num_updates=3740, lr=1e-05, gnorm=0.616, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:42:28 | INFO | train_inner | epoch 030:     24 / 138 loss=2.721, nll_loss=0.869, ppl=1.83, wps=6020.8, ups=0.49, wpb=12338.4, bsz=303.8, num_updates=3750, lr=1e-05, gnorm=0.613, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:42:49 | INFO | train_inner | epoch 030:     34 / 138 loss=2.75, nll_loss=0.902, ppl=1.87, wps=5957.9, ups=0.48, wpb=12535.5, bsz=462.4, num_updates=3760, lr=1e-05, gnorm=0.593, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:43:10 | INFO | train_inner | epoch 030:     44 / 138 loss=2.756, nll_loss=0.91, ppl=1.88, wps=6021.6, ups=0.47, wpb=12717.4, bsz=407.2, num_updates=3770, lr=1e-05, gnorm=0.594, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:43:31 | INFO | train_inner | epoch 030:     54 / 138 loss=2.737, nll_loss=0.888, ppl=1.85, wps=5981.3, ups=0.47, wpb=12652.8, bsz=384.7, num_updates=3780, lr=1e-05, gnorm=0.6, loss_scale=None, train_wall=21, wall=0
2022-07-19 10:43:52 | INFO | train_inner | epoch 030:     64 / 138 loss=2.767, nll_loss=0.921, ppl=1.89, wps=5917, ups=0.48, wpb=12311.6, bsz=340, num_updates=3790, lr=1e-05, gnorm=0.61, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:44:13 | INFO | train_inner | epoch 030:     74 / 138 loss=2.77, nll_loss=0.926, ppl=1.9, wps=6042.8, ups=0.48, wpb=12532.8, bsz=363.2, num_updates=3800, lr=1e-05, gnorm=0.604, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:44:18 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 3.282 | nll_loss 1.467 | ppl 2.76 | wps 14758.6 | wpb 1129.8 | bsz 29.7 | num_updates 3800 | best_loss 3.192
2022-07-19 10:46:08 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_30_3800.pt (epoch 30 @ 3800 updates, score 3.282) (writing took 110.14933656062931 seconds)
2022-07-19 10:46:28 | INFO | train_inner | epoch 030:     84 / 138 loss=2.734, nll_loss=0.882, ppl=1.84, wps=892.4, ups=0.07, wpb=12115.1, bsz=369.6, num_updates=3810, lr=1e-05, gnorm=0.61, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:46:48 | INFO | train_inner | epoch 030:     94 / 138 loss=2.787, nll_loss=0.945, ppl=1.93, wps=6209.4, ups=0.51, wpb=12195.3, bsz=323.3, num_updates=3820, lr=1e-05, gnorm=0.656, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:47:09 | INFO | train_inner | epoch 030:    104 / 138 loss=2.742, nll_loss=0.894, ppl=1.86, wps=6040.6, ups=0.48, wpb=12487.4, bsz=387.2, num_updates=3830, lr=1e-05, gnorm=0.602, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:47:29 | INFO | train_inner | epoch 030:    114 / 138 loss=2.774, nll_loss=0.931, ppl=1.91, wps=6080.2, ups=0.49, wpb=12400.7, bsz=340, num_updates=3840, lr=1e-05, gnorm=0.611, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:47:50 | INFO | train_inner | epoch 030:    124 / 138 loss=2.744, nll_loss=0.895, ppl=1.86, wps=6062.5, ups=0.48, wpb=12637.6, bsz=373.6, num_updates=3850, lr=1e-05, gnorm=0.597, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:48:11 | INFO | train_inner | epoch 030:    134 / 138 loss=2.771, nll_loss=0.926, ppl=1.9, wps=5988.3, ups=0.48, wpb=12407.2, bsz=368.2, num_updates=3860, lr=1e-05, gnorm=0.623, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:48:23 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 3.282 | nll_loss 1.469 | ppl 2.77 | wps 14706.2 | wpb 1129.8 | bsz 29.7 | num_updates 3864 | best_loss 3.192
2022-07-19 10:48:23 | INFO | train | epoch 030 | loss 2.753 | nll_loss 0.906 | ppl 1.87 | wps 4219.8 | ups 0.34 | wpb 12385.4 | bsz 364.8 | num_updates 3864 | lr 1e-05 | gnorm 0.612 | loss_scale None | train_wall 275 | wall 0
2022-07-19 10:48:36 | INFO | train_inner | epoch 031:      6 / 138 loss=2.755, nll_loss=0.908, ppl=1.88, wps=4584.1, ups=0.4, wpb=11543.2, bsz=335, num_updates=3870, lr=1e-05, gnorm=0.665, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:48:56 | INFO | train_inner | epoch 031:     16 / 138 loss=2.728, nll_loss=0.877, ppl=1.84, wps=5851.7, ups=0.48, wpb=12155, bsz=396, num_updates=3880, lr=1e-05, gnorm=0.612, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:49:17 | INFO | train_inner | epoch 031:     26 / 138 loss=2.722, nll_loss=0.872, ppl=1.83, wps=6149.1, ups=0.49, wpb=12662.9, bsz=372.8, num_updates=3890, lr=1e-05, gnorm=0.583, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:49:38 | INFO | train_inner | epoch 031:     36 / 138 loss=2.71, nll_loss=0.856, ppl=1.81, wps=5972, ups=0.47, wpb=12580.5, bsz=372, num_updates=3900, lr=1e-05, gnorm=0.588, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:49:44 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 3.288 | nll_loss 1.476 | ppl 2.78 | wps 14681.7 | wpb 1129.8 | bsz 29.7 | num_updates 3900 | best_loss 3.192
2022-07-19 10:51:23 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_31_3900.pt (epoch 31 @ 3900 updates, score 3.288) (writing took 99.44008429069072 seconds)
2022-07-19 10:51:43 | INFO | train_inner | epoch 031:     46 / 138 loss=2.744, nll_loss=0.895, ppl=1.86, wps=995.5, ups=0.08, wpb=12456, bsz=360.8, num_updates=3910, lr=1e-05, gnorm=0.6, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:52:04 | INFO | train_inner | epoch 031:     56 / 138 loss=2.727, nll_loss=0.877, ppl=1.84, wps=6241.9, ups=0.49, wpb=12724.7, bsz=332.8, num_updates=3920, lr=1e-05, gnorm=0.591, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:52:24 | INFO | train_inner | epoch 031:     66 / 138 loss=2.716, nll_loss=0.863, ppl=1.82, wps=6063.4, ups=0.5, wpb=12148.7, bsz=356.8, num_updates=3930, lr=1e-05, gnorm=0.605, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:52:44 | INFO | train_inner | epoch 031:     76 / 138 loss=2.747, nll_loss=0.898, ppl=1.86, wps=6012.2, ups=0.49, wpb=12272.5, bsz=377.7, num_updates=3940, lr=1e-05, gnorm=0.642, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:53:04 | INFO | train_inner | epoch 031:     86 / 138 loss=2.763, nll_loss=0.918, ppl=1.89, wps=5975.9, ups=0.5, wpb=12059, bsz=352.7, num_updates=3950, lr=1e-05, gnorm=0.633, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:53:25 | INFO | train_inner | epoch 031:     96 / 138 loss=2.714, nll_loss=0.861, ppl=1.82, wps=6022.3, ups=0.48, wpb=12600.5, bsz=362.4, num_updates=3960, lr=1e-05, gnorm=0.594, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:53:46 | INFO | train_inner | epoch 031:    106 / 138 loss=2.753, nll_loss=0.907, ppl=1.87, wps=5990.6, ups=0.48, wpb=12395, bsz=357.6, num_updates=3970, lr=1e-05, gnorm=0.668, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:54:07 | INFO | train_inner | epoch 031:    116 / 138 loss=2.771, nll_loss=0.925, ppl=1.9, wps=6030.6, ups=0.47, wpb=12706.8, bsz=367.6, num_updates=3980, lr=1e-05, gnorm=0.627, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:54:28 | INFO | train_inner | epoch 031:    126 / 138 loss=2.739, nll_loss=0.891, ppl=1.85, wps=5986.9, ups=0.47, wpb=12625.6, bsz=392, num_updates=3990, lr=1e-05, gnorm=0.593, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:54:49 | INFO | train_inner | epoch 031:    136 / 138 loss=2.773, nll_loss=0.928, ppl=1.9, wps=5972.8, ups=0.47, wpb=12653.6, bsz=384.2, num_updates=4000, lr=1e-05, gnorm=0.617, loss_scale=None, train_wall=21, wall=0
2022-07-19 10:54:55 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 3.288 | nll_loss 1.476 | ppl 2.78 | wps 14776.3 | wpb 1129.8 | bsz 29.7 | num_updates 4000 | best_loss 3.192
2022-07-19 10:56:35 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_31_4000.pt (epoch 31 @ 4000 updates, score 3.288) (writing took 100.01380228810012 seconds)
2022-07-19 10:56:43 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 3.288 | nll_loss 1.477 | ppl 2.78 | wps 15539.7 | wpb 1129.8 | bsz 29.7 | num_updates 4002 | best_loss 3.192
2022-07-19 10:56:43 | INFO | train | epoch 031 | loss 2.741 | nll_loss 0.892 | ppl 1.86 | wps 3420.8 | ups 0.28 | wpb 12385.4 | bsz 364.8 | num_updates 4002 | lr 1e-05 | gnorm 0.617 | loss_scale None | train_wall 274 | wall 0
2022-07-19 10:56:59 | INFO | train_inner | epoch 032:      8 / 138 loss=2.723, nll_loss=0.872, ppl=1.83, wps=895.7, ups=0.08, wpb=11629.7, bsz=338.4, num_updates=4010, lr=1e-05, gnorm=0.655, loss_scale=None, train_wall=18, wall=0
2022-07-19 10:57:19 | INFO | train_inner | epoch 032:     18 / 138 loss=2.741, nll_loss=0.891, ppl=1.85, wps=6204.7, ups=0.49, wpb=12572.8, bsz=345.7, num_updates=4020, lr=1e-05, gnorm=0.637, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:57:40 | INFO | train_inner | epoch 032:     28 / 138 loss=2.745, nll_loss=0.896, ppl=1.86, wps=6128.9, ups=0.49, wpb=12591.4, bsz=354.8, num_updates=4030, lr=1e-05, gnorm=0.624, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:58:01 | INFO | train_inner | epoch 032:     38 / 138 loss=2.729, nll_loss=0.878, ppl=1.84, wps=6076.4, ups=0.48, wpb=12573.7, bsz=392.8, num_updates=4040, lr=1e-05, gnorm=0.592, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:58:21 | INFO | train_inner | epoch 032:     48 / 138 loss=2.718, nll_loss=0.865, ppl=1.82, wps=5972.4, ups=0.48, wpb=12348, bsz=394.4, num_updates=4050, lr=1e-05, gnorm=0.627, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:58:42 | INFO | train_inner | epoch 032:     58 / 138 loss=2.761, nll_loss=0.914, ppl=1.88, wps=6001.8, ups=0.48, wpb=12498.7, bsz=400.7, num_updates=4060, lr=1e-05, gnorm=0.612, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:59:02 | INFO | train_inner | epoch 032:     68 / 138 loss=2.71, nll_loss=0.856, ppl=1.81, wps=5970.4, ups=0.5, wpb=11835.1, bsz=280, num_updates=4070, lr=1e-05, gnorm=0.611, loss_scale=None, train_wall=19, wall=0
2022-07-19 10:59:22 | INFO | train_inner | epoch 032:     78 / 138 loss=2.736, nll_loss=0.886, ppl=1.85, wps=5997.5, ups=0.49, wpb=12185.5, bsz=299.2, num_updates=4080, lr=1e-05, gnorm=0.612, loss_scale=None, train_wall=20, wall=0
2022-07-19 10:59:43 | INFO | train_inner | epoch 032:     88 / 138 loss=2.732, nll_loss=0.881, ppl=1.84, wps=5932.2, ups=0.48, wpb=12433.5, bsz=425.6, num_updates=4090, lr=1e-05, gnorm=0.623, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:00:03 | INFO | train_inner | epoch 032:     98 / 138 loss=2.707, nll_loss=0.854, ppl=1.81, wps=6145.5, ups=0.49, wpb=12463.4, bsz=334.4, num_updates=4100, lr=1e-05, gnorm=0.594, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:00:09 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 3.294 | nll_loss 1.482 | ppl 2.79 | wps 14776.7 | wpb 1129.8 | bsz 29.7 | num_updates 4100 | best_loss 3.192
2022-07-19 11:01:46 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_32_4100.pt (epoch 32 @ 4100 updates, score 3.294) (writing took 97.2372112898156 seconds)
2022-07-19 11:02:07 | INFO | train_inner | epoch 032:    108 / 138 loss=2.726, nll_loss=0.873, ppl=1.83, wps=1034.3, ups=0.08, wpb=12726.6, bsz=355.2, num_updates=4110, lr=1e-05, gnorm=0.607, loss_scale=None, train_wall=19, wall=0
2022-07-19 11:02:26 | INFO | train_inner | epoch 032:    118 / 138 loss=2.741, nll_loss=0.893, ppl=1.86, wps=6012.6, ups=0.51, wpb=11757.9, bsz=357.6, num_updates=4120, lr=1e-05, gnorm=0.632, loss_scale=None, train_wall=19, wall=0
2022-07-19 11:02:47 | INFO | train_inner | epoch 032:    128 / 138 loss=2.714, nll_loss=0.861, ppl=1.82, wps=6080.4, ups=0.49, wpb=12535.4, bsz=396.8, num_updates=4130, lr=1e-05, gnorm=0.592, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:03:06 | INFO | train_inner | epoch 032:    138 / 138 loss=2.714, nll_loss=0.862, ppl=1.82, wps=6204.9, ups=0.51, wpb=12199.2, bsz=400.8, num_updates=4140, lr=1e-05, gnorm=0.64, loss_scale=None, train_wall=19, wall=0
2022-07-19 11:03:12 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 3.293 | nll_loss 1.481 | ppl 2.79 | wps 14936.2 | wpb 1129.8 | bsz 29.7 | num_updates 4140 | best_loss 3.192
2022-07-19 11:03:12 | INFO | train | epoch 032 | loss 2.728 | nll_loss 0.877 | ppl 1.84 | wps 4391.4 | ups 0.35 | wpb 12385.4 | bsz 364.8 | num_updates 4140 | lr 1e-05 | gnorm 0.614 | loss_scale None | train_wall 272 | wall 0
2022-07-19 11:03:33 | INFO | train_inner | epoch 033:     10 / 138 loss=2.711, nll_loss=0.858, ppl=1.81, wps=4791.6, ups=0.38, wpb=12635.4, bsz=316, num_updates=4150, lr=1e-05, gnorm=0.593, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:03:54 | INFO | train_inner | epoch 033:     20 / 138 loss=2.707, nll_loss=0.853, ppl=1.81, wps=6048.9, ups=0.48, wpb=12727.8, bsz=423.2, num_updates=4160, lr=1e-05, gnorm=0.584, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:04:15 | INFO | train_inner | epoch 033:     30 / 138 loss=2.701, nll_loss=0.848, ppl=1.8, wps=6141, ups=0.48, wpb=12817.7, bsz=393.6, num_updates=4170, lr=1e-05, gnorm=0.589, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:04:35 | INFO | train_inner | epoch 033:     40 / 138 loss=2.704, nll_loss=0.85, ppl=1.8, wps=6050.2, ups=0.48, wpb=12576.9, bsz=320, num_updates=4180, lr=1e-05, gnorm=0.589, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:04:56 | INFO | train_inner | epoch 033:     50 / 138 loss=2.712, nll_loss=0.858, ppl=1.81, wps=6042.3, ups=0.48, wpb=12582.7, bsz=379.2, num_updates=4190, lr=1e-05, gnorm=0.599, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:05:17 | INFO | train_inner | epoch 033:     60 / 138 loss=2.713, nll_loss=0.859, ppl=1.81, wps=6045.7, ups=0.48, wpb=12680.8, bsz=357.6, num_updates=4200, lr=1e-05, gnorm=0.606, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:05:23 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 3.297 | nll_loss 1.483 | ppl 2.8 | wps 14815.9 | wpb 1129.8 | bsz 29.7 | num_updates 4200 | best_loss 3.192
2022-07-19 11:06:49 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_33_4200.pt (epoch 33 @ 4200 updates, score 3.297) (writing took 86.46278093848377 seconds)
2022-07-19 11:07:09 | INFO | train_inner | epoch 033:     70 / 138 loss=2.717, nll_loss=0.864, ppl=1.82, wps=1097.9, ups=0.09, wpb=12316, bsz=357.4, num_updates=4210, lr=1e-05, gnorm=0.63, loss_scale=None, train_wall=19, wall=0
2022-07-19 11:07:29 | INFO | train_inner | epoch 033:     80 / 138 loss=2.729, nll_loss=0.878, ppl=1.84, wps=6050.8, ups=0.51, wpb=11809.4, bsz=341.7, num_updates=4220, lr=1e-05, gnorm=0.668, loss_scale=None, train_wall=19, wall=0
2022-07-19 11:07:49 | INFO | train_inner | epoch 033:     90 / 138 loss=2.715, nll_loss=0.862, ppl=1.82, wps=6018, ups=0.49, wpb=12314, bsz=367.9, num_updates=4230, lr=1e-05, gnorm=0.624, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:08:10 | INFO | train_inner | epoch 033:    100 / 138 loss=2.731, nll_loss=0.881, ppl=1.84, wps=5961.8, ups=0.49, wpb=12177, bsz=379.2, num_updates=4240, lr=1e-05, gnorm=0.632, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:08:30 | INFO | train_inner | epoch 033:    110 / 138 loss=2.711, nll_loss=0.857, ppl=1.81, wps=5990.7, ups=0.5, wpb=12098.9, bsz=360, num_updates=4250, lr=1e-05, gnorm=0.603, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:08:50 | INFO | train_inner | epoch 033:    120 / 138 loss=2.74, nll_loss=0.89, ppl=1.85, wps=5933.2, ups=0.5, wpb=11906, bsz=327, num_updates=4260, lr=1e-05, gnorm=0.658, loss_scale=None, train_wall=19, wall=0
2022-07-19 11:09:11 | INFO | train_inner | epoch 033:    130 / 138 loss=2.709, nll_loss=0.856, ppl=1.81, wps=6030.2, ups=0.47, wpb=12883.4, bsz=413.6, num_updates=4270, lr=1e-05, gnorm=0.598, loss_scale=None, train_wall=21, wall=0
2022-07-19 11:09:33 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 3.299 | nll_loss 1.488 | ppl 2.8 | wps 14753.1 | wpb 1129.8 | bsz 29.7 | num_updates 4278 | best_loss 3.192
2022-07-19 11:09:33 | INFO | train | epoch 033 | loss 2.716 | nll_loss 0.863 | ppl 1.82 | wps 4488.9 | ups 0.36 | wpb 12385.4 | bsz 364.8 | num_updates 4278 | lr 1e-05 | gnorm 0.616 | loss_scale None | train_wall 274 | wall 0
2022-07-19 11:09:37 | INFO | train_inner | epoch 034:      2 / 138 loss=2.74, nll_loss=0.891, ppl=1.85, wps=4629.7, ups=0.39, wpb=11721.9, bsz=378.5, num_updates=4280, lr=1e-05, gnorm=0.675, loss_scale=None, train_wall=19, wall=0
2022-07-19 11:09:58 | INFO | train_inner | epoch 034:     12 / 138 loss=2.688, nll_loss=0.832, ppl=1.78, wps=6042.1, ups=0.48, wpb=12662.7, bsz=415.2, num_updates=4290, lr=1e-05, gnorm=0.573, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:10:19 | INFO | train_inner | epoch 034:     22 / 138 loss=2.711, nll_loss=0.856, ppl=1.81, wps=5945, ups=0.48, wpb=12450.7, bsz=396.8, num_updates=4300, lr=1e-05, gnorm=0.599, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:10:24 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 3.303 | nll_loss 1.49 | ppl 2.81 | wps 14695.4 | wpb 1129.8 | bsz 29.7 | num_updates 4300 | best_loss 3.192
2022-07-19 11:11:47 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_34_4300.pt (epoch 34 @ 4300 updates, score 3.303) (writing took 82.91713124513626 seconds)
2022-07-19 11:12:07 | INFO | train_inner | epoch 034:     32 / 138 loss=2.692, nll_loss=0.836, ppl=1.79, wps=1125.8, ups=0.09, wpb=12248.7, bsz=359.5, num_updates=4310, lr=1e-05, gnorm=0.654, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:12:28 | INFO | train_inner | epoch 034:     42 / 138 loss=2.703, nll_loss=0.847, ppl=1.8, wps=6243.8, ups=0.49, wpb=12697.7, bsz=359.2, num_updates=4320, lr=1e-05, gnorm=0.623, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:12:48 | INFO | train_inner | epoch 034:     52 / 138 loss=2.696, nll_loss=0.841, ppl=1.79, wps=6103.8, ups=0.49, wpb=12533.1, bsz=306.2, num_updates=4330, lr=1e-05, gnorm=0.618, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:13:08 | INFO | train_inner | epoch 034:     62 / 138 loss=2.716, nll_loss=0.862, ppl=1.82, wps=5949, ups=0.5, wpb=11962.7, bsz=299.2, num_updates=4340, lr=1e-05, gnorm=0.622, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:13:29 | INFO | train_inner | epoch 034:     72 / 138 loss=2.7, nll_loss=0.844, ppl=1.8, wps=5948.8, ups=0.48, wpb=12519.1, bsz=444, num_updates=4350, lr=1e-05, gnorm=0.587, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:13:51 | INFO | train_inner | epoch 034:     82 / 138 loss=2.711, nll_loss=0.858, ppl=1.81, wps=6036.8, ups=0.48, wpb=12688.1, bsz=392, num_updates=4360, lr=1e-05, gnorm=0.597, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:14:11 | INFO | train_inner | epoch 034:     92 / 138 loss=2.719, nll_loss=0.867, ppl=1.82, wps=5947.5, ups=0.49, wpb=12239.5, bsz=370.4, num_updates=4370, lr=1e-05, gnorm=0.611, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:14:32 | INFO | train_inner | epoch 034:    102 / 138 loss=2.674, nll_loss=0.816, ppl=1.76, wps=5961.5, ups=0.47, wpb=12655.7, bsz=412.8, num_updates=4380, lr=1e-05, gnorm=0.582, loss_scale=None, train_wall=21, wall=0
2022-07-19 11:14:53 | INFO | train_inner | epoch 034:    112 / 138 loss=2.717, nll_loss=0.863, ppl=1.82, wps=6057.9, ups=0.48, wpb=12606.8, bsz=342.6, num_updates=4390, lr=1e-05, gnorm=0.605, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:15:14 | INFO | train_inner | epoch 034:    122 / 138 loss=2.69, nll_loss=0.833, ppl=1.78, wps=6035.9, ups=0.49, wpb=12436.5, bsz=336, num_updates=4400, lr=1e-05, gnorm=0.596, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:15:19 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 3.304 | nll_loss 1.492 | ppl 2.81 | wps 14652.3 | wpb 1129.8 | bsz 29.7 | num_updates 4400 | best_loss 3.192
2022-07-19 11:16:34 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_34_4400.pt (epoch 34 @ 4400 updates, score 3.304) (writing took 74.84833647310734 seconds)
2022-07-19 11:16:55 | INFO | train_inner | epoch 034:    132 / 138 loss=2.727, nll_loss=0.875, ppl=1.83, wps=1250.6, ups=0.1, wpb=12607.7, bsz=375.2, num_updates=4410, lr=1e-05, gnorm=0.606, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:17:11 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 3.304 | nll_loss 1.492 | ppl 2.81 | wps 15002.3 | wpb 1129.8 | bsz 29.7 | num_updates 4416 | best_loss 3.192
2022-07-19 11:17:11 | INFO | train | epoch 034 | loss 2.704 | nll_loss 0.849 | ppl 1.8 | wps 3733.6 | ups 0.3 | wpb 12385.4 | bsz 364.8 | num_updates 4416 | lr 1e-05 | gnorm 0.612 | loss_scale None | train_wall 274 | wall 0
2022-07-19 11:17:19 | INFO | train_inner | epoch 035:      4 / 138 loss=2.69, nll_loss=0.834, ppl=1.78, wps=4694.2, ups=0.41, wpb=11420.3, bsz=293.6, num_updates=4420, lr=1e-05, gnorm=0.66, loss_scale=None, train_wall=18, wall=0
2022-07-19 11:17:40 | INFO | train_inner | epoch 035:     14 / 138 loss=2.686, nll_loss=0.829, ppl=1.78, wps=6175.4, ups=0.47, wpb=13250, bsz=420.4, num_updates=4430, lr=1e-05, gnorm=0.58, loss_scale=None, train_wall=21, wall=0
2022-07-19 11:18:01 | INFO | train_inner | epoch 035:     24 / 138 loss=2.693, nll_loss=0.836, ppl=1.79, wps=5981.7, ups=0.49, wpb=12168.6, bsz=333.6, num_updates=4440, lr=1e-05, gnorm=0.611, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:18:22 | INFO | train_inner | epoch 035:     34 / 138 loss=2.706, nll_loss=0.85, ppl=1.8, wps=5929.2, ups=0.48, wpb=12439.5, bsz=352, num_updates=4450, lr=1e-05, gnorm=0.611, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:18:42 | INFO | train_inner | epoch 035:     44 / 138 loss=2.68, nll_loss=0.823, ppl=1.77, wps=5992.7, ups=0.48, wpb=12474.9, bsz=371.2, num_updates=4460, lr=1e-05, gnorm=0.584, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:19:03 | INFO | train_inner | epoch 035:     54 / 138 loss=2.679, nll_loss=0.822, ppl=1.77, wps=5943.9, ups=0.49, wpb=12196.1, bsz=331.2, num_updates=4470, lr=1e-05, gnorm=0.599, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:19:24 | INFO | train_inner | epoch 035:     64 / 138 loss=2.698, nll_loss=0.842, ppl=1.79, wps=5973.9, ups=0.48, wpb=12387.3, bsz=364, num_updates=4480, lr=1e-05, gnorm=0.594, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:19:44 | INFO | train_inner | epoch 035:     74 / 138 loss=2.706, nll_loss=0.851, ppl=1.8, wps=5994, ups=0.48, wpb=12398.8, bsz=356.2, num_updates=4490, lr=1e-05, gnorm=0.622, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:20:05 | INFO | train_inner | epoch 035:     84 / 138 loss=2.67, nll_loss=0.811, ppl=1.75, wps=5995.8, ups=0.48, wpb=12571.3, bsz=371.9, num_updates=4500, lr=1e-05, gnorm=0.591, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:20:11 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 3.309 | nll_loss 1.497 | ppl 2.82 | wps 14635 | wpb 1129.8 | bsz 29.7 | num_updates 4500 | best_loss 3.192
2022-07-19 11:21:21 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_35_4500.pt (epoch 35 @ 4500 updates, score 3.309) (writing took 69.42238931916654 seconds)
2022-07-19 11:21:41 | INFO | train_inner | epoch 035:     94 / 138 loss=2.68, nll_loss=0.822, ppl=1.77, wps=1310.7, ups=0.1, wpb=12537.8, bsz=431.2, num_updates=4510, lr=1e-05, gnorm=0.585, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:22:01 | INFO | train_inner | epoch 035:    104 / 138 loss=2.691, nll_loss=0.836, ppl=1.79, wps=6139, ups=0.49, wpb=12402.2, bsz=358.4, num_updates=4520, lr=1e-05, gnorm=0.595, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:22:22 | INFO | train_inner | epoch 035:    114 / 138 loss=2.693, nll_loss=0.836, ppl=1.79, wps=6044.4, ups=0.49, wpb=12405.5, bsz=359.2, num_updates=4530, lr=1e-05, gnorm=0.599, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:22:42 | INFO | train_inner | epoch 035:    124 / 138 loss=2.691, nll_loss=0.835, ppl=1.78, wps=6009.3, ups=0.49, wpb=12330.6, bsz=367.8, num_updates=4540, lr=1e-05, gnorm=0.624, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:23:03 | INFO | train_inner | epoch 035:    134 / 138 loss=2.726, nll_loss=0.873, ppl=1.83, wps=5942.7, ups=0.49, wpb=12097.7, bsz=351.3, num_updates=4550, lr=1e-05, gnorm=0.679, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:23:15 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 3.309 | nll_loss 1.498 | ppl 2.82 | wps 14628.6 | wpb 1129.8 | bsz 29.7 | num_updates 4554 | best_loss 3.192
2022-07-19 11:23:15 | INFO | train | epoch 035 | loss 2.692 | nll_loss 0.836 | ppl 1.79 | wps 4685.3 | ups 0.38 | wpb 12385.4 | bsz 364.8 | num_updates 4554 | lr 1e-05 | gnorm 0.609 | loss_scale None | train_wall 275 | wall 0
2022-07-19 11:23:28 | INFO | train_inner | epoch 036:      6 / 138 loss=2.694, nll_loss=0.837, ppl=1.79, wps=4545.5, ups=0.39, wpb=11525.1, bsz=323.2, num_updates=4560, lr=1e-05, gnorm=0.658, loss_scale=None, train_wall=19, wall=0
2022-07-19 11:23:49 | INFO | train_inner | epoch 036:     16 / 138 loss=2.68, nll_loss=0.822, ppl=1.77, wps=5976.4, ups=0.48, wpb=12504.1, bsz=367.2, num_updates=4570, lr=1e-05, gnorm=0.589, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:24:10 | INFO | train_inner | epoch 036:     26 / 138 loss=2.671, nll_loss=0.811, ppl=1.75, wps=5908.5, ups=0.47, wpb=12561, bsz=422.4, num_updates=4580, lr=1e-05, gnorm=0.586, loss_scale=None, train_wall=21, wall=0
2022-07-19 11:24:31 | INFO | train_inner | epoch 036:     36 / 138 loss=2.666, nll_loss=0.807, ppl=1.75, wps=5745.2, ups=0.47, wpb=12200, bsz=390.4, num_updates=4590, lr=1e-05, gnorm=0.611, loss_scale=None, train_wall=21, wall=0
2022-07-19 11:24:53 | INFO | train_inner | epoch 036:     46 / 138 loss=2.674, nll_loss=0.815, ppl=1.76, wps=5934.8, ups=0.47, wpb=12540.2, bsz=406.4, num_updates=4600, lr=1e-05, gnorm=0.587, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:24:58 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 3.314 | nll_loss 1.503 | ppl 2.83 | wps 14662.1 | wpb 1129.8 | bsz 29.7 | num_updates 4600 | best_loss 3.192
2022-07-19 11:26:22 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_36_4600.pt (epoch 36 @ 4600 updates, score 3.314) (writing took 83.91672957781702 seconds)
2022-07-19 11:26:42 | INFO | train_inner | epoch 036:     56 / 138 loss=2.684, nll_loss=0.825, ppl=1.77, wps=1101.9, ups=0.09, wpb=12070.3, bsz=308.8, num_updates=4610, lr=1e-05, gnorm=0.602, loss_scale=None, train_wall=19, wall=0
2022-07-19 11:27:03 | INFO | train_inner | epoch 036:     66 / 138 loss=2.697, nll_loss=0.84, ppl=1.79, wps=6191.4, ups=0.48, wpb=12790.8, bsz=358.4, num_updates=4620, lr=1e-05, gnorm=0.642, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:27:23 | INFO | train_inner | epoch 036:     76 / 138 loss=2.693, nll_loss=0.837, ppl=1.79, wps=5975.6, ups=0.49, wpb=12130.7, bsz=361.4, num_updates=4630, lr=1e-05, gnorm=0.64, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:27:44 | INFO | train_inner | epoch 036:     86 / 138 loss=2.671, nll_loss=0.812, ppl=1.76, wps=6167.9, ups=0.47, wpb=13085.8, bsz=381.6, num_updates=4640, lr=1e-05, gnorm=0.578, loss_scale=None, train_wall=21, wall=0
2022-07-19 11:28:05 | INFO | train_inner | epoch 036:     96 / 138 loss=2.682, nll_loss=0.824, ppl=1.77, wps=5996.6, ups=0.48, wpb=12410.9, bsz=351.2, num_updates=4650, lr=1e-05, gnorm=0.595, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:28:26 | INFO | train_inner | epoch 036:    106 / 138 loss=2.705, nll_loss=0.85, ppl=1.8, wps=6043.5, ups=0.48, wpb=12570, bsz=366.4, num_updates=4660, lr=1e-05, gnorm=0.613, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:28:46 | INFO | train_inner | epoch 036:    116 / 138 loss=2.694, nll_loss=0.838, ppl=1.79, wps=6039.9, ups=0.49, wpb=12271.8, bsz=315.2, num_updates=4670, lr=1e-05, gnorm=0.611, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:29:07 | INFO | train_inner | epoch 036:    126 / 138 loss=2.679, nll_loss=0.821, ppl=1.77, wps=5956.6, ups=0.48, wpb=12469.9, bsz=390.8, num_updates=4680, lr=1e-05, gnorm=0.618, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:29:28 | INFO | train_inner | epoch 036:    136 / 138 loss=2.672, nll_loss=0.813, ppl=1.76, wps=5953.3, ups=0.48, wpb=12317.3, bsz=357.8, num_updates=4690, lr=1e-05, gnorm=0.62, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:29:36 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 3.315 | nll_loss 1.505 | ppl 2.84 | wps 14784.6 | wpb 1129.8 | bsz 29.7 | num_updates 4692 | best_loss 3.192
2022-07-19 11:29:36 | INFO | train | epoch 036 | loss 2.682 | nll_loss 0.824 | ppl 1.77 | wps 4488.5 | ups 0.36 | wpb 12385.4 | bsz 364.8 | num_updates 4692 | lr 1e-05 | gnorm 0.61 | loss_scale None | train_wall 276 | wall 0
2022-07-19 11:29:53 | INFO | train_inner | epoch 037:      8 / 138 loss=2.659, nll_loss=0.798, ppl=1.74, wps=4624.8, ups=0.39, wpb=11733, bsz=335.1, num_updates=4700, lr=1e-05, gnorm=0.64, loss_scale=None, train_wall=19, wall=0
2022-07-19 11:29:59 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 3.316 | nll_loss 1.505 | ppl 2.84 | wps 14692.5 | wpb 1129.8 | bsz 29.7 | num_updates 4700 | best_loss 3.192
2022-07-19 11:31:09 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_37_4700.pt (epoch 37 @ 4700 updates, score 3.316) (writing took 70.68047685176134 seconds)
2022-07-19 11:31:29 | INFO | train_inner | epoch 037:     18 / 138 loss=2.695, nll_loss=0.837, ppl=1.79, wps=1278, ups=0.1, wpb=12305.5, bsz=400.8, num_updates=4710, lr=1e-05, gnorm=0.61, loss_scale=None, train_wall=19, wall=0
2022-07-19 11:31:50 | INFO | train_inner | epoch 037:     28 / 138 loss=2.671, nll_loss=0.811, ppl=1.75, wps=6186.1, ups=0.49, wpb=12666, bsz=368, num_updates=4720, lr=1e-05, gnorm=0.591, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:32:10 | INFO | train_inner | epoch 037:     38 / 138 loss=2.687, nll_loss=0.829, ppl=1.78, wps=6045.6, ups=0.49, wpb=12382.3, bsz=376, num_updates=4730, lr=1e-05, gnorm=0.603, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:32:31 | INFO | train_inner | epoch 037:     48 / 138 loss=2.648, nll_loss=0.786, ppl=1.72, wps=6051.8, ups=0.48, wpb=12495.3, bsz=366.4, num_updates=4740, lr=1e-05, gnorm=0.576, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:32:52 | INFO | train_inner | epoch 037:     58 / 138 loss=2.677, nll_loss=0.818, ppl=1.76, wps=5886.8, ups=0.48, wpb=12175.4, bsz=352.8, num_updates=4750, lr=1e-05, gnorm=0.604, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:33:12 | INFO | train_inner | epoch 037:     68 / 138 loss=2.663, nll_loss=0.803, ppl=1.74, wps=5963, ups=0.48, wpb=12422.9, bsz=348, num_updates=4760, lr=1e-05, gnorm=0.593, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:33:33 | INFO | train_inner | epoch 037:     78 / 138 loss=2.653, nll_loss=0.794, ppl=1.73, wps=5987.7, ups=0.48, wpb=12563.7, bsz=354.4, num_updates=4770, lr=1e-05, gnorm=0.595, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:33:55 | INFO | train_inner | epoch 037:     88 / 138 loss=2.658, nll_loss=0.797, ppl=1.74, wps=5902.5, ups=0.47, wpb=12520.8, bsz=381, num_updates=4780, lr=1e-05, gnorm=0.632, loss_scale=None, train_wall=21, wall=0
2022-07-19 11:34:16 | INFO | train_inner | epoch 037:     98 / 138 loss=2.664, nll_loss=0.804, ppl=1.75, wps=5883.1, ups=0.48, wpb=12356.7, bsz=392.8, num_updates=4790, lr=1e-05, gnorm=0.598, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:34:36 | INFO | train_inner | epoch 037:    108 / 138 loss=2.68, nll_loss=0.821, ppl=1.77, wps=6004.2, ups=0.48, wpb=12463.9, bsz=372.9, num_updates=4800, lr=1e-05, gnorm=0.75, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:34:42 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 3.321 | nll_loss 1.51 | ppl 2.85 | wps 14612.8 | wpb 1129.8 | bsz 29.7 | num_updates 4800 | best_loss 3.192
2022-07-19 11:35:51 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_37_4800.pt (epoch 37 @ 4800 updates, score 3.321) (writing took 69.04086795542389 seconds)
2022-07-19 11:36:11 | INFO | train_inner | epoch 037:    118 / 138 loss=2.673, nll_loss=0.814, ppl=1.76, wps=1276.4, ups=0.11, wpb=12056.4, bsz=331.6, num_updates=4810, lr=1e-05, gnorm=0.638, loss_scale=None, train_wall=19, wall=0
2022-07-19 11:36:31 | INFO | train_inner | epoch 037:    128 / 138 loss=2.673, nll_loss=0.813, ppl=1.76, wps=6195.7, ups=0.49, wpb=12618.4, bsz=322.2, num_updates=4820, lr=1e-05, gnorm=0.606, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:36:51 | INFO | train_inner | epoch 037:    138 / 138 loss=2.671, nll_loss=0.812, ppl=1.76, wps=5976.2, ups=0.51, wpb=11743.8, bsz=380.8, num_updates=4830, lr=1e-05, gnorm=0.656, loss_scale=None, train_wall=19, wall=0
2022-07-19 11:36:57 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 3.321 | nll_loss 1.511 | ppl 2.85 | wps 14824.2 | wpb 1129.8 | bsz 29.7 | num_updates 4830 | best_loss 3.192
2022-07-19 11:36:57 | INFO | train | epoch 037 | loss 2.67 | nll_loss 0.81 | ppl 1.75 | wps 3880.1 | ups 0.31 | wpb 12385.4 | bsz 364.8 | num_updates 4830 | lr 1e-05 | gnorm 0.618 | loss_scale None | train_wall 274 | wall 0
2022-07-19 11:37:17 | INFO | train_inner | epoch 038:     10 / 138 loss=2.658, nll_loss=0.797, ppl=1.74, wps=4660.7, ups=0.38, wpb=12188.2, bsz=376.2, num_updates=4840, lr=1e-05, gnorm=0.619, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:37:38 | INFO | train_inner | epoch 038:     20 / 138 loss=2.673, nll_loss=0.813, ppl=1.76, wps=5894.7, ups=0.48, wpb=12209.1, bsz=385.6, num_updates=4850, lr=1e-05, gnorm=0.601, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:37:59 | INFO | train_inner | epoch 038:     30 / 138 loss=2.672, nll_loss=0.811, ppl=1.75, wps=5936.2, ups=0.48, wpb=12423.8, bsz=378.4, num_updates=4860, lr=1e-05, gnorm=0.606, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:38:20 | INFO | train_inner | epoch 038:     40 / 138 loss=2.623, nll_loss=0.757, ppl=1.69, wps=6013, ups=0.47, wpb=12927.5, bsz=342.8, num_updates=4870, lr=1e-05, gnorm=0.586, loss_scale=None, train_wall=21, wall=0
2022-07-19 11:38:41 | INFO | train_inner | epoch 038:     50 / 138 loss=2.65, nll_loss=0.788, ppl=1.73, wps=5986.2, ups=0.47, wpb=12733.1, bsz=396, num_updates=4880, lr=1e-05, gnorm=0.585, loss_scale=None, train_wall=21, wall=0
2022-07-19 11:39:03 | INFO | train_inner | epoch 038:     60 / 138 loss=2.666, nll_loss=0.805, ppl=1.75, wps=5929.6, ups=0.48, wpb=12463.5, bsz=339.1, num_updates=4890, lr=1e-05, gnorm=0.601, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:39:24 | INFO | train_inner | epoch 038:     70 / 138 loss=2.65, nll_loss=0.789, ppl=1.73, wps=5983.2, ups=0.47, wpb=12834.2, bsz=420.8, num_updates=4900, lr=1e-05, gnorm=0.586, loss_scale=None, train_wall=21, wall=0
2022-07-19 11:39:30 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 3.324 | nll_loss 1.514 | ppl 2.86 | wps 14552.8 | wpb 1129.8 | bsz 29.7 | num_updates 4900 | best_loss 3.192
2022-07-19 11:40:29 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_38_4900.pt (epoch 38 @ 4900 updates, score 3.324) (writing took 59.336641155183315 seconds)
2022-07-19 11:40:49 | INFO | train_inner | epoch 038:     80 / 138 loss=2.664, nll_loss=0.803, ppl=1.74, wps=1412.5, ups=0.12, wpb=11993.5, bsz=318.4, num_updates=4910, lr=1e-05, gnorm=0.623, loss_scale=None, train_wall=19, wall=0
2022-07-19 11:41:09 | INFO | train_inner | epoch 038:     90 / 138 loss=2.663, nll_loss=0.802, ppl=1.74, wps=6111.4, ups=0.49, wpb=12469.6, bsz=356.8, num_updates=4920, lr=1e-05, gnorm=0.588, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:41:30 | INFO | train_inner | epoch 038:    100 / 138 loss=2.681, nll_loss=0.821, ppl=1.77, wps=5992.1, ups=0.48, wpb=12502.8, bsz=379, num_updates=4930, lr=1e-05, gnorm=0.63, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:41:51 | INFO | train_inner | epoch 038:    110 / 138 loss=2.66, nll_loss=0.8, ppl=1.74, wps=6016.4, ups=0.48, wpb=12546.8, bsz=346.4, num_updates=4940, lr=1e-05, gnorm=0.93, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:42:12 | INFO | train_inner | epoch 038:    120 / 138 loss=2.667, nll_loss=0.806, ppl=1.75, wps=5984.5, ups=0.48, wpb=12523.9, bsz=362.4, num_updates=4950, lr=1e-05, gnorm=0.602, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:42:33 | INFO | train_inner | epoch 038:    130 / 138 loss=2.644, nll_loss=0.781, ppl=1.72, wps=5965.6, ups=0.48, wpb=12337.9, bsz=342.5, num_updates=4960, lr=1e-05, gnorm=0.623, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:42:53 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 3.326 | nll_loss 1.515 | ppl 2.86 | wps 14674.3 | wpb 1129.8 | bsz 29.7 | num_updates 4968 | best_loss 3.192
2022-07-19 11:42:53 | INFO | train | epoch 038 | loss 2.66 | nll_loss 0.798 | ppl 1.74 | wps 4792.7 | ups 0.39 | wpb 12385.4 | bsz 364.8 | num_updates 4968 | lr 1e-05 | gnorm 0.633 | loss_scale None | train_wall 276 | wall 0
2022-07-19 11:42:57 | INFO | train_inner | epoch 039:      2 / 138 loss=2.673, nll_loss=0.814, ppl=1.76, wps=4553.7, ups=0.4, wpb=11288.2, bsz=347.2, num_updates=4970, lr=1e-05, gnorm=0.672, loss_scale=None, train_wall=18, wall=0
2022-07-19 11:43:19 | INFO | train_inner | epoch 039:     12 / 138 loss=2.628, nll_loss=0.762, ppl=1.7, wps=5860.7, ups=0.47, wpb=12472.9, bsz=402.3, num_updates=4980, lr=1e-05, gnorm=0.597, loss_scale=None, train_wall=21, wall=0
2022-07-19 11:43:39 | INFO | train_inner | epoch 039:     22 / 138 loss=2.653, nll_loss=0.792, ppl=1.73, wps=5908.8, ups=0.48, wpb=12248.5, bsz=339.4, num_updates=4990, lr=1e-05, gnorm=0.604, loss_scale=None, train_wall=20, wall=0
2022-07-19 11:44:01 | INFO | train_inner | epoch 039:     32 / 138 loss=2.647, nll_loss=0.783, ppl=1.72, wps=5903.1, ups=0.47, wpb=12488.3, bsz=359.2, num_updates=5000, lr=1e-05, gnorm=0.594, loss_scale=None, train_wall=21, wall=0
2022-07-19 11:44:06 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 3.33 | nll_loss 1.52 | ppl 2.87 | wps 14640.9 | wpb 1129.8 | bsz 29.7 | num_updates 5000 | best_loss 3.192
2022-07-19 11:45:06 | INFO | fairseq.checkpoint_utils | saved checkpoint /scratch/gicado/nmt-scripts-output/experiments/mt/CERN/fairseq_out/CERN-June28_v4_1M_backtranslations.finetuned_K90CERNnews/checkpoint_39_5000.pt (epoch 39 @ 5000 updates, score 3.33) (writing took 60.05236347950995 seconds)
2022-07-19 11:45:06 | INFO | train | epoch 039 | loss 2.646 | nll_loss 0.782 | ppl 1.72 | wps 2983.8 | ups 0.24 | wpb 12416.8 | bsz 362 | num_updates 5000 | lr 1e-05 | gnorm 0.599 | loss_scale None | train_wall 65 | wall 0
2022-07-19 11:45:06 | INFO | fairseq_cli.train | done training in 15149.2 seconds
+------- EPILOGUE SCRIPT -----------------------------------------------
|
| Job ID ..............: 4920616
| Stopped at ..........: Tue Jul 19 11:45:07 CEST 2022
| Resources used ......: cpu=03:09:36, mem=39017.92179 GBs, io=506.08486, vmem=7.047G, maxvmem=10.559G
| Peak memory value ...: 10.559G
| Total time used .....: 4:13:25
|
+------- EPILOGUE SCRIPT -----------------------------------------------
